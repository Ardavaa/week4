2024-08-28 10:59:51,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 10:59:51,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 10:59:51,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 10:59:51,551:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 11:00:15,967:INFO:PyCaret RegressionExperiment
2024-08-28 11:00:15,968:INFO:Logging name: reg-default-name
2024-08-28 11:00:15,968:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-28 11:00:15,968:INFO:version 3.3.2
2024-08-28 11:00:15,968:INFO:Initializing setup()
2024-08-28 11:00:15,968:INFO:self.USI: c11f
2024-08-28 11:00:15,968:INFO:self._variable_keys: {'fold_generator', 'y_test', 'memory', 'seed', 'html_param', 'exp_id', 'data', 'logging_param', '_available_plots', 'gpu_param', 'X_train', 'fold_shuffle_param', '_ml_usecase', 'X_test', 'exp_name_log', 'target_param', 'X', 'n_jobs_param', 'pipeline', 'log_plots_param', 'y', 'USI', 'y_train', 'fold_groups_param', 'transform_target_param', 'idx', 'gpu_n_jobs_param'}
2024-08-28 11:00:15,968:INFO:Checking environment
2024-08-28 11:00:15,968:INFO:python_version: 3.11.9
2024-08-28 11:00:15,968:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 11:00:15,968:INFO:machine: AMD64
2024-08-28 11:00:15,968:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 11:00:15,974:INFO:Memory: svmem(total=16867028992, available=4658806784, percent=72.4, used=12208222208, free=4658806784)
2024-08-28 11:00:15,974:INFO:Physical Core: 6
2024-08-28 11:00:15,974:INFO:Logical Core: 12
2024-08-28 11:00:15,974:INFO:Checking libraries
2024-08-28 11:00:15,974:INFO:System:
2024-08-28 11:00:15,974:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 11:00:15,974:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 11:00:15,974:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 11:00:15,974:INFO:PyCaret required dependencies:
2024-08-28 11:00:16,075:INFO:                 pip: 23.2.1
2024-08-28 11:00:16,075:INFO:          setuptools: 67.8.0
2024-08-28 11:00:16,075:INFO:             pycaret: 3.3.2
2024-08-28 11:00:16,075:INFO:             IPython: 8.14.0
2024-08-28 11:00:16,075:INFO:          ipywidgets: 8.1.5
2024-08-28 11:00:16,075:INFO:                tqdm: 4.66.5
2024-08-28 11:00:16,075:INFO:               numpy: 1.24.3
2024-08-28 11:00:16,075:INFO:              pandas: 2.0.3
2024-08-28 11:00:16,075:INFO:              jinja2: 3.1.4
2024-08-28 11:00:16,075:INFO:               scipy: 1.10.1
2024-08-28 11:00:16,075:INFO:              joblib: 1.2.0
2024-08-28 11:00:16,075:INFO:             sklearn: 1.4.2
2024-08-28 11:00:16,075:INFO:                pyod: 2.0.1
2024-08-28 11:00:16,075:INFO:            imblearn: 0.12.3
2024-08-28 11:00:16,075:INFO:   category_encoders: 2.6.3
2024-08-28 11:00:16,075:INFO:            lightgbm: 4.5.0
2024-08-28 11:00:16,075:INFO:               numba: 0.60.0
2024-08-28 11:00:16,075:INFO:            requests: 2.32.3
2024-08-28 11:00:16,075:INFO:          matplotlib: 3.7.1
2024-08-28 11:00:16,075:INFO:          scikitplot: 0.3.7
2024-08-28 11:00:16,075:INFO:         yellowbrick: 1.5
2024-08-28 11:00:16,075:INFO:              plotly: 5.16.1
2024-08-28 11:00:16,075:INFO:    plotly-resampler: Not installed
2024-08-28 11:00:16,075:INFO:             kaleido: 0.2.1
2024-08-28 11:00:16,075:INFO:           schemdraw: 0.15
2024-08-28 11:00:16,075:INFO:         statsmodels: 0.14.2
2024-08-28 11:00:16,075:INFO:              sktime: 0.26.0
2024-08-28 11:00:16,075:INFO:               tbats: 1.1.3
2024-08-28 11:00:16,075:INFO:            pmdarima: 2.0.4
2024-08-28 11:00:16,076:INFO:              psutil: 5.9.0
2024-08-28 11:00:16,076:INFO:          markupsafe: 2.1.3
2024-08-28 11:00:16,076:INFO:             pickle5: Not installed
2024-08-28 11:00:16,076:INFO:         cloudpickle: 3.0.0
2024-08-28 11:00:16,076:INFO:         deprecation: 2.1.0
2024-08-28 11:00:16,076:INFO:              xxhash: 3.5.0
2024-08-28 11:00:16,076:INFO:           wurlitzer: Not installed
2024-08-28 11:00:16,076:INFO:PyCaret optional dependencies:
2024-08-28 11:00:20,449:INFO:                shap: Not installed
2024-08-28 11:00:20,450:INFO:           interpret: Not installed
2024-08-28 11:00:20,450:INFO:                umap: Not installed
2024-08-28 11:00:20,450:INFO:     ydata_profiling: Not installed
2024-08-28 11:00:20,450:INFO:  explainerdashboard: Not installed
2024-08-28 11:00:20,450:INFO:             autoviz: Not installed
2024-08-28 11:00:20,450:INFO:           fairlearn: Not installed
2024-08-28 11:00:20,450:INFO:          deepchecks: Not installed
2024-08-28 11:00:20,450:INFO:             xgboost: 2.0.2
2024-08-28 11:00:20,450:INFO:            catboost: Not installed
2024-08-28 11:00:20,450:INFO:              kmodes: Not installed
2024-08-28 11:00:20,450:INFO:             mlxtend: Not installed
2024-08-28 11:00:20,450:INFO:       statsforecast: Not installed
2024-08-28 11:00:20,450:INFO:        tune_sklearn: Not installed
2024-08-28 11:00:20,450:INFO:                 ray: Not installed
2024-08-28 11:00:20,450:INFO:            hyperopt: Not installed
2024-08-28 11:00:20,450:INFO:              optuna: Not installed
2024-08-28 11:00:20,450:INFO:               skopt: Not installed
2024-08-28 11:00:20,450:INFO:              mlflow: Not installed
2024-08-28 11:00:20,450:INFO:              gradio: 4.41.0
2024-08-28 11:00:20,450:INFO:             fastapi: 0.112.1
2024-08-28 11:00:20,450:INFO:             uvicorn: 0.30.6
2024-08-28 11:00:20,450:INFO:              m2cgen: Not installed
2024-08-28 11:00:20,450:INFO:           evidently: Not installed
2024-08-28 11:00:20,450:INFO:               fugue: Not installed
2024-08-28 11:00:20,450:INFO:           streamlit: Not installed
2024-08-28 11:00:20,450:INFO:             prophet: Not installed
2024-08-28 11:00:20,450:INFO:None
2024-08-28 11:00:20,450:INFO:Set up data.
2024-08-28 11:00:20,455:INFO:Set up folding strategy.
2024-08-28 11:00:20,455:INFO:Set up train/test split.
2024-08-28 11:00:20,459:INFO:Set up index.
2024-08-28 11:00:20,459:INFO:Assigning column types.
2024-08-28 11:00:20,461:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-28 11:00:20,461:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,465:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,551:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,552:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:20,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:20,554:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,558:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,561:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,608:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,645:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,645:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:20,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:20,647:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-28 11:00:20,653:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,658:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,783:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:20,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:20,790:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,795:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:20,987:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:20,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:20,989:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-28 11:00:20,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,079:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,089:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,175:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,175:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,177:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-28 11:00:21,232:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,269:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,324:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,361:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,364:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-28 11:00:21,418:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,455:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,514:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:00:21,550:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,553:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-28 11:00:21,646:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,738:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:21,744:INFO:Preparing preprocessing pipeline...
2024-08-28 11:00:21,744:INFO:Set up simple imputation.
2024-08-28 11:00:21,760:INFO:Finished creating preprocessing pipeline.
2024-08-28 11:00:21,763:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['feature1', 'feature2',
                                             'feature3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-08-28 11:00:21,763:INFO:Creating final display dataframe.
2024-08-28 11:00:21,804:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Regression
3           Original data shape          (100, 4)
4        Transformed data shape          (100, 4)
5   Transformed train set shape           (70, 4)
6    Transformed test set shape           (30, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              c11f
2024-08-28 11:00:21,907:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:21,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:22,002:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:00:22,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:00:22,005:INFO:setup() successfully completed in 6.04s...............
2024-08-28 11:00:22,005:INFO:Initializing compare_models()
2024-08-28 11:00:22,005:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-08-28 11:00:22,005:INFO:Checking exceptions
2024-08-28 11:00:22,007:INFO:Preparing display monitor
2024-08-28 11:00:22,023:INFO:Initializing Linear Regression
2024-08-28 11:00:22,024:INFO:Total runtime is 8.400281270345052e-06 minutes
2024-08-28 11:00:22,027:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:22,027:INFO:Initializing create_model()
2024-08-28 11:00:22,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:22,027:INFO:Checking exceptions
2024-08-28 11:00:22,027:INFO:Importing libraries
2024-08-28 11:00:22,027:INFO:Copying training dataset
2024-08-28 11:00:22,030:INFO:Defining folds
2024-08-28 11:00:22,030:INFO:Declaring metric variables
2024-08-28 11:00:22,033:INFO:Importing untrained model
2024-08-28 11:00:22,037:INFO:Linear Regression Imported successfully
2024-08-28 11:00:22,044:INFO:Starting cross validation
2024-08-28 11:00:22,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:28,895:INFO:Calculating mean and std
2024-08-28 11:00:28,897:INFO:Creating metrics dataframe
2024-08-28 11:00:28,902:INFO:Uploading results into container
2024-08-28 11:00:28,902:INFO:Uploading model into container now
2024-08-28 11:00:28,904:INFO:_master_model_container: 1
2024-08-28 11:00:28,905:INFO:_display_container: 2
2024-08-28 11:00:28,905:INFO:LinearRegression(n_jobs=-1)
2024-08-28 11:00:28,905:INFO:create_model() successfully completed......................................
2024-08-28 11:00:29,057:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:29,057:INFO:Creating metrics dataframe
2024-08-28 11:00:29,063:INFO:Initializing Lasso Regression
2024-08-28 11:00:29,063:INFO:Total runtime is 0.11731928586959839 minutes
2024-08-28 11:00:29,066:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:29,067:INFO:Initializing create_model()
2024-08-28 11:00:29,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:29,067:INFO:Checking exceptions
2024-08-28 11:00:29,067:INFO:Importing libraries
2024-08-28 11:00:29,067:INFO:Copying training dataset
2024-08-28 11:00:29,070:INFO:Defining folds
2024-08-28 11:00:29,070:INFO:Declaring metric variables
2024-08-28 11:00:29,074:INFO:Importing untrained model
2024-08-28 11:00:29,077:INFO:Lasso Regression Imported successfully
2024-08-28 11:00:29,084:INFO:Starting cross validation
2024-08-28 11:00:29,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:31,360:INFO:Calculating mean and std
2024-08-28 11:00:31,362:INFO:Creating metrics dataframe
2024-08-28 11:00:31,364:INFO:Uploading results into container
2024-08-28 11:00:31,365:INFO:Uploading model into container now
2024-08-28 11:00:31,365:INFO:_master_model_container: 2
2024-08-28 11:00:31,365:INFO:_display_container: 2
2024-08-28 11:00:31,366:INFO:Lasso(random_state=123)
2024-08-28 11:00:31,366:INFO:create_model() successfully completed......................................
2024-08-28 11:00:31,481:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:31,481:INFO:Creating metrics dataframe
2024-08-28 11:00:31,488:INFO:Initializing Ridge Regression
2024-08-28 11:00:31,488:INFO:Total runtime is 0.15774774948755899 minutes
2024-08-28 11:00:31,491:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:31,491:INFO:Initializing create_model()
2024-08-28 11:00:31,491:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:31,491:INFO:Checking exceptions
2024-08-28 11:00:31,491:INFO:Importing libraries
2024-08-28 11:00:31,491:INFO:Copying training dataset
2024-08-28 11:00:31,494:INFO:Defining folds
2024-08-28 11:00:31,495:INFO:Declaring metric variables
2024-08-28 11:00:31,498:INFO:Importing untrained model
2024-08-28 11:00:31,501:INFO:Ridge Regression Imported successfully
2024-08-28 11:00:31,507:INFO:Starting cross validation
2024-08-28 11:00:31,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:31,578:INFO:Calculating mean and std
2024-08-28 11:00:31,578:INFO:Creating metrics dataframe
2024-08-28 11:00:31,580:INFO:Uploading results into container
2024-08-28 11:00:31,581:INFO:Uploading model into container now
2024-08-28 11:00:31,581:INFO:_master_model_container: 3
2024-08-28 11:00:31,581:INFO:_display_container: 2
2024-08-28 11:00:31,581:INFO:Ridge(random_state=123)
2024-08-28 11:00:31,581:INFO:create_model() successfully completed......................................
2024-08-28 11:00:31,692:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:31,692:INFO:Creating metrics dataframe
2024-08-28 11:00:31,698:INFO:Initializing Elastic Net
2024-08-28 11:00:31,698:INFO:Total runtime is 0.16124124526977537 minutes
2024-08-28 11:00:31,701:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:31,701:INFO:Initializing create_model()
2024-08-28 11:00:31,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:31,702:INFO:Checking exceptions
2024-08-28 11:00:31,702:INFO:Importing libraries
2024-08-28 11:00:31,702:INFO:Copying training dataset
2024-08-28 11:00:31,705:INFO:Defining folds
2024-08-28 11:00:31,706:INFO:Declaring metric variables
2024-08-28 11:00:31,707:INFO:Importing untrained model
2024-08-28 11:00:31,710:INFO:Elastic Net Imported successfully
2024-08-28 11:00:31,716:INFO:Starting cross validation
2024-08-28 11:00:31,717:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:31,775:INFO:Calculating mean and std
2024-08-28 11:00:31,775:INFO:Creating metrics dataframe
2024-08-28 11:00:31,777:INFO:Uploading results into container
2024-08-28 11:00:31,778:INFO:Uploading model into container now
2024-08-28 11:00:31,778:INFO:_master_model_container: 4
2024-08-28 11:00:31,778:INFO:_display_container: 2
2024-08-28 11:00:31,778:INFO:ElasticNet(random_state=123)
2024-08-28 11:00:31,778:INFO:create_model() successfully completed......................................
2024-08-28 11:00:31,886:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:31,886:INFO:Creating metrics dataframe
2024-08-28 11:00:31,892:INFO:Initializing Least Angle Regression
2024-08-28 11:00:31,892:INFO:Total runtime is 0.1644786238670349 minutes
2024-08-28 11:00:31,896:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:31,896:INFO:Initializing create_model()
2024-08-28 11:00:31,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:31,896:INFO:Checking exceptions
2024-08-28 11:00:31,896:INFO:Importing libraries
2024-08-28 11:00:31,896:INFO:Copying training dataset
2024-08-28 11:00:31,899:INFO:Defining folds
2024-08-28 11:00:31,899:INFO:Declaring metric variables
2024-08-28 11:00:31,902:INFO:Importing untrained model
2024-08-28 11:00:31,905:INFO:Least Angle Regression Imported successfully
2024-08-28 11:00:31,911:INFO:Starting cross validation
2024-08-28 11:00:31,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:31,972:INFO:Calculating mean and std
2024-08-28 11:00:31,972:INFO:Creating metrics dataframe
2024-08-28 11:00:31,974:INFO:Uploading results into container
2024-08-28 11:00:31,975:INFO:Uploading model into container now
2024-08-28 11:00:31,975:INFO:_master_model_container: 5
2024-08-28 11:00:31,975:INFO:_display_container: 2
2024-08-28 11:00:31,975:INFO:Lars(random_state=123)
2024-08-28 11:00:31,975:INFO:create_model() successfully completed......................................
2024-08-28 11:00:32,083:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:32,083:INFO:Creating metrics dataframe
2024-08-28 11:00:32,089:INFO:Initializing Lasso Least Angle Regression
2024-08-28 11:00:32,089:INFO:Total runtime is 0.1677643616994222 minutes
2024-08-28 11:00:32,092:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:32,092:INFO:Initializing create_model()
2024-08-28 11:00:32,092:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:32,092:INFO:Checking exceptions
2024-08-28 11:00:32,093:INFO:Importing libraries
2024-08-28 11:00:32,093:INFO:Copying training dataset
2024-08-28 11:00:32,096:INFO:Defining folds
2024-08-28 11:00:32,096:INFO:Declaring metric variables
2024-08-28 11:00:32,099:INFO:Importing untrained model
2024-08-28 11:00:32,101:INFO:Lasso Least Angle Regression Imported successfully
2024-08-28 11:00:32,107:INFO:Starting cross validation
2024-08-28 11:00:32,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:32,175:INFO:Calculating mean and std
2024-08-28 11:00:32,175:INFO:Creating metrics dataframe
2024-08-28 11:00:32,176:INFO:Uploading results into container
2024-08-28 11:00:32,178:INFO:Uploading model into container now
2024-08-28 11:00:32,178:INFO:_master_model_container: 6
2024-08-28 11:00:32,178:INFO:_display_container: 2
2024-08-28 11:00:32,178:INFO:LassoLars(random_state=123)
2024-08-28 11:00:32,178:INFO:create_model() successfully completed......................................
2024-08-28 11:00:32,284:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:32,284:INFO:Creating metrics dataframe
2024-08-28 11:00:32,292:INFO:Initializing Orthogonal Matching Pursuit
2024-08-28 11:00:32,292:INFO:Total runtime is 0.17113833030064898 minutes
2024-08-28 11:00:32,294:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:32,294:INFO:Initializing create_model()
2024-08-28 11:00:32,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:32,294:INFO:Checking exceptions
2024-08-28 11:00:32,294:INFO:Importing libraries
2024-08-28 11:00:32,296:INFO:Copying training dataset
2024-08-28 11:00:32,298:INFO:Defining folds
2024-08-28 11:00:32,298:INFO:Declaring metric variables
2024-08-28 11:00:32,301:INFO:Importing untrained model
2024-08-28 11:00:32,304:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:00:32,309:INFO:Starting cross validation
2024-08-28 11:00:32,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:32,361:INFO:Calculating mean and std
2024-08-28 11:00:32,362:INFO:Creating metrics dataframe
2024-08-28 11:00:32,363:INFO:Uploading results into container
2024-08-28 11:00:32,363:INFO:Uploading model into container now
2024-08-28 11:00:32,364:INFO:_master_model_container: 7
2024-08-28 11:00:32,364:INFO:_display_container: 2
2024-08-28 11:00:32,364:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:00:32,364:INFO:create_model() successfully completed......................................
2024-08-28 11:00:32,470:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:32,470:INFO:Creating metrics dataframe
2024-08-28 11:00:32,477:INFO:Initializing Bayesian Ridge
2024-08-28 11:00:32,477:INFO:Total runtime is 0.17422002951304116 minutes
2024-08-28 11:00:32,480:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:32,480:INFO:Initializing create_model()
2024-08-28 11:00:32,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:32,480:INFO:Checking exceptions
2024-08-28 11:00:32,480:INFO:Importing libraries
2024-08-28 11:00:32,480:INFO:Copying training dataset
2024-08-28 11:00:32,483:INFO:Defining folds
2024-08-28 11:00:32,483:INFO:Declaring metric variables
2024-08-28 11:00:32,485:INFO:Importing untrained model
2024-08-28 11:00:32,488:INFO:Bayesian Ridge Imported successfully
2024-08-28 11:00:32,493:INFO:Starting cross validation
2024-08-28 11:00:32,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:32,570:INFO:Calculating mean and std
2024-08-28 11:00:32,570:INFO:Creating metrics dataframe
2024-08-28 11:00:32,572:INFO:Uploading results into container
2024-08-28 11:00:32,573:INFO:Uploading model into container now
2024-08-28 11:00:32,573:INFO:_master_model_container: 8
2024-08-28 11:00:32,573:INFO:_display_container: 2
2024-08-28 11:00:32,573:INFO:BayesianRidge()
2024-08-28 11:00:32,573:INFO:create_model() successfully completed......................................
2024-08-28 11:00:32,685:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:32,686:INFO:Creating metrics dataframe
2024-08-28 11:00:32,693:INFO:Initializing Passive Aggressive Regressor
2024-08-28 11:00:32,693:INFO:Total runtime is 0.17782591581344603 minutes
2024-08-28 11:00:32,697:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:32,697:INFO:Initializing create_model()
2024-08-28 11:00:32,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:32,698:INFO:Checking exceptions
2024-08-28 11:00:32,698:INFO:Importing libraries
2024-08-28 11:00:32,698:INFO:Copying training dataset
2024-08-28 11:00:32,701:INFO:Defining folds
2024-08-28 11:00:32,701:INFO:Declaring metric variables
2024-08-28 11:00:32,704:INFO:Importing untrained model
2024-08-28 11:00:32,707:INFO:Passive Aggressive Regressor Imported successfully
2024-08-28 11:00:32,713:INFO:Starting cross validation
2024-08-28 11:00:32,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:32,783:INFO:Calculating mean and std
2024-08-28 11:00:32,783:INFO:Creating metrics dataframe
2024-08-28 11:00:32,785:INFO:Uploading results into container
2024-08-28 11:00:32,785:INFO:Uploading model into container now
2024-08-28 11:00:32,786:INFO:_master_model_container: 9
2024-08-28 11:00:32,786:INFO:_display_container: 2
2024-08-28 11:00:32,786:INFO:PassiveAggressiveRegressor(random_state=123)
2024-08-28 11:00:32,786:INFO:create_model() successfully completed......................................
2024-08-28 11:00:32,897:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:32,897:INFO:Creating metrics dataframe
2024-08-28 11:00:32,905:INFO:Initializing Huber Regressor
2024-08-28 11:00:32,905:INFO:Total runtime is 0.18136276801427204 minutes
2024-08-28 11:00:32,908:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:32,908:INFO:Initializing create_model()
2024-08-28 11:00:32,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:32,908:INFO:Checking exceptions
2024-08-28 11:00:32,908:INFO:Importing libraries
2024-08-28 11:00:32,908:INFO:Copying training dataset
2024-08-28 11:00:32,912:INFO:Defining folds
2024-08-28 11:00:32,912:INFO:Declaring metric variables
2024-08-28 11:00:32,915:INFO:Importing untrained model
2024-08-28 11:00:32,918:INFO:Huber Regressor Imported successfully
2024-08-28 11:00:32,923:INFO:Starting cross validation
2024-08-28 11:00:32,924:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:32,986:INFO:Calculating mean and std
2024-08-28 11:00:32,986:INFO:Creating metrics dataframe
2024-08-28 11:00:32,989:INFO:Uploading results into container
2024-08-28 11:00:32,989:INFO:Uploading model into container now
2024-08-28 11:00:32,989:INFO:_master_model_container: 10
2024-08-28 11:00:32,989:INFO:_display_container: 2
2024-08-28 11:00:32,990:INFO:HuberRegressor()
2024-08-28 11:00:32,990:INFO:create_model() successfully completed......................................
2024-08-28 11:00:33,097:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:33,098:INFO:Creating metrics dataframe
2024-08-28 11:00:33,107:INFO:Initializing K Neighbors Regressor
2024-08-28 11:00:33,107:INFO:Total runtime is 0.18472476005554198 minutes
2024-08-28 11:00:33,110:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:33,110:INFO:Initializing create_model()
2024-08-28 11:00:33,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:33,110:INFO:Checking exceptions
2024-08-28 11:00:33,110:INFO:Importing libraries
2024-08-28 11:00:33,110:INFO:Copying training dataset
2024-08-28 11:00:33,113:INFO:Defining folds
2024-08-28 11:00:33,113:INFO:Declaring metric variables
2024-08-28 11:00:33,116:INFO:Importing untrained model
2024-08-28 11:00:33,119:INFO:K Neighbors Regressor Imported successfully
2024-08-28 11:00:33,125:INFO:Starting cross validation
2024-08-28 11:00:33,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:33,206:INFO:Calculating mean and std
2024-08-28 11:00:33,206:INFO:Creating metrics dataframe
2024-08-28 11:00:33,208:INFO:Uploading results into container
2024-08-28 11:00:33,208:INFO:Uploading model into container now
2024-08-28 11:00:33,209:INFO:_master_model_container: 11
2024-08-28 11:00:33,209:INFO:_display_container: 2
2024-08-28 11:00:33,209:INFO:KNeighborsRegressor(n_jobs=-1)
2024-08-28 11:00:33,209:INFO:create_model() successfully completed......................................
2024-08-28 11:00:33,322:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:33,322:INFO:Creating metrics dataframe
2024-08-28 11:00:33,331:INFO:Initializing Decision Tree Regressor
2024-08-28 11:00:33,331:INFO:Total runtime is 0.18845072587331135 minutes
2024-08-28 11:00:33,334:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:33,334:INFO:Initializing create_model()
2024-08-28 11:00:33,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:33,335:INFO:Checking exceptions
2024-08-28 11:00:33,335:INFO:Importing libraries
2024-08-28 11:00:33,335:INFO:Copying training dataset
2024-08-28 11:00:33,337:INFO:Defining folds
2024-08-28 11:00:33,337:INFO:Declaring metric variables
2024-08-28 11:00:33,340:INFO:Importing untrained model
2024-08-28 11:00:33,343:INFO:Decision Tree Regressor Imported successfully
2024-08-28 11:00:33,349:INFO:Starting cross validation
2024-08-28 11:00:33,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:33,414:INFO:Calculating mean and std
2024-08-28 11:00:33,414:INFO:Creating metrics dataframe
2024-08-28 11:00:33,416:INFO:Uploading results into container
2024-08-28 11:00:33,416:INFO:Uploading model into container now
2024-08-28 11:00:33,417:INFO:_master_model_container: 12
2024-08-28 11:00:33,417:INFO:_display_container: 2
2024-08-28 11:00:33,417:INFO:DecisionTreeRegressor(random_state=123)
2024-08-28 11:00:33,417:INFO:create_model() successfully completed......................................
2024-08-28 11:00:33,529:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:33,530:INFO:Creating metrics dataframe
2024-08-28 11:00:33,537:INFO:Initializing Random Forest Regressor
2024-08-28 11:00:33,537:INFO:Total runtime is 0.19189576307932535 minutes
2024-08-28 11:00:33,541:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:33,541:INFO:Initializing create_model()
2024-08-28 11:00:33,541:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:33,541:INFO:Checking exceptions
2024-08-28 11:00:33,541:INFO:Importing libraries
2024-08-28 11:00:33,541:INFO:Copying training dataset
2024-08-28 11:00:33,544:INFO:Defining folds
2024-08-28 11:00:33,544:INFO:Declaring metric variables
2024-08-28 11:00:33,548:INFO:Importing untrained model
2024-08-28 11:00:33,551:INFO:Random Forest Regressor Imported successfully
2024-08-28 11:00:33,556:INFO:Starting cross validation
2024-08-28 11:00:33,557:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:33,855:INFO:Calculating mean and std
2024-08-28 11:00:33,857:INFO:Creating metrics dataframe
2024-08-28 11:00:33,858:INFO:Uploading results into container
2024-08-28 11:00:33,859:INFO:Uploading model into container now
2024-08-28 11:00:33,859:INFO:_master_model_container: 13
2024-08-28 11:00:33,859:INFO:_display_container: 2
2024-08-28 11:00:33,859:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:00:33,859:INFO:create_model() successfully completed......................................
2024-08-28 11:00:33,974:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:33,975:INFO:Creating metrics dataframe
2024-08-28 11:00:33,983:INFO:Initializing Extra Trees Regressor
2024-08-28 11:00:33,984:INFO:Total runtime is 0.19932930469512938 minutes
2024-08-28 11:00:33,987:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:33,987:INFO:Initializing create_model()
2024-08-28 11:00:33,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:33,987:INFO:Checking exceptions
2024-08-28 11:00:33,987:INFO:Importing libraries
2024-08-28 11:00:33,987:INFO:Copying training dataset
2024-08-28 11:00:33,990:INFO:Defining folds
2024-08-28 11:00:33,990:INFO:Declaring metric variables
2024-08-28 11:00:33,993:INFO:Importing untrained model
2024-08-28 11:00:33,996:INFO:Extra Trees Regressor Imported successfully
2024-08-28 11:00:34,001:INFO:Starting cross validation
2024-08-28 11:00:34,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:34,221:INFO:Calculating mean and std
2024-08-28 11:00:34,222:INFO:Creating metrics dataframe
2024-08-28 11:00:34,224:INFO:Uploading results into container
2024-08-28 11:00:34,225:INFO:Uploading model into container now
2024-08-28 11:00:34,225:INFO:_master_model_container: 14
2024-08-28 11:00:34,225:INFO:_display_container: 2
2024-08-28 11:00:34,225:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:00:34,226:INFO:create_model() successfully completed......................................
2024-08-28 11:00:34,337:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:34,337:INFO:Creating metrics dataframe
2024-08-28 11:00:34,349:INFO:Initializing AdaBoost Regressor
2024-08-28 11:00:34,349:INFO:Total runtime is 0.20543168783187865 minutes
2024-08-28 11:00:34,353:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:34,353:INFO:Initializing create_model()
2024-08-28 11:00:34,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:34,353:INFO:Checking exceptions
2024-08-28 11:00:34,353:INFO:Importing libraries
2024-08-28 11:00:34,353:INFO:Copying training dataset
2024-08-28 11:00:34,356:INFO:Defining folds
2024-08-28 11:00:34,356:INFO:Declaring metric variables
2024-08-28 11:00:34,361:INFO:Importing untrained model
2024-08-28 11:00:34,364:INFO:AdaBoost Regressor Imported successfully
2024-08-28 11:00:34,371:INFO:Starting cross validation
2024-08-28 11:00:34,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:34,524:INFO:Calculating mean and std
2024-08-28 11:00:34,525:INFO:Creating metrics dataframe
2024-08-28 11:00:34,527:INFO:Uploading results into container
2024-08-28 11:00:34,527:INFO:Uploading model into container now
2024-08-28 11:00:34,528:INFO:_master_model_container: 15
2024-08-28 11:00:34,528:INFO:_display_container: 2
2024-08-28 11:00:34,528:INFO:AdaBoostRegressor(random_state=123)
2024-08-28 11:00:34,528:INFO:create_model() successfully completed......................................
2024-08-28 11:00:34,640:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:34,640:INFO:Creating metrics dataframe
2024-08-28 11:00:34,651:INFO:Initializing Gradient Boosting Regressor
2024-08-28 11:00:34,651:INFO:Total runtime is 0.21045076449712116 minutes
2024-08-28 11:00:34,653:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:34,653:INFO:Initializing create_model()
2024-08-28 11:00:34,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:34,654:INFO:Checking exceptions
2024-08-28 11:00:34,654:INFO:Importing libraries
2024-08-28 11:00:34,654:INFO:Copying training dataset
2024-08-28 11:00:34,657:INFO:Defining folds
2024-08-28 11:00:34,657:INFO:Declaring metric variables
2024-08-28 11:00:34,660:INFO:Importing untrained model
2024-08-28 11:00:34,664:INFO:Gradient Boosting Regressor Imported successfully
2024-08-28 11:00:34,670:INFO:Starting cross validation
2024-08-28 11:00:34,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:34,820:INFO:Calculating mean and std
2024-08-28 11:00:34,821:INFO:Creating metrics dataframe
2024-08-28 11:00:34,824:INFO:Uploading results into container
2024-08-28 11:00:34,824:INFO:Uploading model into container now
2024-08-28 11:00:34,825:INFO:_master_model_container: 16
2024-08-28 11:00:34,825:INFO:_display_container: 2
2024-08-28 11:00:34,825:INFO:GradientBoostingRegressor(random_state=123)
2024-08-28 11:00:34,825:INFO:create_model() successfully completed......................................
2024-08-28 11:00:34,940:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:34,940:INFO:Creating metrics dataframe
2024-08-28 11:00:34,950:INFO:Initializing Extreme Gradient Boosting
2024-08-28 11:00:34,950:INFO:Total runtime is 0.2154488404591878 minutes
2024-08-28 11:00:34,953:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:34,953:INFO:Initializing create_model()
2024-08-28 11:00:34,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:34,953:INFO:Checking exceptions
2024-08-28 11:00:34,953:INFO:Importing libraries
2024-08-28 11:00:34,953:INFO:Copying training dataset
2024-08-28 11:00:34,956:INFO:Defining folds
2024-08-28 11:00:34,956:INFO:Declaring metric variables
2024-08-28 11:00:34,960:INFO:Importing untrained model
2024-08-28 11:00:34,963:INFO:Extreme Gradient Boosting Imported successfully
2024-08-28 11:00:34,968:INFO:Starting cross validation
2024-08-28 11:00:34,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:35,183:INFO:Calculating mean and std
2024-08-28 11:00:35,185:INFO:Creating metrics dataframe
2024-08-28 11:00:35,186:INFO:Uploading results into container
2024-08-28 11:00:35,187:INFO:Uploading model into container now
2024-08-28 11:00:35,188:INFO:_master_model_container: 17
2024-08-28 11:00:35,188:INFO:_display_container: 2
2024-08-28 11:00:35,189:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-08-28 11:00:35,189:INFO:create_model() successfully completed......................................
2024-08-28 11:00:35,307:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:35,307:INFO:Creating metrics dataframe
2024-08-28 11:00:35,317:INFO:Initializing Light Gradient Boosting Machine
2024-08-28 11:00:35,317:INFO:Total runtime is 0.22156589825948078 minutes
2024-08-28 11:00:35,320:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:35,320:INFO:Initializing create_model()
2024-08-28 11:00:35,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:35,320:INFO:Checking exceptions
2024-08-28 11:00:35,320:INFO:Importing libraries
2024-08-28 11:00:35,320:INFO:Copying training dataset
2024-08-28 11:00:35,323:INFO:Defining folds
2024-08-28 11:00:35,323:INFO:Declaring metric variables
2024-08-28 11:00:35,326:INFO:Importing untrained model
2024-08-28 11:00:35,330:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:00:35,336:INFO:Starting cross validation
2024-08-28 11:00:35,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:35,529:INFO:Calculating mean and std
2024-08-28 11:00:35,530:INFO:Creating metrics dataframe
2024-08-28 11:00:35,533:INFO:Uploading results into container
2024-08-28 11:00:35,534:INFO:Uploading model into container now
2024-08-28 11:00:35,535:INFO:_master_model_container: 18
2024-08-28 11:00:35,535:INFO:_display_container: 2
2024-08-28 11:00:35,535:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:00:35,535:INFO:create_model() successfully completed......................................
2024-08-28 11:00:35,674:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:35,674:INFO:Creating metrics dataframe
2024-08-28 11:00:35,684:INFO:Initializing Dummy Regressor
2024-08-28 11:00:35,684:INFO:Total runtime is 0.22767930030822753 minutes
2024-08-28 11:00:35,687:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:35,688:INFO:Initializing create_model()
2024-08-28 11:00:35,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631237290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:35,688:INFO:Checking exceptions
2024-08-28 11:00:35,688:INFO:Importing libraries
2024-08-28 11:00:35,688:INFO:Copying training dataset
2024-08-28 11:00:35,691:INFO:Defining folds
2024-08-28 11:00:35,691:INFO:Declaring metric variables
2024-08-28 11:00:35,695:INFO:Importing untrained model
2024-08-28 11:00:35,698:INFO:Dummy Regressor Imported successfully
2024-08-28 11:00:35,704:INFO:Starting cross validation
2024-08-28 11:00:35,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:35,782:INFO:Calculating mean and std
2024-08-28 11:00:35,782:INFO:Creating metrics dataframe
2024-08-28 11:00:35,784:INFO:Uploading results into container
2024-08-28 11:00:35,784:INFO:Uploading model into container now
2024-08-28 11:00:35,785:INFO:_master_model_container: 19
2024-08-28 11:00:35,785:INFO:_display_container: 2
2024-08-28 11:00:35,785:INFO:DummyRegressor()
2024-08-28 11:00:35,785:INFO:create_model() successfully completed......................................
2024-08-28 11:00:35,897:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:35,897:INFO:Creating metrics dataframe
2024-08-28 11:00:35,914:INFO:Initializing create_model()
2024-08-28 11:00:35,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:35,914:INFO:Checking exceptions
2024-08-28 11:00:35,916:INFO:Importing libraries
2024-08-28 11:00:35,916:INFO:Copying training dataset
2024-08-28 11:00:35,918:INFO:Defining folds
2024-08-28 11:00:35,918:INFO:Declaring metric variables
2024-08-28 11:00:35,918:INFO:Importing untrained model
2024-08-28 11:00:35,918:INFO:Declaring custom model
2024-08-28 11:00:35,918:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:00:35,918:INFO:Cross validation set to False
2024-08-28 11:00:35,918:INFO:Fitting Model
2024-08-28 11:00:35,930:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:00:35,930:INFO:create_model() successfully completed......................................
2024-08-28 11:00:36,066:INFO:_master_model_container: 19
2024-08-28 11:00:36,066:INFO:_display_container: 2
2024-08-28 11:00:36,066:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:00:36,066:INFO:compare_models() successfully completed......................................
2024-08-28 11:00:36,066:INFO:Initializing create_model()
2024-08-28 11:00:36,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=OrthogonalMatchingPursuit(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:36,067:INFO:Checking exceptions
2024-08-28 11:00:36,077:INFO:Importing libraries
2024-08-28 11:00:36,077:INFO:Copying training dataset
2024-08-28 11:00:36,081:INFO:Defining folds
2024-08-28 11:00:36,081:INFO:Declaring metric variables
2024-08-28 11:00:36,085:INFO:Importing untrained model
2024-08-28 11:00:36,085:INFO:Declaring custom model
2024-08-28 11:00:36,088:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:00:36,095:INFO:Starting cross validation
2024-08-28 11:00:36,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:36,161:INFO:Calculating mean and std
2024-08-28 11:00:36,161:INFO:Creating metrics dataframe
2024-08-28 11:00:36,165:INFO:Finalizing model
2024-08-28 11:00:36,174:INFO:Uploading results into container
2024-08-28 11:00:36,175:INFO:Uploading model into container now
2024-08-28 11:00:36,182:INFO:_master_model_container: 20
2024-08-28 11:00:36,183:INFO:_display_container: 3
2024-08-28 11:00:36,183:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:00:36,183:INFO:create_model() successfully completed......................................
2024-08-28 11:00:36,291:INFO:Initializing tune_model()
2024-08-28 11:00:36,291:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=OrthogonalMatchingPursuit(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-28 11:00:36,291:INFO:Checking exceptions
2024-08-28 11:00:36,300:INFO:Copying training dataset
2024-08-28 11:00:36,302:INFO:Checking base model
2024-08-28 11:00:36,303:INFO:Base model : Orthogonal Matching Pursuit
2024-08-28 11:00:36,305:INFO:Declaring metric variables
2024-08-28 11:00:36,307:INFO:Defining Hyperparameters
2024-08-28 11:00:36,307:INFO:10 is bigger than total combinations 6, setting search algorithm to grid
2024-08-28 11:00:36,424:INFO:Tuning with n_jobs=-1
2024-08-28 11:00:36,424:INFO:Initializing GridSearchCV
2024-08-28 11:00:36,573:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__n_nonzero_coefs': 1}
2024-08-28 11:00:36,573:INFO:Hyperparameter search completed
2024-08-28 11:00:36,573:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:36,573:INFO:Initializing create_model()
2024-08-28 11:00:36,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018631B94D10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'n_nonzero_coefs': 1})
2024-08-28 11:00:36,573:INFO:Checking exceptions
2024-08-28 11:00:36,573:INFO:Importing libraries
2024-08-28 11:00:36,573:INFO:Copying training dataset
2024-08-28 11:00:36,576:INFO:Defining folds
2024-08-28 11:00:36,576:INFO:Declaring metric variables
2024-08-28 11:00:36,580:INFO:Importing untrained model
2024-08-28 11:00:36,580:INFO:Declaring custom model
2024-08-28 11:00:36,583:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:00:36,589:INFO:Starting cross validation
2024-08-28 11:00:36,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:36,659:INFO:Calculating mean and std
2024-08-28 11:00:36,660:INFO:Creating metrics dataframe
2024-08-28 11:00:36,664:INFO:Finalizing model
2024-08-28 11:00:36,674:INFO:Uploading results into container
2024-08-28 11:00:36,674:INFO:Uploading model into container now
2024-08-28 11:00:36,675:INFO:_master_model_container: 21
2024-08-28 11:00:36,675:INFO:_display_container: 4
2024-08-28 11:00:36,675:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1)
2024-08-28 11:00:36,676:INFO:create_model() successfully completed......................................
2024-08-28 11:00:36,792:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:36,792:INFO:choose_better activated
2024-08-28 11:00:36,796:INFO:SubProcess create_model() called ==================================
2024-08-28 11:00:36,796:INFO:Initializing create_model()
2024-08-28 11:00:36,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:36,797:INFO:Checking exceptions
2024-08-28 11:00:36,798:INFO:Importing libraries
2024-08-28 11:00:36,798:INFO:Copying training dataset
2024-08-28 11:00:36,800:INFO:Defining folds
2024-08-28 11:00:36,800:INFO:Declaring metric variables
2024-08-28 11:00:36,801:INFO:Importing untrained model
2024-08-28 11:00:36,801:INFO:Declaring custom model
2024-08-28 11:00:36,801:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:00:36,801:INFO:Starting cross validation
2024-08-28 11:00:36,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:00:36,856:INFO:Calculating mean and std
2024-08-28 11:00:36,856:INFO:Creating metrics dataframe
2024-08-28 11:00:36,858:INFO:Finalizing model
2024-08-28 11:00:36,863:INFO:Uploading results into container
2024-08-28 11:00:36,864:INFO:Uploading model into container now
2024-08-28 11:00:36,864:INFO:_master_model_container: 22
2024-08-28 11:00:36,864:INFO:_display_container: 5
2024-08-28 11:00:36,864:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:00:36,864:INFO:create_model() successfully completed......................................
2024-08-28 11:00:36,973:INFO:SubProcess create_model() end ==================================
2024-08-28 11:00:36,973:INFO:OrthogonalMatchingPursuit() result for R2 is -0.3352
2024-08-28 11:00:36,974:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1) result for R2 is -0.3167
2024-08-28 11:00:36,974:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1) is best model
2024-08-28 11:00:36,974:INFO:choose_better completed
2024-08-28 11:00:36,982:INFO:_master_model_container: 22
2024-08-28 11:00:36,982:INFO:_display_container: 4
2024-08-28 11:00:36,982:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1)
2024-08-28 11:00:36,982:INFO:tune_model() successfully completed......................................
2024-08-28 11:00:37,102:INFO:Initializing finalize_model()
2024-08-28 11:00:37,102:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-28 11:00:37,102:INFO:Finalizing OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1)
2024-08-28 11:00:37,104:INFO:Initializing create_model()
2024-08-28 11:00:37,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:00:37,104:INFO:Checking exceptions
2024-08-28 11:00:37,106:INFO:Importing libraries
2024-08-28 11:00:37,106:INFO:Copying training dataset
2024-08-28 11:00:37,106:INFO:Defining folds
2024-08-28 11:00:37,106:INFO:Declaring metric variables
2024-08-28 11:00:37,106:INFO:Importing untrained model
2024-08-28 11:00:37,106:INFO:Declaring custom model
2024-08-28 11:00:37,107:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:00:37,107:INFO:Cross validation set to False
2024-08-28 11:00:37,107:INFO:Fitting Model
2024-08-28 11:00:37,116:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['feature1', 'feature2',
                                             'feature3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 OrthogonalMatchingPursuit(fit_intercept=False,
                                           n_nonzero_coefs=1))])
2024-08-28 11:00:37,116:INFO:create_model() successfully completed......................................
2024-08-28 11:00:37,222:INFO:_master_model_container: 22
2024-08-28 11:00:37,222:INFO:_display_container: 4
2024-08-28 11:00:37,226:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['feature1', 'feature2',
                                             'feature3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 OrthogonalMatchingPursuit(fit_intercept=False,
                                           n_nonzero_coefs=1))])
2024-08-28 11:00:37,226:INFO:finalize_model() successfully completed......................................
2024-08-28 11:00:37,334:INFO:Initializing predict_model()
2024-08-28 11:00:37,334:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['feature1', 'feature2',
                                             'feature3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 OrthogonalMatchingPursuit(fit_intercept=False,
                                           n_nonzero_coefs=1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018633A75620>)
2024-08-28 11:00:37,335:INFO:Checking exceptions
2024-08-28 11:00:37,335:INFO:Preloading libraries
2024-08-28 11:00:37,336:INFO:Set up data.
2024-08-28 11:00:37,338:INFO:Set up index.
2024-08-28 11:00:37,456:INFO:Initializing evaluate_model()
2024-08-28 11:00:37,456:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['feature1', 'feature2',
                                             'feature3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 OrthogonalMatchingPursuit(fit_intercept=False,
                                           n_nonzero_coefs=1))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-08-28 11:00:37,471:INFO:Initializing plot_model()
2024-08-28 11:00:37,471:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018631DA92D0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['feature1', 'feature2',
                                             'feature3'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 OrthogonalMatchingPursuit(fit_intercept=False,
                                           n_nonzero_coefs=1))]), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:00:37,471:INFO:Checking exceptions
2024-08-28 11:00:37,472:INFO:Preloading libraries
2024-08-28 11:00:37,472:INFO:Copying training dataset
2024-08-28 11:00:37,472:INFO:Plot type: pipeline
2024-08-28 11:00:37,568:INFO:Visual Rendered Successfully
2024-08-28 11:00:37,677:INFO:plot_model() successfully completed......................................
2024-08-28 11:04:08,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 11:04:08,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 11:04:08,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 11:04:08,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 11:04:21,254:INFO:PyCaret RegressionExperiment
2024-08-28 11:04:21,254:INFO:Logging name: reg-default-name
2024-08-28 11:04:21,254:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-28 11:04:21,254:INFO:version 3.3.2
2024-08-28 11:04:21,254:INFO:Initializing setup()
2024-08-28 11:04:21,254:INFO:self.USI: 56eb
2024-08-28 11:04:21,254:INFO:self._variable_keys: {'data', 'html_param', 'pipeline', '_ml_usecase', 'y', 'X_test', 'exp_name_log', 'gpu_param', 'X_train', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'fold_generator', 'seed', 'USI', 'memory', 'fold_groups_param', 'idx', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'y_train', 'target_param'}
2024-08-28 11:04:21,254:INFO:Checking environment
2024-08-28 11:04:21,254:INFO:python_version: 3.11.9
2024-08-28 11:04:21,254:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 11:04:21,254:INFO:machine: AMD64
2024-08-28 11:04:21,254:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 11:04:21,261:INFO:Memory: svmem(total=16867028992, available=4431167488, percent=73.7, used=12435861504, free=4431167488)
2024-08-28 11:04:21,262:INFO:Physical Core: 6
2024-08-28 11:04:21,262:INFO:Logical Core: 12
2024-08-28 11:04:21,262:INFO:Checking libraries
2024-08-28 11:04:21,262:INFO:System:
2024-08-28 11:04:21,262:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 11:04:21,262:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 11:04:21,262:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 11:04:21,262:INFO:PyCaret required dependencies:
2024-08-28 11:04:21,344:INFO:                 pip: 23.2.1
2024-08-28 11:04:21,344:INFO:          setuptools: 67.8.0
2024-08-28 11:04:21,344:INFO:             pycaret: 3.3.2
2024-08-28 11:04:21,344:INFO:             IPython: 8.14.0
2024-08-28 11:04:21,344:INFO:          ipywidgets: 8.1.5
2024-08-28 11:04:21,344:INFO:                tqdm: 4.66.5
2024-08-28 11:04:21,344:INFO:               numpy: 1.24.3
2024-08-28 11:04:21,344:INFO:              pandas: 2.0.3
2024-08-28 11:04:21,344:INFO:              jinja2: 3.1.4
2024-08-28 11:04:21,344:INFO:               scipy: 1.10.1
2024-08-28 11:04:21,344:INFO:              joblib: 1.2.0
2024-08-28 11:04:21,345:INFO:             sklearn: 1.4.2
2024-08-28 11:04:21,345:INFO:                pyod: 2.0.1
2024-08-28 11:04:21,345:INFO:            imblearn: 0.12.3
2024-08-28 11:04:21,345:INFO:   category_encoders: 2.6.3
2024-08-28 11:04:21,345:INFO:            lightgbm: 4.5.0
2024-08-28 11:04:21,345:INFO:               numba: 0.60.0
2024-08-28 11:04:21,345:INFO:            requests: 2.32.3
2024-08-28 11:04:21,345:INFO:          matplotlib: 3.7.1
2024-08-28 11:04:21,345:INFO:          scikitplot: 0.3.7
2024-08-28 11:04:21,345:INFO:         yellowbrick: 1.5
2024-08-28 11:04:21,345:INFO:              plotly: 5.16.1
2024-08-28 11:04:21,345:INFO:    plotly-resampler: Not installed
2024-08-28 11:04:21,345:INFO:             kaleido: 0.2.1
2024-08-28 11:04:21,345:INFO:           schemdraw: 0.15
2024-08-28 11:04:21,345:INFO:         statsmodels: 0.14.2
2024-08-28 11:04:21,345:INFO:              sktime: 0.26.0
2024-08-28 11:04:21,345:INFO:               tbats: 1.1.3
2024-08-28 11:04:21,345:INFO:            pmdarima: 2.0.4
2024-08-28 11:04:21,345:INFO:              psutil: 5.9.0
2024-08-28 11:04:21,345:INFO:          markupsafe: 2.1.3
2024-08-28 11:04:21,345:INFO:             pickle5: Not installed
2024-08-28 11:04:21,345:INFO:         cloudpickle: 3.0.0
2024-08-28 11:04:21,345:INFO:         deprecation: 2.1.0
2024-08-28 11:04:21,345:INFO:              xxhash: 3.5.0
2024-08-28 11:04:21,345:INFO:           wurlitzer: Not installed
2024-08-28 11:04:21,345:INFO:PyCaret optional dependencies:
2024-08-28 11:04:24,351:INFO:                shap: Not installed
2024-08-28 11:04:24,351:INFO:           interpret: Not installed
2024-08-28 11:04:24,351:INFO:                umap: Not installed
2024-08-28 11:04:24,351:INFO:     ydata_profiling: Not installed
2024-08-28 11:04:24,351:INFO:  explainerdashboard: Not installed
2024-08-28 11:04:24,351:INFO:             autoviz: Not installed
2024-08-28 11:04:24,351:INFO:           fairlearn: Not installed
2024-08-28 11:04:24,351:INFO:          deepchecks: Not installed
2024-08-28 11:04:24,351:INFO:             xgboost: 2.0.2
2024-08-28 11:04:24,351:INFO:            catboost: Not installed
2024-08-28 11:04:24,351:INFO:              kmodes: Not installed
2024-08-28 11:04:24,351:INFO:             mlxtend: Not installed
2024-08-28 11:04:24,351:INFO:       statsforecast: Not installed
2024-08-28 11:04:24,351:INFO:        tune_sklearn: Not installed
2024-08-28 11:04:24,351:INFO:                 ray: Not installed
2024-08-28 11:04:24,352:INFO:            hyperopt: Not installed
2024-08-28 11:04:24,352:INFO:              optuna: Not installed
2024-08-28 11:04:24,352:INFO:               skopt: Not installed
2024-08-28 11:04:24,352:INFO:              mlflow: Not installed
2024-08-28 11:04:24,352:INFO:              gradio: 4.41.0
2024-08-28 11:04:24,352:INFO:             fastapi: 0.112.1
2024-08-28 11:04:24,352:INFO:             uvicorn: 0.30.6
2024-08-28 11:04:24,352:INFO:              m2cgen: Not installed
2024-08-28 11:04:24,352:INFO:           evidently: Not installed
2024-08-28 11:04:24,352:INFO:               fugue: Not installed
2024-08-28 11:04:24,352:INFO:           streamlit: Not installed
2024-08-28 11:04:24,352:INFO:             prophet: Not installed
2024-08-28 11:04:24,352:INFO:None
2024-08-28 11:04:24,352:INFO:Set up data.
2024-08-28 11:04:48,749:INFO:PyCaret RegressionExperiment
2024-08-28 11:04:48,749:INFO:Logging name: reg-default-name
2024-08-28 11:04:48,749:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-28 11:04:48,749:INFO:version 3.3.2
2024-08-28 11:04:48,749:INFO:Initializing setup()
2024-08-28 11:04:48,750:INFO:self.USI: cb35
2024-08-28 11:04:48,750:INFO:self._variable_keys: {'data', 'html_param', 'pipeline', '_ml_usecase', 'y', 'X_test', 'exp_name_log', 'gpu_param', 'X_train', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'fold_generator', 'seed', 'USI', 'memory', 'fold_groups_param', 'idx', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'y_train', 'target_param'}
2024-08-28 11:04:48,750:INFO:Checking environment
2024-08-28 11:04:48,750:INFO:python_version: 3.11.9
2024-08-28 11:04:48,750:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 11:04:48,750:INFO:machine: AMD64
2024-08-28 11:04:48,750:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 11:04:48,755:INFO:Memory: svmem(total=16867028992, available=4546146304, percent=73.0, used=12320882688, free=4546146304)
2024-08-28 11:04:48,755:INFO:Physical Core: 6
2024-08-28 11:04:48,756:INFO:Logical Core: 12
2024-08-28 11:04:48,756:INFO:Checking libraries
2024-08-28 11:04:48,756:INFO:System:
2024-08-28 11:04:48,756:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 11:04:48,756:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 11:04:48,756:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 11:04:48,756:INFO:PyCaret required dependencies:
2024-08-28 11:04:48,756:INFO:                 pip: 23.2.1
2024-08-28 11:04:48,756:INFO:          setuptools: 67.8.0
2024-08-28 11:04:48,756:INFO:             pycaret: 3.3.2
2024-08-28 11:04:48,756:INFO:             IPython: 8.14.0
2024-08-28 11:04:48,756:INFO:          ipywidgets: 8.1.5
2024-08-28 11:04:48,756:INFO:                tqdm: 4.66.5
2024-08-28 11:04:48,756:INFO:               numpy: 1.24.3
2024-08-28 11:04:48,756:INFO:              pandas: 2.0.3
2024-08-28 11:04:48,756:INFO:              jinja2: 3.1.4
2024-08-28 11:04:48,756:INFO:               scipy: 1.10.1
2024-08-28 11:04:48,757:INFO:              joblib: 1.2.0
2024-08-28 11:04:48,757:INFO:             sklearn: 1.4.2
2024-08-28 11:04:48,757:INFO:                pyod: 2.0.1
2024-08-28 11:04:48,757:INFO:            imblearn: 0.12.3
2024-08-28 11:04:48,757:INFO:   category_encoders: 2.6.3
2024-08-28 11:04:48,757:INFO:            lightgbm: 4.5.0
2024-08-28 11:04:48,757:INFO:               numba: 0.60.0
2024-08-28 11:04:48,757:INFO:            requests: 2.32.3
2024-08-28 11:04:48,757:INFO:          matplotlib: 3.7.1
2024-08-28 11:04:48,757:INFO:          scikitplot: 0.3.7
2024-08-28 11:04:48,757:INFO:         yellowbrick: 1.5
2024-08-28 11:04:48,757:INFO:              plotly: 5.16.1
2024-08-28 11:04:48,757:INFO:    plotly-resampler: Not installed
2024-08-28 11:04:48,757:INFO:             kaleido: 0.2.1
2024-08-28 11:04:48,757:INFO:           schemdraw: 0.15
2024-08-28 11:04:48,757:INFO:         statsmodels: 0.14.2
2024-08-28 11:04:48,757:INFO:              sktime: 0.26.0
2024-08-28 11:04:48,757:INFO:               tbats: 1.1.3
2024-08-28 11:04:48,757:INFO:            pmdarima: 2.0.4
2024-08-28 11:04:48,757:INFO:              psutil: 5.9.0
2024-08-28 11:04:48,757:INFO:          markupsafe: 2.1.3
2024-08-28 11:04:48,757:INFO:             pickle5: Not installed
2024-08-28 11:04:48,758:INFO:         cloudpickle: 3.0.0
2024-08-28 11:04:48,758:INFO:         deprecation: 2.1.0
2024-08-28 11:04:48,758:INFO:              xxhash: 3.5.0
2024-08-28 11:04:48,758:INFO:           wurlitzer: Not installed
2024-08-28 11:04:48,758:INFO:PyCaret optional dependencies:
2024-08-28 11:04:48,758:INFO:                shap: Not installed
2024-08-28 11:04:48,758:INFO:           interpret: Not installed
2024-08-28 11:04:48,758:INFO:                umap: Not installed
2024-08-28 11:04:48,758:INFO:     ydata_profiling: Not installed
2024-08-28 11:04:48,758:INFO:  explainerdashboard: Not installed
2024-08-28 11:04:48,758:INFO:             autoviz: Not installed
2024-08-28 11:04:48,758:INFO:           fairlearn: Not installed
2024-08-28 11:04:48,758:INFO:          deepchecks: Not installed
2024-08-28 11:04:48,758:INFO:             xgboost: 2.0.2
2024-08-28 11:04:48,758:INFO:            catboost: Not installed
2024-08-28 11:04:48,758:INFO:              kmodes: Not installed
2024-08-28 11:04:48,758:INFO:             mlxtend: Not installed
2024-08-28 11:04:48,758:INFO:       statsforecast: Not installed
2024-08-28 11:04:48,758:INFO:        tune_sklearn: Not installed
2024-08-28 11:04:48,758:INFO:                 ray: Not installed
2024-08-28 11:04:48,758:INFO:            hyperopt: Not installed
2024-08-28 11:04:48,759:INFO:              optuna: Not installed
2024-08-28 11:04:48,759:INFO:               skopt: Not installed
2024-08-28 11:04:48,759:INFO:              mlflow: Not installed
2024-08-28 11:04:48,759:INFO:              gradio: 4.41.0
2024-08-28 11:04:48,759:INFO:             fastapi: 0.112.1
2024-08-28 11:04:48,759:INFO:             uvicorn: 0.30.6
2024-08-28 11:04:48,759:INFO:              m2cgen: Not installed
2024-08-28 11:04:48,759:INFO:           evidently: Not installed
2024-08-28 11:04:48,759:INFO:               fugue: Not installed
2024-08-28 11:04:48,759:INFO:           streamlit: Not installed
2024-08-28 11:04:48,759:INFO:             prophet: Not installed
2024-08-28 11:04:48,759:INFO:None
2024-08-28 11:04:48,759:INFO:Set up data.
2024-08-28 11:04:48,774:INFO:Set up folding strategy.
2024-08-28 11:04:48,774:INFO:Set up train/test split.
2024-08-28 11:04:48,779:INFO:Set up index.
2024-08-28 11:04:48,779:INFO:Assigning column types.
2024-08-28 11:04:48,782:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-28 11:04:48,783:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,786:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,789:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,875:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:48,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:48,878:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,881:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,930:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,965:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:48,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:48,967:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-28 11:04:48,970:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:04:48,975:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,054:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,055:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,061:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,065:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,155:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,157:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-28 11:04:49,165:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,211:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,246:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,255:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,301:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,338:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,340:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-28 11:04:49,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,430:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,430:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,523:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,526:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-28 11:04:49,581:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,617:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,674:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:04:49,710:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,712:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-28 11:04:49,821:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,918:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:49,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:49,922:INFO:Preparing preprocessing pipeline...
2024-08-28 11:04:49,922:INFO:Set up simple imputation.
2024-08-28 11:04:49,952:INFO:Finished creating preprocessing pipeline.
2024-08-28 11:04:49,955:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-08-28 11:04:49,955:INFO:Creating final display dataframe.
2024-08-28 11:04:50,016:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               age
2                   Target type        Regression
3           Original data shape        (3298, 13)
4        Transformed data shape        (3298, 13)
5   Transformed train set shape        (2308, 13)
6    Transformed test set shape         (990, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              cb35
2024-08-28 11:04:50,147:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:50,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:50,261:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:04:50,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:04:50,264:INFO:setup() successfully completed in 1.52s...............
2024-08-28 11:04:50,264:INFO:Initializing compare_models()
2024-08-28 11:04:50,264:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-08-28 11:04:50,264:INFO:Checking exceptions
2024-08-28 11:04:50,266:INFO:Preparing display monitor
2024-08-28 11:04:50,288:INFO:Initializing Linear Regression
2024-08-28 11:04:50,288:INFO:Total runtime is 0.0 minutes
2024-08-28 11:04:50,292:INFO:SubProcess create_model() called ==================================
2024-08-28 11:04:50,292:INFO:Initializing create_model()
2024-08-28 11:04:50,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:04:50,292:INFO:Checking exceptions
2024-08-28 11:04:50,292:INFO:Importing libraries
2024-08-28 11:04:50,292:INFO:Copying training dataset
2024-08-28 11:04:50,305:INFO:Defining folds
2024-08-28 11:04:50,306:INFO:Declaring metric variables
2024-08-28 11:04:50,316:INFO:Importing untrained model
2024-08-28 11:04:50,340:INFO:Linear Regression Imported successfully
2024-08-28 11:04:50,350:INFO:Starting cross validation
2024-08-28 11:04:50,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:04:56,139:INFO:Calculating mean and std
2024-08-28 11:04:56,141:INFO:Creating metrics dataframe
2024-08-28 11:04:56,143:INFO:Uploading results into container
2024-08-28 11:04:56,144:INFO:Uploading model into container now
2024-08-28 11:04:56,145:INFO:_master_model_container: 1
2024-08-28 11:04:56,146:INFO:_display_container: 2
2024-08-28 11:04:56,146:INFO:LinearRegression(n_jobs=-1)
2024-08-28 11:04:56,146:INFO:create_model() successfully completed......................................
2024-08-28 11:04:56,288:INFO:SubProcess create_model() end ==================================
2024-08-28 11:04:56,288:INFO:Creating metrics dataframe
2024-08-28 11:04:56,294:INFO:Initializing Lasso Regression
2024-08-28 11:04:56,294:INFO:Total runtime is 0.10010832150777181 minutes
2024-08-28 11:04:56,298:INFO:SubProcess create_model() called ==================================
2024-08-28 11:04:56,298:INFO:Initializing create_model()
2024-08-28 11:04:56,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:04:56,298:INFO:Checking exceptions
2024-08-28 11:04:56,298:INFO:Importing libraries
2024-08-28 11:04:56,298:INFO:Copying training dataset
2024-08-28 11:04:56,303:INFO:Defining folds
2024-08-28 11:04:56,303:INFO:Declaring metric variables
2024-08-28 11:04:56,307:INFO:Importing untrained model
2024-08-28 11:04:56,310:INFO:Lasso Regression Imported successfully
2024-08-28 11:04:56,316:INFO:Starting cross validation
2024-08-28 11:04:56,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:04:59,077:INFO:Calculating mean and std
2024-08-28 11:04:59,079:INFO:Creating metrics dataframe
2024-08-28 11:04:59,082:INFO:Uploading results into container
2024-08-28 11:04:59,085:INFO:Uploading model into container now
2024-08-28 11:04:59,088:INFO:_master_model_container: 2
2024-08-28 11:04:59,089:INFO:_display_container: 2
2024-08-28 11:04:59,090:INFO:Lasso(random_state=123)
2024-08-28 11:04:59,090:INFO:create_model() successfully completed......................................
2024-08-28 11:04:59,303:INFO:SubProcess create_model() end ==================================
2024-08-28 11:04:59,303:INFO:Creating metrics dataframe
2024-08-28 11:04:59,310:INFO:Initializing Ridge Regression
2024-08-28 11:04:59,310:INFO:Total runtime is 0.1503796418507894 minutes
2024-08-28 11:04:59,312:INFO:SubProcess create_model() called ==================================
2024-08-28 11:04:59,313:INFO:Initializing create_model()
2024-08-28 11:04:59,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:04:59,313:INFO:Checking exceptions
2024-08-28 11:04:59,313:INFO:Importing libraries
2024-08-28 11:04:59,313:INFO:Copying training dataset
2024-08-28 11:04:59,318:INFO:Defining folds
2024-08-28 11:04:59,319:INFO:Declaring metric variables
2024-08-28 11:04:59,323:INFO:Importing untrained model
2024-08-28 11:04:59,326:INFO:Ridge Regression Imported successfully
2024-08-28 11:04:59,332:INFO:Starting cross validation
2024-08-28 11:04:59,333:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:04:59,422:INFO:Calculating mean and std
2024-08-28 11:04:59,423:INFO:Creating metrics dataframe
2024-08-28 11:04:59,425:INFO:Uploading results into container
2024-08-28 11:04:59,425:INFO:Uploading model into container now
2024-08-28 11:04:59,425:INFO:_master_model_container: 3
2024-08-28 11:04:59,426:INFO:_display_container: 2
2024-08-28 11:04:59,426:INFO:Ridge(random_state=123)
2024-08-28 11:04:59,426:INFO:create_model() successfully completed......................................
2024-08-28 11:04:59,538:INFO:SubProcess create_model() end ==================================
2024-08-28 11:04:59,538:INFO:Creating metrics dataframe
2024-08-28 11:04:59,545:INFO:Initializing Elastic Net
2024-08-28 11:04:59,545:INFO:Total runtime is 0.1542834719022115 minutes
2024-08-28 11:04:59,547:INFO:SubProcess create_model() called ==================================
2024-08-28 11:04:59,547:INFO:Initializing create_model()
2024-08-28 11:04:59,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:04:59,547:INFO:Checking exceptions
2024-08-28 11:04:59,547:INFO:Importing libraries
2024-08-28 11:04:59,547:INFO:Copying training dataset
2024-08-28 11:04:59,553:INFO:Defining folds
2024-08-28 11:04:59,553:INFO:Declaring metric variables
2024-08-28 11:04:59,555:INFO:Importing untrained model
2024-08-28 11:04:59,560:INFO:Elastic Net Imported successfully
2024-08-28 11:04:59,565:INFO:Starting cross validation
2024-08-28 11:04:59,566:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:04:59,643:INFO:Calculating mean and std
2024-08-28 11:04:59,643:INFO:Creating metrics dataframe
2024-08-28 11:04:59,644:INFO:Uploading results into container
2024-08-28 11:04:59,645:INFO:Uploading model into container now
2024-08-28 11:04:59,645:INFO:_master_model_container: 4
2024-08-28 11:04:59,645:INFO:_display_container: 2
2024-08-28 11:04:59,645:INFO:ElasticNet(random_state=123)
2024-08-28 11:04:59,645:INFO:create_model() successfully completed......................................
2024-08-28 11:04:59,754:INFO:SubProcess create_model() end ==================================
2024-08-28 11:04:59,754:INFO:Creating metrics dataframe
2024-08-28 11:04:59,760:INFO:Initializing Least Angle Regression
2024-08-28 11:04:59,760:INFO:Total runtime is 0.1578682541847229 minutes
2024-08-28 11:04:59,763:INFO:SubProcess create_model() called ==================================
2024-08-28 11:04:59,763:INFO:Initializing create_model()
2024-08-28 11:04:59,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:04:59,764:INFO:Checking exceptions
2024-08-28 11:04:59,764:INFO:Importing libraries
2024-08-28 11:04:59,764:INFO:Copying training dataset
2024-08-28 11:04:59,769:INFO:Defining folds
2024-08-28 11:04:59,770:INFO:Declaring metric variables
2024-08-28 11:04:59,772:INFO:Importing untrained model
2024-08-28 11:04:59,775:INFO:Least Angle Regression Imported successfully
2024-08-28 11:04:59,782:INFO:Starting cross validation
2024-08-28 11:04:59,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:04:59,854:INFO:Calculating mean and std
2024-08-28 11:04:59,854:INFO:Creating metrics dataframe
2024-08-28 11:04:59,856:INFO:Uploading results into container
2024-08-28 11:04:59,856:INFO:Uploading model into container now
2024-08-28 11:04:59,857:INFO:_master_model_container: 5
2024-08-28 11:04:59,857:INFO:_display_container: 2
2024-08-28 11:04:59,857:INFO:Lars(random_state=123)
2024-08-28 11:04:59,857:INFO:create_model() successfully completed......................................
2024-08-28 11:04:59,965:INFO:SubProcess create_model() end ==================================
2024-08-28 11:04:59,965:INFO:Creating metrics dataframe
2024-08-28 11:04:59,972:INFO:Initializing Lasso Least Angle Regression
2024-08-28 11:04:59,972:INFO:Total runtime is 0.1614018122355143 minutes
2024-08-28 11:04:59,974:INFO:SubProcess create_model() called ==================================
2024-08-28 11:04:59,975:INFO:Initializing create_model()
2024-08-28 11:04:59,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:04:59,975:INFO:Checking exceptions
2024-08-28 11:04:59,975:INFO:Importing libraries
2024-08-28 11:04:59,975:INFO:Copying training dataset
2024-08-28 11:04:59,979:INFO:Defining folds
2024-08-28 11:04:59,979:INFO:Declaring metric variables
2024-08-28 11:04:59,982:INFO:Importing untrained model
2024-08-28 11:04:59,986:INFO:Lasso Least Angle Regression Imported successfully
2024-08-28 11:04:59,991:INFO:Starting cross validation
2024-08-28 11:04:59,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:00,077:INFO:Calculating mean and std
2024-08-28 11:05:00,077:INFO:Creating metrics dataframe
2024-08-28 11:05:00,079:INFO:Uploading results into container
2024-08-28 11:05:00,080:INFO:Uploading model into container now
2024-08-28 11:05:00,080:INFO:_master_model_container: 6
2024-08-28 11:05:00,080:INFO:_display_container: 2
2024-08-28 11:05:00,081:INFO:LassoLars(random_state=123)
2024-08-28 11:05:00,081:INFO:create_model() successfully completed......................................
2024-08-28 11:05:00,189:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:00,190:INFO:Creating metrics dataframe
2024-08-28 11:05:00,197:INFO:Initializing Orthogonal Matching Pursuit
2024-08-28 11:05:00,197:INFO:Total runtime is 0.1651552081108093 minutes
2024-08-28 11:05:00,199:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:00,199:INFO:Initializing create_model()
2024-08-28 11:05:00,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:00,200:INFO:Checking exceptions
2024-08-28 11:05:00,200:INFO:Importing libraries
2024-08-28 11:05:00,200:INFO:Copying training dataset
2024-08-28 11:05:00,204:INFO:Defining folds
2024-08-28 11:05:00,204:INFO:Declaring metric variables
2024-08-28 11:05:00,206:INFO:Importing untrained model
2024-08-28 11:05:00,209:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:05:00,214:INFO:Starting cross validation
2024-08-28 11:05:00,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:00,280:INFO:Calculating mean and std
2024-08-28 11:05:00,281:INFO:Creating metrics dataframe
2024-08-28 11:05:00,282:INFO:Uploading results into container
2024-08-28 11:05:00,283:INFO:Uploading model into container now
2024-08-28 11:05:00,283:INFO:_master_model_container: 7
2024-08-28 11:05:00,283:INFO:_display_container: 2
2024-08-28 11:05:00,283:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:05:00,283:INFO:create_model() successfully completed......................................
2024-08-28 11:05:00,393:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:00,393:INFO:Creating metrics dataframe
2024-08-28 11:05:00,399:INFO:Initializing Bayesian Ridge
2024-08-28 11:05:00,399:INFO:Total runtime is 0.16851873795191444 minutes
2024-08-28 11:05:00,401:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:00,401:INFO:Initializing create_model()
2024-08-28 11:05:00,401:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:00,401:INFO:Checking exceptions
2024-08-28 11:05:00,401:INFO:Importing libraries
2024-08-28 11:05:00,401:INFO:Copying training dataset
2024-08-28 11:05:00,406:INFO:Defining folds
2024-08-28 11:05:00,406:INFO:Declaring metric variables
2024-08-28 11:05:00,409:INFO:Importing untrained model
2024-08-28 11:05:00,413:INFO:Bayesian Ridge Imported successfully
2024-08-28 11:05:00,418:INFO:Starting cross validation
2024-08-28 11:05:00,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:00,485:INFO:Calculating mean and std
2024-08-28 11:05:00,486:INFO:Creating metrics dataframe
2024-08-28 11:05:00,487:INFO:Uploading results into container
2024-08-28 11:05:00,487:INFO:Uploading model into container now
2024-08-28 11:05:00,488:INFO:_master_model_container: 8
2024-08-28 11:05:00,488:INFO:_display_container: 2
2024-08-28 11:05:00,488:INFO:BayesianRidge()
2024-08-28 11:05:00,488:INFO:create_model() successfully completed......................................
2024-08-28 11:05:00,593:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:00,593:INFO:Creating metrics dataframe
2024-08-28 11:05:00,599:INFO:Initializing Passive Aggressive Regressor
2024-08-28 11:05:00,600:INFO:Total runtime is 0.17187108198801673 minutes
2024-08-28 11:05:00,602:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:00,602:INFO:Initializing create_model()
2024-08-28 11:05:00,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:00,602:INFO:Checking exceptions
2024-08-28 11:05:00,602:INFO:Importing libraries
2024-08-28 11:05:00,602:INFO:Copying training dataset
2024-08-28 11:05:00,607:INFO:Defining folds
2024-08-28 11:05:00,607:INFO:Declaring metric variables
2024-08-28 11:05:00,609:INFO:Importing untrained model
2024-08-28 11:05:00,612:INFO:Passive Aggressive Regressor Imported successfully
2024-08-28 11:05:00,619:INFO:Starting cross validation
2024-08-28 11:05:00,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:00,704:INFO:Calculating mean and std
2024-08-28 11:05:00,704:INFO:Creating metrics dataframe
2024-08-28 11:05:00,706:INFO:Uploading results into container
2024-08-28 11:05:00,706:INFO:Uploading model into container now
2024-08-28 11:05:00,706:INFO:_master_model_container: 9
2024-08-28 11:05:00,706:INFO:_display_container: 2
2024-08-28 11:05:00,706:INFO:PassiveAggressiveRegressor(random_state=123)
2024-08-28 11:05:00,707:INFO:create_model() successfully completed......................................
2024-08-28 11:05:00,824:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:00,824:INFO:Creating metrics dataframe
2024-08-28 11:05:00,831:INFO:Initializing Huber Regressor
2024-08-28 11:05:00,831:INFO:Total runtime is 0.17572486797968542 minutes
2024-08-28 11:05:00,834:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:00,834:INFO:Initializing create_model()
2024-08-28 11:05:00,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:00,834:INFO:Checking exceptions
2024-08-28 11:05:00,834:INFO:Importing libraries
2024-08-28 11:05:00,834:INFO:Copying training dataset
2024-08-28 11:05:00,839:INFO:Defining folds
2024-08-28 11:05:00,839:INFO:Declaring metric variables
2024-08-28 11:05:00,843:INFO:Importing untrained model
2024-08-28 11:05:00,846:INFO:Huber Regressor Imported successfully
2024-08-28 11:05:00,851:INFO:Starting cross validation
2024-08-28 11:05:00,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:00,943:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,953:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,954:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,961:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,962:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,962:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,968:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,974:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,975:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:05:00,980:INFO:Calculating mean and std
2024-08-28 11:05:00,982:INFO:Creating metrics dataframe
2024-08-28 11:05:00,983:INFO:Uploading results into container
2024-08-28 11:05:00,984:INFO:Uploading model into container now
2024-08-28 11:05:00,984:INFO:_master_model_container: 10
2024-08-28 11:05:00,984:INFO:_display_container: 2
2024-08-28 11:05:00,984:INFO:HuberRegressor()
2024-08-28 11:05:00,984:INFO:create_model() successfully completed......................................
2024-08-28 11:05:01,091:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:01,091:INFO:Creating metrics dataframe
2024-08-28 11:05:01,098:INFO:Initializing K Neighbors Regressor
2024-08-28 11:05:01,098:INFO:Total runtime is 0.18018243312835688 minutes
2024-08-28 11:05:01,102:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:01,102:INFO:Initializing create_model()
2024-08-28 11:05:01,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:01,102:INFO:Checking exceptions
2024-08-28 11:05:01,102:INFO:Importing libraries
2024-08-28 11:05:01,102:INFO:Copying training dataset
2024-08-28 11:05:01,107:INFO:Defining folds
2024-08-28 11:05:01,108:INFO:Declaring metric variables
2024-08-28 11:05:01,111:INFO:Importing untrained model
2024-08-28 11:05:01,116:INFO:K Neighbors Regressor Imported successfully
2024-08-28 11:05:01,129:INFO:Starting cross validation
2024-08-28 11:05:01,129:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:01,230:INFO:Calculating mean and std
2024-08-28 11:05:01,231:INFO:Creating metrics dataframe
2024-08-28 11:05:01,233:INFO:Uploading results into container
2024-08-28 11:05:01,233:INFO:Uploading model into container now
2024-08-28 11:05:01,233:INFO:_master_model_container: 11
2024-08-28 11:05:01,233:INFO:_display_container: 2
2024-08-28 11:05:01,234:INFO:KNeighborsRegressor(n_jobs=-1)
2024-08-28 11:05:01,234:INFO:create_model() successfully completed......................................
2024-08-28 11:05:01,344:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:01,344:INFO:Creating metrics dataframe
2024-08-28 11:05:01,353:INFO:Initializing Decision Tree Regressor
2024-08-28 11:05:01,353:INFO:Total runtime is 0.1844169934590657 minutes
2024-08-28 11:05:01,356:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:01,356:INFO:Initializing create_model()
2024-08-28 11:05:01,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:01,356:INFO:Checking exceptions
2024-08-28 11:05:01,356:INFO:Importing libraries
2024-08-28 11:05:01,356:INFO:Copying training dataset
2024-08-28 11:05:01,361:INFO:Defining folds
2024-08-28 11:05:01,361:INFO:Declaring metric variables
2024-08-28 11:05:01,363:INFO:Importing untrained model
2024-08-28 11:05:01,366:INFO:Decision Tree Regressor Imported successfully
2024-08-28 11:05:01,371:INFO:Starting cross validation
2024-08-28 11:05:01,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:01,463:INFO:Calculating mean and std
2024-08-28 11:05:01,464:INFO:Creating metrics dataframe
2024-08-28 11:05:01,466:INFO:Uploading results into container
2024-08-28 11:05:01,466:INFO:Uploading model into container now
2024-08-28 11:05:01,466:INFO:_master_model_container: 12
2024-08-28 11:05:01,467:INFO:_display_container: 2
2024-08-28 11:05:01,467:INFO:DecisionTreeRegressor(random_state=123)
2024-08-28 11:05:01,467:INFO:create_model() successfully completed......................................
2024-08-28 11:05:01,578:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:01,578:INFO:Creating metrics dataframe
2024-08-28 11:05:01,585:INFO:Initializing Random Forest Regressor
2024-08-28 11:05:01,585:INFO:Total runtime is 0.1882965962092081 minutes
2024-08-28 11:05:01,588:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:01,588:INFO:Initializing create_model()
2024-08-28 11:05:01,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:01,588:INFO:Checking exceptions
2024-08-28 11:05:01,588:INFO:Importing libraries
2024-08-28 11:05:01,588:INFO:Copying training dataset
2024-08-28 11:05:01,593:INFO:Defining folds
2024-08-28 11:05:01,593:INFO:Declaring metric variables
2024-08-28 11:05:01,596:INFO:Importing untrained model
2024-08-28 11:05:01,600:INFO:Random Forest Regressor Imported successfully
2024-08-28 11:05:01,605:INFO:Starting cross validation
2024-08-28 11:05:01,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:04,000:INFO:Calculating mean and std
2024-08-28 11:05:04,001:INFO:Creating metrics dataframe
2024-08-28 11:05:04,003:INFO:Uploading results into container
2024-08-28 11:05:04,003:INFO:Uploading model into container now
2024-08-28 11:05:04,004:INFO:_master_model_container: 13
2024-08-28 11:05:04,004:INFO:_display_container: 2
2024-08-28 11:05:04,004:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:04,004:INFO:create_model() successfully completed......................................
2024-08-28 11:05:04,123:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:04,123:INFO:Creating metrics dataframe
2024-08-28 11:05:04,132:INFO:Initializing Extra Trees Regressor
2024-08-28 11:05:04,132:INFO:Total runtime is 0.23073494434356684 minutes
2024-08-28 11:05:04,134:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:04,135:INFO:Initializing create_model()
2024-08-28 11:05:04,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:04,135:INFO:Checking exceptions
2024-08-28 11:05:04,135:INFO:Importing libraries
2024-08-28 11:05:04,135:INFO:Copying training dataset
2024-08-28 11:05:04,140:INFO:Defining folds
2024-08-28 11:05:04,140:INFO:Declaring metric variables
2024-08-28 11:05:04,142:INFO:Importing untrained model
2024-08-28 11:05:04,147:INFO:Extra Trees Regressor Imported successfully
2024-08-28 11:05:04,152:INFO:Starting cross validation
2024-08-28 11:05:04,152:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:05,497:INFO:Calculating mean and std
2024-08-28 11:05:05,498:INFO:Creating metrics dataframe
2024-08-28 11:05:05,500:INFO:Uploading results into container
2024-08-28 11:05:05,500:INFO:Uploading model into container now
2024-08-28 11:05:05,500:INFO:_master_model_container: 14
2024-08-28 11:05:05,500:INFO:_display_container: 2
2024-08-28 11:05:05,502:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:05,502:INFO:create_model() successfully completed......................................
2024-08-28 11:05:05,621:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:05,621:INFO:Creating metrics dataframe
2024-08-28 11:05:05,629:INFO:Initializing AdaBoost Regressor
2024-08-28 11:05:05,629:INFO:Total runtime is 0.255696686108907 minutes
2024-08-28 11:05:05,632:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:05,633:INFO:Initializing create_model()
2024-08-28 11:05:05,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:05,633:INFO:Checking exceptions
2024-08-28 11:05:05,633:INFO:Importing libraries
2024-08-28 11:05:05,633:INFO:Copying training dataset
2024-08-28 11:05:05,639:INFO:Defining folds
2024-08-28 11:05:05,639:INFO:Declaring metric variables
2024-08-28 11:05:05,642:INFO:Importing untrained model
2024-08-28 11:05:05,645:INFO:AdaBoost Regressor Imported successfully
2024-08-28 11:05:05,649:INFO:Starting cross validation
2024-08-28 11:05:05,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:06,104:INFO:Calculating mean and std
2024-08-28 11:05:06,105:INFO:Creating metrics dataframe
2024-08-28 11:05:06,107:INFO:Uploading results into container
2024-08-28 11:05:06,107:INFO:Uploading model into container now
2024-08-28 11:05:06,108:INFO:_master_model_container: 15
2024-08-28 11:05:06,108:INFO:_display_container: 2
2024-08-28 11:05:06,108:INFO:AdaBoostRegressor(random_state=123)
2024-08-28 11:05:06,108:INFO:create_model() successfully completed......................................
2024-08-28 11:05:06,215:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:06,216:INFO:Creating metrics dataframe
2024-08-28 11:05:06,224:INFO:Initializing Gradient Boosting Regressor
2024-08-28 11:05:06,224:INFO:Total runtime is 0.2656107306480407 minutes
2024-08-28 11:05:06,228:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:06,228:INFO:Initializing create_model()
2024-08-28 11:05:06,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:06,228:INFO:Checking exceptions
2024-08-28 11:05:06,229:INFO:Importing libraries
2024-08-28 11:05:06,229:INFO:Copying training dataset
2024-08-28 11:05:06,234:INFO:Defining folds
2024-08-28 11:05:06,234:INFO:Declaring metric variables
2024-08-28 11:05:06,238:INFO:Importing untrained model
2024-08-28 11:05:06,241:INFO:Gradient Boosting Regressor Imported successfully
2024-08-28 11:05:06,248:INFO:Starting cross validation
2024-08-28 11:05:06,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:07,153:INFO:Calculating mean and std
2024-08-28 11:05:07,154:INFO:Creating metrics dataframe
2024-08-28 11:05:07,155:INFO:Uploading results into container
2024-08-28 11:05:07,155:INFO:Uploading model into container now
2024-08-28 11:05:07,155:INFO:_master_model_container: 16
2024-08-28 11:05:07,155:INFO:_display_container: 2
2024-08-28 11:05:07,156:INFO:GradientBoostingRegressor(random_state=123)
2024-08-28 11:05:07,156:INFO:create_model() successfully completed......................................
2024-08-28 11:05:07,264:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:07,265:INFO:Creating metrics dataframe
2024-08-28 11:05:07,276:INFO:Initializing Extreme Gradient Boosting
2024-08-28 11:05:07,276:INFO:Total runtime is 0.2831406076749165 minutes
2024-08-28 11:05:07,280:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:07,280:INFO:Initializing create_model()
2024-08-28 11:05:07,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:07,280:INFO:Checking exceptions
2024-08-28 11:05:07,280:INFO:Importing libraries
2024-08-28 11:05:07,280:INFO:Copying training dataset
2024-08-28 11:05:07,285:INFO:Defining folds
2024-08-28 11:05:07,285:INFO:Declaring metric variables
2024-08-28 11:05:07,288:INFO:Importing untrained model
2024-08-28 11:05:07,295:INFO:Extreme Gradient Boosting Imported successfully
2024-08-28 11:05:07,305:INFO:Starting cross validation
2024-08-28 11:05:07,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:07,947:INFO:Calculating mean and std
2024-08-28 11:05:07,948:INFO:Creating metrics dataframe
2024-08-28 11:05:07,949:INFO:Uploading results into container
2024-08-28 11:05:07,951:INFO:Uploading model into container now
2024-08-28 11:05:07,951:INFO:_master_model_container: 17
2024-08-28 11:05:07,951:INFO:_display_container: 2
2024-08-28 11:05:07,952:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-08-28 11:05:07,952:INFO:create_model() successfully completed......................................
2024-08-28 11:05:08,065:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:08,065:INFO:Creating metrics dataframe
2024-08-28 11:05:08,073:INFO:Initializing Light Gradient Boosting Machine
2024-08-28 11:05:08,073:INFO:Total runtime is 0.2964168429374694 minutes
2024-08-28 11:05:08,076:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:08,076:INFO:Initializing create_model()
2024-08-28 11:05:08,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:08,076:INFO:Checking exceptions
2024-08-28 11:05:08,076:INFO:Importing libraries
2024-08-28 11:05:08,076:INFO:Copying training dataset
2024-08-28 11:05:08,081:INFO:Defining folds
2024-08-28 11:05:08,081:INFO:Declaring metric variables
2024-08-28 11:05:08,085:INFO:Importing untrained model
2024-08-28 11:05:08,088:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:05:08,093:INFO:Starting cross validation
2024-08-28 11:05:08,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:09,394:INFO:Calculating mean and std
2024-08-28 11:05:09,396:INFO:Creating metrics dataframe
2024-08-28 11:05:09,399:INFO:Uploading results into container
2024-08-28 11:05:09,400:INFO:Uploading model into container now
2024-08-28 11:05:09,401:INFO:_master_model_container: 18
2024-08-28 11:05:09,401:INFO:_display_container: 2
2024-08-28 11:05:09,402:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:09,402:INFO:create_model() successfully completed......................................
2024-08-28 11:05:09,544:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:09,544:INFO:Creating metrics dataframe
2024-08-28 11:05:09,555:INFO:Initializing Dummy Regressor
2024-08-28 11:05:09,555:INFO:Total runtime is 0.3211293935775756 minutes
2024-08-28 11:05:09,558:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:09,558:INFO:Initializing create_model()
2024-08-28 11:05:09,558:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BB352E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:09,558:INFO:Checking exceptions
2024-08-28 11:05:09,558:INFO:Importing libraries
2024-08-28 11:05:09,558:INFO:Copying training dataset
2024-08-28 11:05:09,563:INFO:Defining folds
2024-08-28 11:05:09,564:INFO:Declaring metric variables
2024-08-28 11:05:09,567:INFO:Importing untrained model
2024-08-28 11:05:09,570:INFO:Dummy Regressor Imported successfully
2024-08-28 11:05:09,574:INFO:Starting cross validation
2024-08-28 11:05:09,575:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:09,640:INFO:Calculating mean and std
2024-08-28 11:05:09,640:INFO:Creating metrics dataframe
2024-08-28 11:05:09,642:INFO:Uploading results into container
2024-08-28 11:05:09,642:INFO:Uploading model into container now
2024-08-28 11:05:09,642:INFO:_master_model_container: 19
2024-08-28 11:05:09,642:INFO:_display_container: 2
2024-08-28 11:05:09,642:INFO:DummyRegressor()
2024-08-28 11:05:09,642:INFO:create_model() successfully completed......................................
2024-08-28 11:05:09,752:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:09,752:INFO:Creating metrics dataframe
2024-08-28 11:05:09,769:INFO:Initializing create_model()
2024-08-28 11:05:09,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:09,769:INFO:Checking exceptions
2024-08-28 11:05:09,770:INFO:Importing libraries
2024-08-28 11:05:09,770:INFO:Copying training dataset
2024-08-28 11:05:09,774:INFO:Defining folds
2024-08-28 11:05:09,774:INFO:Declaring metric variables
2024-08-28 11:05:09,774:INFO:Importing untrained model
2024-08-28 11:05:09,774:INFO:Declaring custom model
2024-08-28 11:05:09,775:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:05:09,775:INFO:Cross validation set to False
2024-08-28 11:05:09,775:INFO:Fitting Model
2024-08-28 11:05:09,785:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:05:09,785:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:05:09,785:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:05:09,785:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:05:09,785:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:05:09,785:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:05:09,897:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:09,897:INFO:create_model() successfully completed......................................
2024-08-28 11:05:10,062:INFO:_master_model_container: 19
2024-08-28 11:05:10,062:INFO:_display_container: 2
2024-08-28 11:05:10,062:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:10,062:INFO:compare_models() successfully completed......................................
2024-08-28 11:05:10,063:INFO:Initializing create_model()
2024-08-28 11:05:10,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:10,063:INFO:Checking exceptions
2024-08-28 11:05:10,078:INFO:Importing libraries
2024-08-28 11:05:10,079:INFO:Copying training dataset
2024-08-28 11:05:10,085:INFO:Defining folds
2024-08-28 11:05:10,085:INFO:Declaring metric variables
2024-08-28 11:05:10,088:INFO:Importing untrained model
2024-08-28 11:05:10,088:INFO:Declaring custom model
2024-08-28 11:05:10,092:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:05:10,101:INFO:Starting cross validation
2024-08-28 11:05:10,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:11,457:INFO:Calculating mean and std
2024-08-28 11:05:11,459:INFO:Creating metrics dataframe
2024-08-28 11:05:11,471:INFO:Finalizing model
2024-08-28 11:05:11,492:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000967 seconds.
2024-08-28 11:05:11,495:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:05:11,495:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:05:11,496:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:05:11,496:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:05:11,496:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:05:11,687:INFO:Uploading results into container
2024-08-28 11:05:11,689:INFO:Uploading model into container now
2024-08-28 11:05:11,706:INFO:_master_model_container: 20
2024-08-28 11:05:11,706:INFO:_display_container: 3
2024-08-28 11:05:11,706:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:11,706:INFO:create_model() successfully completed......................................
2024-08-28 11:05:11,870:INFO:Initializing tune_model()
2024-08-28 11:05:11,870:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-28 11:05:11,870:INFO:Checking exceptions
2024-08-28 11:05:11,885:INFO:Copying training dataset
2024-08-28 11:05:11,888:INFO:Checking base model
2024-08-28 11:05:11,888:INFO:Base model : Light Gradient Boosting Machine
2024-08-28 11:05:11,892:INFO:Declaring metric variables
2024-08-28 11:05:11,895:INFO:Defining Hyperparameters
2024-08-28 11:05:12,066:INFO:Tuning with n_jobs=-1
2024-08-28 11:05:12,066:INFO:Initializing RandomizedSearchCV
2024-08-28 11:05:24,265:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-08-28 11:05:24,267:INFO:Hyperparameter search completed
2024-08-28 11:05:24,267:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:24,268:INFO:Initializing create_model()
2024-08-28 11:05:24,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155BC835C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-08-28 11:05:24,269:INFO:Checking exceptions
2024-08-28 11:05:24,269:INFO:Importing libraries
2024-08-28 11:05:24,269:INFO:Copying training dataset
2024-08-28 11:05:24,278:INFO:Defining folds
2024-08-28 11:05:24,279:INFO:Declaring metric variables
2024-08-28 11:05:24,284:INFO:Importing untrained model
2024-08-28 11:05:24,284:INFO:Declaring custom model
2024-08-28 11:05:24,290:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:05:24,300:INFO:Starting cross validation
2024-08-28 11:05:24,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:26,207:INFO:Calculating mean and std
2024-08-28 11:05:26,208:INFO:Creating metrics dataframe
2024-08-28 11:05:26,218:INFO:Finalizing model
2024-08-28 11:05:26,230:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-08-28 11:05:26,230:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-08-28 11:05:26,230:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-08-28 11:05:26,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-08-28 11:05:26,236:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-08-28 11:05:26,236:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-08-28 11:05:26,238:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.
2024-08-28 11:05:26,238:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:05:26,238:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:05:26,238:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:05:26,239:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:05:26,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:05:26,555:INFO:Uploading results into container
2024-08-28 11:05:26,557:INFO:Uploading model into container now
2024-08-28 11:05:26,558:INFO:_master_model_container: 21
2024-08-28 11:05:26,558:INFO:_display_container: 4
2024-08-28 11:05:26,560:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2024-08-28 11:05:26,560:INFO:create_model() successfully completed......................................
2024-08-28 11:05:26,719:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:26,719:INFO:choose_better activated
2024-08-28 11:05:26,722:INFO:SubProcess create_model() called ==================================
2024-08-28 11:05:26,722:INFO:Initializing create_model()
2024-08-28 11:05:26,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:26,722:INFO:Checking exceptions
2024-08-28 11:05:26,724:INFO:Importing libraries
2024-08-28 11:05:26,724:INFO:Copying training dataset
2024-08-28 11:05:26,728:INFO:Defining folds
2024-08-28 11:05:26,728:INFO:Declaring metric variables
2024-08-28 11:05:26,729:INFO:Importing untrained model
2024-08-28 11:05:26,729:INFO:Declaring custom model
2024-08-28 11:05:26,729:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:05:26,729:INFO:Starting cross validation
2024-08-28 11:05:26,730:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:05:27,827:INFO:Calculating mean and std
2024-08-28 11:05:27,827:INFO:Creating metrics dataframe
2024-08-28 11:05:27,829:INFO:Finalizing model
2024-08-28 11:05:27,841:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2024-08-28 11:05:27,841:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:05:27,841:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:05:27,841:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:05:27,842:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:05:27,981:INFO:Uploading results into container
2024-08-28 11:05:27,981:INFO:Uploading model into container now
2024-08-28 11:05:27,982:INFO:_master_model_container: 22
2024-08-28 11:05:27,982:INFO:_display_container: 5
2024-08-28 11:05:27,982:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:27,982:INFO:create_model() successfully completed......................................
2024-08-28 11:05:28,124:INFO:SubProcess create_model() end ==================================
2024-08-28 11:05:28,125:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9845
2024-08-28 11:05:28,125:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.9796
2024-08-28 11:05:28,126:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2024-08-28 11:05:28,126:INFO:choose_better completed
2024-08-28 11:05:28,126:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-08-28 11:05:28,134:INFO:_master_model_container: 22
2024-08-28 11:05:28,134:INFO:_display_container: 4
2024-08-28 11:05:28,134:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:28,134:INFO:tune_model() successfully completed......................................
2024-08-28 11:05:28,253:INFO:Initializing finalize_model()
2024-08-28 11:05:28,253:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-28 11:05:28,253:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:05:28,256:INFO:Initializing create_model()
2024-08-28 11:05:28,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:05:28,256:INFO:Checking exceptions
2024-08-28 11:05:28,257:INFO:Importing libraries
2024-08-28 11:05:28,257:INFO:Copying training dataset
2024-08-28 11:05:28,258:INFO:Defining folds
2024-08-28 11:05:28,258:INFO:Declaring metric variables
2024-08-28 11:05:28,258:INFO:Importing untrained model
2024-08-28 11:05:28,258:INFO:Declaring custom model
2024-08-28 11:05:28,258:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:05:28,258:INFO:Cross validation set to False
2024-08-28 11:05:28,258:INFO:Fitting Model
2024-08-28 11:05:28,266:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.
2024-08-28 11:05:28,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:05:28,266:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:05:28,266:INFO:[LightGBM] [Info] Number of data points in the train set: 3298, number of used features: 12
2024-08-28 11:05:28,266:INFO:[LightGBM] [Info] Start training from score 40625.855670
2024-08-28 11:05:28,413:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-28 11:05:28,413:INFO:create_model() successfully completed......................................
2024-08-28 11:05:28,569:INFO:_master_model_container: 22
2024-08-28 11:05:28,569:INFO:_display_container: 4
2024-08-28 11:05:28,573:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-28 11:05:28,573:INFO:finalize_model() successfully completed......................................
2024-08-28 11:05:28,695:INFO:Initializing predict_model()
2024-08-28 11:05:28,695:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000155CFBD0360>)
2024-08-28 11:05:28,695:INFO:Checking exceptions
2024-08-28 11:05:28,695:INFO:Preloading libraries
2024-08-28 11:05:28,697:INFO:Set up data.
2024-08-28 11:05:28,700:INFO:Set up index.
2024-08-28 11:05:28,849:INFO:Initializing evaluate_model()
2024-08-28 11:05:28,849:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-08-28 11:05:28,862:INFO:Initializing plot_model()
2024-08-28 11:05:28,862:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:28,862:INFO:Checking exceptions
2024-08-28 11:05:28,864:INFO:Preloading libraries
2024-08-28 11:05:28,869:INFO:Copying training dataset
2024-08-28 11:05:28,869:INFO:Plot type: pipeline
2024-08-28 11:05:29,010:INFO:Visual Rendered Successfully
2024-08-28 11:05:29,127:INFO:plot_model() successfully completed......................................
2024-08-28 11:05:34,719:INFO:Initializing plot_model()
2024-08-28 11:05:34,719:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:34,719:INFO:Checking exceptions
2024-08-28 11:05:34,722:INFO:Preloading libraries
2024-08-28 11:05:34,728:INFO:Copying training dataset
2024-08-28 11:05:34,728:INFO:Plot type: parameter
2024-08-28 11:05:34,733:INFO:Visual Rendered Successfully
2024-08-28 11:05:34,879:INFO:plot_model() successfully completed......................................
2024-08-28 11:05:36,181:INFO:Initializing plot_model()
2024-08-28 11:05:36,181:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:36,181:INFO:Checking exceptions
2024-08-28 11:05:36,183:INFO:Preloading libraries
2024-08-28 11:05:36,187:INFO:Copying training dataset
2024-08-28 11:05:36,187:INFO:Plot type: pipeline
2024-08-28 11:05:36,268:INFO:Visual Rendered Successfully
2024-08-28 11:05:36,385:INFO:plot_model() successfully completed......................................
2024-08-28 11:05:42,867:INFO:Initializing plot_model()
2024-08-28 11:05:42,868:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:42,868:INFO:Checking exceptions
2024-08-28 11:05:42,870:INFO:Preloading libraries
2024-08-28 11:05:42,876:INFO:Copying training dataset
2024-08-28 11:05:42,876:INFO:Plot type: parameter
2024-08-28 11:05:42,881:INFO:Visual Rendered Successfully
2024-08-28 11:05:43,028:INFO:plot_model() successfully completed......................................
2024-08-28 11:05:46,203:INFO:Initializing plot_model()
2024-08-28 11:05:46,203:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:46,203:INFO:Checking exceptions
2024-08-28 11:05:46,205:INFO:Preloading libraries
2024-08-28 11:05:46,209:INFO:Copying training dataset
2024-08-28 11:05:46,209:INFO:Plot type: residuals
2024-08-28 11:05:46,343:INFO:Fitting Model
2024-08-28 11:05:46,390:INFO:Scoring test/hold-out set
2024-08-28 11:05:46,801:INFO:Visual Rendered Successfully
2024-08-28 11:05:46,914:INFO:plot_model() successfully completed......................................
2024-08-28 11:05:47,358:INFO:Initializing plot_model()
2024-08-28 11:05:47,358:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=tree, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:47,358:INFO:Checking exceptions
2024-08-28 11:05:48,488:INFO:Initializing plot_model()
2024-08-28 11:05:48,488:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:48,488:INFO:Checking exceptions
2024-08-28 11:05:48,490:INFO:Preloading libraries
2024-08-28 11:05:48,495:INFO:Copying training dataset
2024-08-28 11:05:48,495:INFO:Plot type: residuals
2024-08-28 11:05:48,605:INFO:Fitting Model
2024-08-28 11:05:48,651:INFO:Scoring test/hold-out set
2024-08-28 11:05:49,006:INFO:Visual Rendered Successfully
2024-08-28 11:05:49,158:INFO:plot_model() successfully completed......................................
2024-08-28 11:05:54,744:INFO:Initializing plot_model()
2024-08-28 11:05:54,744:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:05:54,744:INFO:Checking exceptions
2024-08-28 11:05:54,746:INFO:Preloading libraries
2024-08-28 11:05:54,750:INFO:Copying training dataset
2024-08-28 11:05:54,750:INFO:Plot type: error
2024-08-28 11:05:54,836:INFO:Fitting Model
2024-08-28 11:05:54,836:INFO:Scoring test/hold-out set
2024-08-28 11:05:55,045:INFO:Visual Rendered Successfully
2024-08-28 11:05:55,164:INFO:plot_model() successfully completed......................................
2024-08-28 11:06:01,885:INFO:Initializing plot_model()
2024-08-28 11:06:01,885:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=cooks, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:06:01,885:INFO:Checking exceptions
2024-08-28 11:06:01,887:INFO:Preloading libraries
2024-08-28 11:06:01,892:INFO:Copying training dataset
2024-08-28 11:06:01,892:INFO:Plot type: cooks
2024-08-28 11:06:01,978:INFO:Fitting Model
2024-08-28 11:06:02,190:INFO:Visual Rendered Successfully
2024-08-28 11:06:02,333:INFO:plot_model() successfully completed......................................
2024-08-28 11:06:05,963:INFO:Initializing plot_model()
2024-08-28 11:06:05,963:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:06:05,963:INFO:Checking exceptions
2024-08-28 11:06:05,966:INFO:Preloading libraries
2024-08-28 11:06:05,969:INFO:Copying training dataset
2024-08-28 11:06:05,970:INFO:Plot type: rfe
2024-08-28 11:06:06,069:INFO:Fitting Model
2024-08-28 11:06:06,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-08-28 11:06:06,082:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,082:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:06,082:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:06,082:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,150:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.
2024-08-28 11:06:06,150:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,150:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:06,150:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:06,150:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,213:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:06:06,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,213:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:06,213:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:06,213:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-08-28 11:06:06,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,283:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:06,283:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:06,283:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,359:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.
2024-08-28 11:06:06,359:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,359:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:06,359:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:06,359:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,436:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.
2024-08-28 11:06:06,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,436:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:06,436:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:06,437:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-08-28 11:06:06,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,494:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:06,494:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:06,494:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.
2024-08-28 11:06:06,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,544:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:06,544:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:06,545:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,594:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.
2024-08-28 11:06:06,594:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,594:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:06,594:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:06,594:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.
2024-08-28 11:06:06,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,649:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:06,649:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:06,649:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,701:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.
2024-08-28 11:06:06,701:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,701:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:06,701:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:06,701:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.
2024-08-28 11:06:06,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,748:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:06,748:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:06,748:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:06,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-08-28 11:06:06,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,797:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:06,797:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:06,797:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:06,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-28 11:06:06,867:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,867:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:06,867:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:06,868:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:06,929:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2024-08-28 11:06:06,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,929:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:06,930:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:06,930:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:06,990:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-08-28 11:06:06,990:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:06,990:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:06,990:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:06,990:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2024-08-28 11:06:07,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,052:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:07,053:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:07,053:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-08-28 11:06:07,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,122:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:07,122:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:07,123:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.
2024-08-28 11:06:07,181:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,181:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:07,181:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:07,181:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2024-08-28 11:06:07,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,237:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:07,237:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:07,237:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.
2024-08-28 11:06:07,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,293:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:07,293:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:07,293:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.
2024-08-28 11:06:07,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,343:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:07,343:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:07,343:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.
2024-08-28 11:06:07,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,389:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:07,389:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:07,389:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,433:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.
2024-08-28 11:06:07,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,434:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:07,434:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:07,434:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:07,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:06:07,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,476:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:07,476:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:07,476:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:07,548:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.
2024-08-28 11:06:07,548:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,548:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:07,548:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:07,548:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:07,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-28 11:06:07,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,612:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:07,612:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:07,612:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:07,714:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.
2024-08-28 11:06:07,714:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,714:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:07,714:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:07,715:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:07,817:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.
2024-08-28 11:06:07,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,817:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:07,817:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:07,817:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:07,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2024-08-28 11:06:07,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:07,904:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:07,904:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:07,904:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:08,001:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.
2024-08-28 11:06:08,001:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,001:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:08,002:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:08,002:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:08,080:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.
2024-08-28 11:06:08,080:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,080:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:08,081:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:08,081:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:08,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.
2024-08-28 11:06:08,140:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,140:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:08,140:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:08,140:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:08,190:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2024-08-28 11:06:08,190:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,190:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:08,190:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:08,191:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:08,238:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.
2024-08-28 11:06:08,238:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,238:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:08,238:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:08,238:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:08,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.
2024-08-28 11:06:08,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,284:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:08,284:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:08,284:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:08,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-08-28 11:06:08,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,341:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:08,341:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:08,342:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,408:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-08-28 11:06:08,408:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,408:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:08,409:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:08,409:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-08-28 11:06:08,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,493:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:08,493:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:08,494:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,577:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-08-28 11:06:08,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,577:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:08,577:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:08,577:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.
2024-08-28 11:06:08,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,645:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:08,645:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:08,645:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,699:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.
2024-08-28 11:06:08,699:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,699:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:08,699:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:08,699:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-08-28 11:06:08,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,754:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:08,754:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:08,754:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.
2024-08-28 11:06:08,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,803:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:08,803:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:08,803:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,858:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.
2024-08-28 11:06:08,858:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,858:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:08,859:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:08,859:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.
2024-08-28 11:06:08,906:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,906:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:08,906:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:08,906:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.
2024-08-28 11:06:08,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,950:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:08,951:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:08,951:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:08,998:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000055 seconds.
2024-08-28 11:06:08,998:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:08,998:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:08,998:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:08,998:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:09,042:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-08-28 11:06:09,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,042:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:09,042:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:09,043:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,105:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-08-28 11:06:09,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,106:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:09,106:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:09,106:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-28 11:06:09,174:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,174:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:09,174:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:09,174:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-08-28 11:06:09,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,278:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:06:09,278:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:09,278:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,357:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.
2024-08-28 11:06:09,357:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,358:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:09,358:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:09,358:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.
2024-08-28 11:06:09,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,423:INFO:[LightGBM] [Info] Total Bins 1540
2024-08-28 11:06:09,423:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:09,423:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.
2024-08-28 11:06:09,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,475:INFO:[LightGBM] [Info] Total Bins 1529
2024-08-28 11:06:09,475:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:09,476:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-08-28 11:06:09,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,528:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:09,528:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:09,528:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,579:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.
2024-08-28 11:06:09,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,580:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:09,580:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:09,580:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.
2024-08-28 11:06:09,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,655:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:09,655:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:09,655:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-08-28 11:06:09,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,713:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:09,714:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:09,714:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.
2024-08-28 11:06:09,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,780:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:09,780:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:09,781:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:09,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-28 11:06:09,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,853:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:09,853:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:09,853:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:09,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2024-08-28 11:06:09,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:09,962:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:09,962:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:09,962:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.
2024-08-28 11:06:10,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,085:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:06:10,085:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:10,085:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-08-28 11:06:10,148:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,148:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:10,149:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:10,149:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2024-08-28 11:06:10,209:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,210:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:10,210:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:10,210:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,270:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.
2024-08-28 11:06:10,270:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,270:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:10,270:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:10,271:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,319:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-08-28 11:06:10,320:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,320:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:10,320:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:10,320:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,375:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-08-28 11:06:10,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,375:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:10,376:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:10,376:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000094 seconds.
2024-08-28 11:06:10,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,424:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:10,424:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:10,424:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.
2024-08-28 11:06:10,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,469:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:10,469:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:10,469:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,522:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.
2024-08-28 11:06:10,522:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,522:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:10,522:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:10,522:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.
2024-08-28 11:06:10,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,587:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:10,587:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:10,587:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:10,651:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-08-28 11:06:10,651:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,651:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:10,651:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:10,651:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:10,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2024-08-28 11:06:10,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,748:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:10,748:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:10,749:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:10,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2024-08-28 11:06:10,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,826:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:10,826:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:10,826:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:10,888:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.
2024-08-28 11:06:10,888:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,888:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:10,889:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:10,889:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:10,940:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-08-28 11:06:10,940:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,941:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:10,941:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:10,941:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:10,996:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-28 11:06:10,996:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:10,996:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:10,996:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:10,997:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:11,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.
2024-08-28 11:06:11,047:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,047:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:11,047:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:11,047:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:11,095:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-08-28 11:06:11,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,095:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:11,095:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:11,095:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:11,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-08-28 11:06:11,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,157:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:11,157:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:11,157:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:11,220:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.
2024-08-28 11:06:11,220:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,220:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:11,220:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:11,220:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:11,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.
2024-08-28 11:06:11,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,296:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:11,296:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:11,297:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:11,358:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.
2024-08-28 11:06:11,358:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,358:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:11,358:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:11,358:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:11,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:06:11,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,438:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:11,438:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:11,438:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:11,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-08-28 11:06:11,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,521:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:11,521:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:11,521:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:11,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:06:11,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,595:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:11,595:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:11,595:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:11,661:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.
2024-08-28 11:06:11,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,662:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:11,662:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:11,662:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:11,720:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-28 11:06:11,720:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,720:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:11,720:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:11,720:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:11,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
2024-08-28 11:06:11,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,802:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:11,802:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:11,802:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:11,885:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.
2024-08-28 11:06:11,885:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,885:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:11,885:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:11,885:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:11,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.
2024-08-28 11:06:11,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:11,955:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:11,955:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:11,955:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:12,033:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-08-28 11:06:12,033:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,034:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:12,034:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:12,034:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:12,090:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.
2024-08-28 11:06:12,090:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,090:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:12,090:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:12,090:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:12,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000061 seconds.
2024-08-28 11:06:12,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,138:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:12,138:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:12,138:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:12,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.
2024-08-28 11:06:12,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,178:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:12,179:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 1
2024-08-28 11:06:12,179:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:12,239:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2024-08-28 11:06:12,239:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,239:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:12,239:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:12,240:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-08-28 11:06:12,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,314:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:12,314:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:12,314:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-08-28 11:06:12,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,381:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:12,381:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:12,381:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-08-28 11:06:12,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,473:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:12,473:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:12,473:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-08-28 11:06:12,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,543:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:12,543:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:12,543:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-08-28 11:06:12,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,601:INFO:[LightGBM] [Info] Total Bins 1288
2024-08-28 11:06:12,601:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:12,601:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,656:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.
2024-08-28 11:06:12,656:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,656:INFO:[LightGBM] [Info] Total Bins 1285
2024-08-28 11:06:12,656:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:12,657:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.
2024-08-28 11:06:12,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,711:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:12,711:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:12,711:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.
2024-08-28 11:06:12,759:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,759:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:12,759:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:12,759:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,813:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.
2024-08-28 11:06:12,813:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,813:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:12,813:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 3
2024-08-28 11:06:12,813:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000071 seconds.
2024-08-28 11:06:12,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,878:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:12,878:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 2
2024-08-28 11:06:12,878:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,933:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.
2024-08-28 11:06:12,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,933:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:12,933:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 1
2024-08-28 11:06:12,933:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:12,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:06:12,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:12,982:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:12,982:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:12,982:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-28 11:06:13,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,064:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:13,064:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:13,064:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:06:13,154:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,154:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:13,155:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:13,155:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2024-08-28 11:06:13,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,224:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:13,224:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:13,224:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,276:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-28 11:06:13,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,276:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:13,276:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:13,277:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-08-28 11:06:13,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,332:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:13,332:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:13,332:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,388:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-08-28 11:06:13,388:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,388:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:13,389:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:13,389:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,441:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.
2024-08-28 11:06:13,441:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,441:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:13,441:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:13,441:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-08-28 11:06:13,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,497:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:13,497:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:13,497:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,545:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-08-28 11:06:13,545:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,545:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:13,545:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 3
2024-08-28 11:06:13,545:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,594:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.
2024-08-28 11:06:13,594:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,594:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:13,594:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 2
2024-08-28 11:06:13,594:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,642:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.
2024-08-28 11:06:13,642:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,642:INFO:[LightGBM] [Info] Total Bins 255
2024-08-28 11:06:13,642:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 1
2024-08-28 11:06:13,643:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:13,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-28 11:06:13,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,692:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:13,692:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:13,693:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:13,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-08-28 11:06:13,778:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,778:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:13,778:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:13,779:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:13,895:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.
2024-08-28 11:06:13,895:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:13,896:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:13,896:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:13,896:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.
2024-08-28 11:06:14,026:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,026:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:14,026:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:14,026:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,127:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.
2024-08-28 11:06:14,127:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,129:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:14,129:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:14,129:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,222:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-08-28 11:06:14,222:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,222:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:14,222:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:14,222:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,312:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-08-28 11:06:14,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,313:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:14,313:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:14,313:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000088 seconds.
2024-08-28 11:06:14,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,384:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:14,384:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:14,384:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000093 seconds.
2024-08-28 11:06:14,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,454:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:14,454:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:14,455:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.
2024-08-28 11:06:14,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,529:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:14,529:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:14,529:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,586:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000057 seconds.
2024-08-28 11:06:14,586:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,587:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:14,587:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:14,587:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:14,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
2024-08-28 11:06:14,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,637:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:14,638:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:14,638:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:14,705:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-08-28 11:06:14,705:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,705:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:14,705:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:14,706:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:14,787:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-08-28 11:06:14,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,788:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:14,788:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:14,788:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:14,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-28 11:06:14,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,856:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:14,857:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:14,857:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:14,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-08-28 11:06:14,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,916:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:14,916:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:14,916:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:14,969:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-08-28 11:06:14,969:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:14,969:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:14,969:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:14,969:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:15,026:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.
2024-08-28 11:06:15,026:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,026:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:15,026:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:15,026:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:15,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.
2024-08-28 11:06:15,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,074:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:15,074:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:15,075:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:15,132:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.
2024-08-28 11:06:15,132:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,132:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:15,133:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:15,133:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:15,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000071 seconds.
2024-08-28 11:06:15,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,178:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:15,178:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:15,178:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:15,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000059 seconds.
2024-08-28 11:06:15,230:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,230:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:15,230:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:15,230:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:15,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-08-28 11:06:15,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,295:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:15,295:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:15,295:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2024-08-28 11:06:15,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,381:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:15,381:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:15,381:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-08-28 11:06:15,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,450:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:15,450:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:15,450:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,514:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:06:15,514:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,514:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:15,514:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:15,514:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-08-28 11:06:15,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,571:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:15,571:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:15,571:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.
2024-08-28 11:06:15,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,623:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:15,623:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:15,623:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-08-28 11:06:15,680:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,680:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:15,680:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:15,680:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.
2024-08-28 11:06:15,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,729:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:15,729:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:15,729:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,787:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.
2024-08-28 11:06:15,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,787:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:15,787:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:15,787:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.
2024-08-28 11:06:15,833:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,834:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:15,834:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:15,834:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.
2024-08-28 11:06:15,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,878:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:15,878:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:15,878:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:15,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-08-28 11:06:15,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,925:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:15,925:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:15,925:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:15,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-08-28 11:06:15,988:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:15,988:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:15,988:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:15,988:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,097:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-08-28 11:06:16,097:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,098:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:16,098:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:16,098:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-08-28 11:06:16,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,224:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:16,224:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:16,224:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-08-28 11:06:16,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,304:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:16,304:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:16,304:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.
2024-08-28 11:06:16,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,379:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:16,380:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:16,380:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-08-28 11:06:16,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,464:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:16,464:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:16,464:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,546:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000094 seconds.
2024-08-28 11:06:16,546:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,546:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:16,546:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:16,546:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-08-28 11:06:16,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,626:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:16,626:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:16,626:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,707:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.
2024-08-28 11:06:16,707:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,707:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:16,708:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:16,708:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000060 seconds.
2024-08-28 11:06:16,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,756:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:16,756:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:16,756:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:16,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-08-28 11:06:16,804:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,804:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:16,804:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:16,804:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:16,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-28 11:06:16,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,873:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:16,873:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:16,873:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:16,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:06:16,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:16,946:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:16,946:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:16,946:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2024-08-28 11:06:17,022:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,022:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:06:17,022:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:17,022:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-08-28 11:06:17,093:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,093:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:17,094:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:17,094:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-08-28 11:06:17,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,164:INFO:[LightGBM] [Info] Total Bins 1540
2024-08-28 11:06:17,164:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:17,164:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,220:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-08-28 11:06:17,220:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,220:INFO:[LightGBM] [Info] Total Bins 1529
2024-08-28 11:06:17,220:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:17,220:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.
2024-08-28 11:06:17,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,271:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:17,271:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:17,272:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,319:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.
2024-08-28 11:06:17,319:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,319:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:17,319:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:17,319:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,375:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.
2024-08-28 11:06:17,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,375:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:17,376:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:17,376:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000073 seconds.
2024-08-28 11:06:17,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,430:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:17,430:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:17,430:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:17,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2024-08-28 11:06:17,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,490:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:17,490:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:17,491:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:17,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-08-28 11:06:17,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,581:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:17,581:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:17,581:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:17,657:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-08-28 11:06:17,657:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,657:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:06:17,657:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:17,658:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:17,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.
2024-08-28 11:06:17,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,729:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:17,729:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:17,730:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:17,812:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:06:17,812:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,812:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:17,812:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:17,812:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:17,877:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-08-28 11:06:17,877:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,877:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:17,878:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:17,878:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:17,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.
2024-08-28 11:06:17,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:17,942:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:17,942:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:17,942:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:18,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.
2024-08-28 11:06:18,011:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,011:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:18,012:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:18,012:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:18,067:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.
2024-08-28 11:06:18,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,067:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:18,067:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:18,068:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:18,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.
2024-08-28 11:06:18,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,118:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:18,118:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:18,118:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:18,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.
2024-08-28 11:06:18,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,164:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:18,165:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:18,165:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:18,210:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2024-08-28 11:06:18,210:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,210:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:18,210:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:18,210:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.
2024-08-28 11:06:18,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,283:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:18,283:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:18,283:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:18,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,350:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:18,350:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:18,350:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,444:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2024-08-28 11:06:18,444:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,444:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:18,445:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:18,445:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-08-28 11:06:18,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,518:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:18,518:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:18,518:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,591:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.
2024-08-28 11:06:18,591:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,591:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:18,591:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:18,591:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,675:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.
2024-08-28 11:06:18,675:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,675:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:18,675:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:18,676:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,750:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-08-28 11:06:18,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,750:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:18,750:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:18,750:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.
2024-08-28 11:06:18,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,821:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:18,821:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:18,821:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,890:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.
2024-08-28 11:06:18,890:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,890:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:18,890:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:18,891:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000056 seconds.
2024-08-28 11:06:18,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,946:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:18,946:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:18,946:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:18,997:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-08-28 11:06:18,997:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:18,997:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:18,997:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:18,997:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,062:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.
2024-08-28 11:06:19,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,063:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:19,063:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:19,063:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-28 11:06:19,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,141:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:19,141:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:19,141:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,206:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-08-28 11:06:19,206:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,206:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:19,206:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:19,206:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,261:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.
2024-08-28 11:06:19,261:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,261:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:19,261:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:19,261:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-08-28 11:06:19,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,343:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:19,344:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:19,344:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,417:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.
2024-08-28 11:06:19,417:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,417:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:19,417:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:19,418:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.
2024-08-28 11:06:19,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,469:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:19,469:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:19,470:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.
2024-08-28 11:06:19,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,534:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:19,534:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:19,534:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,611:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.
2024-08-28 11:06:19,611:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,611:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:19,613:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:19,613:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.
2024-08-28 11:06:19,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,691:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:19,691:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 2
2024-08-28 11:06:19,691:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:19,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-08-28 11:06:19,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,780:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:19,780:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:19,780:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:19,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-28 11:06:19,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:19,893:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:19,893:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:19,893:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,001:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-08-28 11:06:20,001:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,001:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:20,001:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:20,001:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,114:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2024-08-28 11:06:20,114:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,114:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:20,114:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:20,114:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,206:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.
2024-08-28 11:06:20,207:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,207:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:20,207:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:20,207:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2024-08-28 11:06:20,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,311:INFO:[LightGBM] [Info] Total Bins 1288
2024-08-28 11:06:20,311:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:20,312:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,402:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.
2024-08-28 11:06:20,402:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,402:INFO:[LightGBM] [Info] Total Bins 1285
2024-08-28 11:06:20,403:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:20,403:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.
2024-08-28 11:06:20,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,532:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:20,532:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:20,532:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.
2024-08-28 11:06:20,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,670:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:20,670:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:20,670:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,768:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.
2024-08-28 11:06:20,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,769:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:20,769:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 3
2024-08-28 11:06:20,769:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,870:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.
2024-08-28 11:06:20,870:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,870:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:20,870:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 2
2024-08-28 11:06:20,871:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:20,955:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-08-28 11:06:20,955:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:20,956:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:20,956:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:20,956:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,071:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.
2024-08-28 11:06:21,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,071:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:21,071:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:21,071:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,192:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-28 11:06:21,192:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,192:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:21,192:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:21,192:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,328:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.
2024-08-28 11:06:21,328:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,328:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:21,328:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:21,329:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-08-28 11:06:21,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,428:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:21,428:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:21,428:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.
2024-08-28 11:06:21,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,504:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:21,505:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:21,505:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-08-28 11:06:21,578:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,578:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:21,578:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:21,578:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,666:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-08-28 11:06:21,666:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,666:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:21,667:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:21,667:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.
2024-08-28 11:06:21,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,743:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:21,743:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:21,743:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,835:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:21,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,836:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:21,836:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 3
2024-08-28 11:06:21,836:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000056 seconds.
2024-08-28 11:06:21,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,920:INFO:[LightGBM] [Info] Total Bins 510
2024-08-28 11:06:21,920:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 2
2024-08-28 11:06:21,921:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:21,992:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
2024-08-28 11:06:21,992:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:21,992:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:21,992:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:21,993:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-28 11:06:22,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,090:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:22,090:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:22,090:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,188:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:06:22,188:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,188:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:22,189:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:22,189:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-08-28 11:06:22,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,313:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:22,313:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:22,313:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,407:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-08-28 11:06:22,407:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,407:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:22,407:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:22,409:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-08-28 11:06:22,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,494:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:22,494:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:22,494:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.
2024-08-28 11:06:22,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,595:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:22,595:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:22,595:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2024-08-28 11:06:22,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,717:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:22,717:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:22,717:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-08-28 11:06:22,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,802:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:22,802:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:22,803:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000070 seconds.
2024-08-28 11:06:22,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,884:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:22,884:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:22,884:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:22,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2024-08-28 11:06:22,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:22,981:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:22,981:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:22,981:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,077:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-08-28 11:06:23,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,077:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:23,077:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:23,077:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-28 11:06:23,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,156:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:23,156:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:23,157:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.
2024-08-28 11:06:23,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,211:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:23,211:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:23,212:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,264:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.
2024-08-28 11:06:23,264:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,264:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:23,264:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:23,264:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,353:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-08-28 11:06:23,353:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,353:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:23,353:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:23,353:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-28 11:06:23,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,414:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:23,415:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:23,415:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.
2024-08-28 11:06:23,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,494:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:23,494:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:23,496:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
2024-08-28 11:06:23,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,569:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:23,570:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:23,570:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,624:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.
2024-08-28 11:06:23,624:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,624:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:23,624:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:23,624:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:23,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
2024-08-28 11:06:23,678:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,678:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:23,678:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:23,678:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:23,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.
2024-08-28 11:06:23,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,760:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:23,761:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:23,761:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:23,856:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2024-08-28 11:06:23,856:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,856:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:23,857:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:23,857:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:23,937:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-08-28 11:06:23,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,937:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:23,938:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:23,938:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:23,995:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:06:23,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:23,996:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:23,996:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:23,996:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:24,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.
2024-08-28 11:06:24,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,058:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:24,059:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:24,059:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:24,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.
2024-08-28 11:06:24,130:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,130:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:24,131:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:24,131:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:24,201:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.
2024-08-28 11:06:24,201:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,201:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:24,201:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:24,202:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:24,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
2024-08-28 11:06:24,281:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,281:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:24,281:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:24,281:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:24,337:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.
2024-08-28 11:06:24,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,338:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:24,338:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:24,338:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:24,395:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-08-28 11:06:24,395:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,395:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:24,395:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:24,395:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:24,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-08-28 11:06:24,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,488:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:24,488:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:24,489:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:24,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2024-08-28 11:06:24,576:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,576:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:24,576:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:24,576:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:24,683:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:06:24,683:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,683:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:24,683:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:24,683:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:24,775:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-28 11:06:24,775:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,775:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:24,776:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:24,776:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:24,869:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-28 11:06:24,869:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,869:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:24,869:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:24,869:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:24,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:24,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:24,970:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:24,970:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:24,971:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:25,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-08-28 11:06:25,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,036:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:25,036:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:25,037:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:25,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.
2024-08-28 11:06:25,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,085:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:25,085:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:25,086:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:25,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.
2024-08-28 11:06:25,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,134:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:25,134:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:25,134:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:25,187:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
2024-08-28 11:06:25,187:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,187:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:25,187:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:25,188:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,260:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:06:25,261:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,261:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:25,261:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:25,261:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,326:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-08-28 11:06:25,326:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,326:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:25,326:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:25,326:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:25,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,392:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:06:25,392:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:25,392:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:06:25,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,454:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:25,454:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:25,455:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.
2024-08-28 11:06:25,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,532:INFO:[LightGBM] [Info] Total Bins 1540
2024-08-28 11:06:25,532:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:25,533:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,608:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2024-08-28 11:06:25,608:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,608:INFO:[LightGBM] [Info] Total Bins 1529
2024-08-28 11:06:25,608:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:25,608:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,664:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.
2024-08-28 11:06:25,665:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,665:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:25,665:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:25,665:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.
2024-08-28 11:06:25,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,722:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:25,722:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:25,722:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,768:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.
2024-08-28 11:06:25,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,769:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:25,769:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:25,769:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:25,831:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-28 11:06:25,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,831:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:25,832:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:25,832:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:25,922:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
2024-08-28 11:06:25,922:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,922:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:25,922:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:25,922:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:25,989:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2024-08-28 11:06:25,989:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:25,989:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:06:25,989:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:25,990:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-08-28 11:06:26,056:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,056:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:26,056:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:26,056:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,120:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.
2024-08-28 11:06:26,120:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,120:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:26,120:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:26,120:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-28 11:06:26,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,186:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:26,186:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:26,186:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-08-28 11:06:26,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,246:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:26,247:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:26,247:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.
2024-08-28 11:06:26,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,298:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:26,298:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:26,299:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000122 seconds.
2024-08-28 11:06:26,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,367:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:26,367:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:26,367:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,415:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000075 seconds.
2024-08-28 11:06:26,415:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,415:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:26,415:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:26,416:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:26,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.
2024-08-28 11:06:26,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,465:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:26,465:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:26,465:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:26,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-08-28 11:06:26,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,529:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:26,529:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:26,529:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:26,594:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-08-28 11:06:26,594:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,594:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:26,594:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:26,594:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:26,668:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-08-28 11:06:26,668:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,668:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:26,668:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:26,668:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:26,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.
2024-08-28 11:06:26,741:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,741:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:26,741:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:26,741:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:26,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-08-28 11:06:26,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,825:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:26,825:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:26,826:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:26,898:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-28 11:06:26,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,899:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:26,899:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:26,899:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:26,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.
2024-08-28 11:06:26,973:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:26,973:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:26,973:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:26,973:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:27,048:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.
2024-08-28 11:06:27,048:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,048:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:27,048:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:27,049:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:27,117:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000073 seconds.
2024-08-28 11:06:27,117:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,117:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:27,117:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:27,117:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:27,168:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2024-08-28 11:06:27,168:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,169:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:27,169:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:27,169:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,238:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.
2024-08-28 11:06:27,238:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,238:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:27,238:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:27,238:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,305:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-28 11:06:27,305:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,305:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:27,305:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:27,305:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-08-28 11:06:27,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,373:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:27,373:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:27,373:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,435:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.
2024-08-28 11:06:27,436:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,436:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:27,436:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:27,436:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-08-28 11:06:27,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,532:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:27,532:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:27,532:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
2024-08-28 11:06:27,611:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,611:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:27,611:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:27,611:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,674:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.
2024-08-28 11:06:27,674:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,675:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:27,675:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:27,675:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000094 seconds.
2024-08-28 11:06:27,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,748:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:27,748:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:27,748:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.
2024-08-28 11:06:27,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,822:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:27,822:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 3
2024-08-28 11:06:27,822:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:27,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2024-08-28 11:06:27,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,872:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:27,872:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:27,872:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:27,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-08-28 11:06:27,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:27,943:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:27,943:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:27,943:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,007:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:28,007:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,007:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:28,008:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:28,008:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-28 11:06:28,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,071:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:28,071:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:28,071:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.
2024-08-28 11:06:28,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,127:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:28,127:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:28,127:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2024-08-28 11:06:28,193:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,193:INFO:[LightGBM] [Info] Total Bins 1288
2024-08-28 11:06:28,193:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:28,194:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.
2024-08-28 11:06:28,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,257:INFO:[LightGBM] [Info] Total Bins 1285
2024-08-28 11:06:28,257:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:28,258:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.
2024-08-28 11:06:28,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,314:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:28,314:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:28,314:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,370:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.
2024-08-28 11:06:28,370:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,370:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:28,370:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:28,370:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,419:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.
2024-08-28 11:06:28,419:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,419:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:28,419:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 3
2024-08-28 11:06:28,419:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:28,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2024-08-28 11:06:28,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,479:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:28,479:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:28,479:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:28,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-28 11:06:28,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,562:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:28,562:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:28,562:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:28,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-08-28 11:06:28,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,643:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:28,644:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:28,644:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:28,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-08-28 11:06:28,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,717:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:28,717:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:28,717:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:28,778:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-08-28 11:06:28,778:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,778:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:28,778:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:28,778:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:28,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-08-28 11:06:28,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,861:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:28,861:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:28,862:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:28,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2024-08-28 11:06:28,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:28,942:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:28,942:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:28,942:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:29,018:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.
2024-08-28 11:06:29,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,019:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:29,019:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:29,019:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:29,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:06:29,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,101:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:29,101:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:29,101:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:29,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.
2024-08-28 11:06:29,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,167:INFO:[LightGBM] [Info] Total Bins 765
2024-08-28 11:06:29,167:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 3
2024-08-28 11:06:29,167:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:29,222:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
2024-08-28 11:06:29,222:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,222:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:29,222:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:29,222:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,288:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-08-28 11:06:29,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,288:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:29,288:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:29,288:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2024-08-28 11:06:29,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,356:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:29,356:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:29,356:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-08-28 11:06:29,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,450:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:29,450:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:29,451:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,505:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-28 11:06:29,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,505:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:29,505:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:29,506:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.
2024-08-28 11:06:29,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,560:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:29,560:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:29,560:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:29,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,617:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:29,617:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:29,617:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,677:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.
2024-08-28 11:06:29,677:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,677:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:29,677:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:29,677:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000081 seconds.
2024-08-28 11:06:29,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,738:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:29,738:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:29,740:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:29,801:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:06:29,801:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,802:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:29,802:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:29,802:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:29,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-28 11:06:29,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,872:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:29,872:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:29,873:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:29,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.
2024-08-28 11:06:29,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:29,950:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:29,950:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:29,950:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:30,038:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-08-28 11:06:30,038:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,038:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:30,038:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:30,038:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:30,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2024-08-28 11:06:30,093:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,095:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:30,095:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:30,095:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:30,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
2024-08-28 11:06:30,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,158:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:30,158:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:30,158:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:30,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.
2024-08-28 11:06:30,212:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,212:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:30,212:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:30,212:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:30,262:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.
2024-08-28 11:06:30,262:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,262:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:30,262:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:30,262:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:30,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.
2024-08-28 11:06:30,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,311:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:30,312:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:30,312:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:30,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.
2024-08-28 11:06:30,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,366:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:30,366:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:30,366:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:30,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-08-28 11:06:30,431:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,431:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:30,431:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:30,431:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:30,497:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:30,497:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,497:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:30,497:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:30,497:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:30,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.
2024-08-28 11:06:30,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,587:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:30,588:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:30,588:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:30,679:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.
2024-08-28 11:06:30,679:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,679:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:30,679:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:30,679:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:30,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:30,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,822:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:30,822:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:30,823:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:30,926:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.
2024-08-28 11:06:30,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:30,927:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:30,927:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:30,927:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:31,065:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.
2024-08-28 11:06:31,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,065:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:31,065:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:31,065:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:31,201:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.
2024-08-28 11:06:31,201:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,201:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:31,201:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:31,201:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:31,289:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.
2024-08-28 11:06:31,290:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:31,290:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:31,290:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:31,290:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:31,290:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,393:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.
2024-08-28 11:06:31,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,394:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:31,394:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:31,394:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,519:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-08-28 11:06:31,519:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,519:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:31,519:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:31,519:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-08-28 11:06:31,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,601:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:31,601:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:31,601:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,690:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-08-28 11:06:31,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,691:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:31,691:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:31,691:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.
2024-08-28 11:06:31,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,772:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:31,772:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:31,772:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.
2024-08-28 11:06:31,848:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,848:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:31,848:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:31,848:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2024-08-28 11:06:31,901:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,901:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:31,901:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:31,901:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:31,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.
2024-08-28 11:06:31,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:31,956:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:31,956:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:31,956:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:32,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.
2024-08-28 11:06:32,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,013:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:32,013:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:32,013:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,104:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-28 11:06:32,104:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,104:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:32,105:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:32,105:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,219:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-08-28 11:06:32,219:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,219:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:32,219:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:32,219:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-08-28 11:06:32,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,397:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:06:32,398:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:32,398:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,566:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-28 11:06:32,566:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,566:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:32,567:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:32,567:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-08-28 11:06:32,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,685:INFO:[LightGBM] [Info] Total Bins 1540
2024-08-28 11:06:32,685:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:32,685:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2024-08-28 11:06:32,784:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,785:INFO:[LightGBM] [Info] Total Bins 1529
2024-08-28 11:06:32,785:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:32,785:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,888:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.
2024-08-28 11:06:32,888:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,888:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:32,888:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:32,889:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:32,991:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000120 seconds.
2024-08-28 11:06:32,992:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:32,992:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:32,992:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:32,992:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:33,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.
2024-08-28 11:06:33,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,094:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:33,094:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:33,095:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,247:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
2024-08-28 11:06:33,247:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,248:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:33,248:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:33,248:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,378:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-28 11:06:33,378:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,378:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:06:33,378:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:33,378:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,455:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:06:33,456:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,456:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:33,456:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:33,456:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-08-28 11:06:33,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,528:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:33,528:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:33,528:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,606:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-08-28 11:06:33,606:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,606:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:33,607:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:33,607:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-08-28 11:06:33,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,669:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:33,669:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:33,669:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.
2024-08-28 11:06:33,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,727:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:33,727:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:33,727:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.
2024-08-28 11:06:33,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,782:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:33,782:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:33,783:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:33,848:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-28 11:06:33,848:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,848:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:33,848:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:33,848:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:33,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-08-28 11:06:33,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:33,945:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:33,945:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:33,946:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2024-08-28 11:06:34,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,058:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:34,060:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:34,060:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,193:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:06:34,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,194:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:34,194:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:34,194:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2024-08-28 11:06:34,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,295:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:34,295:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:34,295:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,410:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:34,410:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,410:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:34,410:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:34,410:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,499:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-08-28 11:06:34,499:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,499:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:34,499:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:34,500:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2024-08-28 11:06:34,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,559:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:34,559:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:34,559:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
2024-08-28 11:06:34,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,645:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:34,645:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:34,645:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:34,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2024-08-28 11:06:34,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,765:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:34,765:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:34,765:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:34,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2024-08-28 11:06:34,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:34,925:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:34,926:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:34,926:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2024-08-28 11:06:35,090:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,090:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:35,090:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:35,090:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
2024-08-28 11:06:35,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,254:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:35,254:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:35,254:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2024-08-28 11:06:35,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,377:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:35,377:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:35,377:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:06:35,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,498:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:35,498:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:35,498:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,609:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-08-28 11:06:35,609:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,609:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:35,609:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:35,610:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.
2024-08-28 11:06:35,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,722:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:35,722:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:35,722:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.
2024-08-28 11:06:35,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,810:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:35,810:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 4
2024-08-28 11:06:35,811:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:35,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
2024-08-28 11:06:35,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:35,919:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:35,920:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:35,920:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:36,077:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-08-28 11:06:36,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:36,077:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:36,077:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:36,078:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:36,235:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2024-08-28 11:06:36,236:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:36,236:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:36,236:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:36,236:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:36,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-08-28 11:06:36,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:36,397:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:36,397:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:36,397:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:36,531:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:06:36,531:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:36,531:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:36,531:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:36,531:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:36,674:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:06:36,674:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:36,674:INFO:[LightGBM] [Info] Total Bins 1288
2024-08-28 11:06:36,674:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:36,674:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:36,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2024-08-28 11:06:36,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:36,797:INFO:[LightGBM] [Info] Total Bins 1285
2024-08-28 11:06:36,797:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:36,797:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:36,911:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-08-28 11:06:36,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:36,912:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:36,912:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:36,912:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:37,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.
2024-08-28 11:06:37,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:37,046:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:37,046:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:37,047:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:37,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-08-28 11:06:37,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:37,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:37,176:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:37,176:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:37,176:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:37,416:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.
2024-08-28 11:06:37,416:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:37,416:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:37,416:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:37,416:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:37,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-08-28 11:06:37,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:37,645:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:37,645:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:37,646:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:37,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-28 11:06:37,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:37,826:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:37,826:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:37,827:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:37,958:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:06:37,958:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:37,958:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:37,959:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:37,959:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:38,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2024-08-28 11:06:38,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:38,096:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:38,096:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:38,096:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:38,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-08-28 11:06:38,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:38,226:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:38,226:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:38,227:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:38,421:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.
2024-08-28 11:06:38,421:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:38,421:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:38,421:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:38,421:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:38,421:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:38,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032065 seconds.
2024-08-28 11:06:38,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:38,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:38,833:INFO:[LightGBM] [Info] Total Bins 1020
2024-08-28 11:06:38,843:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 4
2024-08-28 11:06:38,845:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:39,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2024-08-28 11:06:39,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:39,347:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:39,347:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:39,347:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:39,595:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2024-08-28 11:06:39,595:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:39,595:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:39,595:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:39,596:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:39,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-08-28 11:06:39,786:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:39,786:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:39,787:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:39,787:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:39,951:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-08-28 11:06:39,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:39,951:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:39,951:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:39,955:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:40,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.
2024-08-28 11:06:40,137:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,137:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:40,137:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:40,137:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:40,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.
2024-08-28 11:06:40,247:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,247:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:40,247:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:40,247:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:40,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-08-28 11:06:40,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,351:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:40,351:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:40,351:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:40,428:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.
2024-08-28 11:06:40,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,428:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:40,428:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:40,428:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:40,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-08-28 11:06:40,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,515:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:40,515:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:40,515:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:40,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-28 11:06:40,635:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,635:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:40,635:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:40,635:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:40,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-08-28 11:06:40,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,740:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:40,740:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:40,740:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:40,815:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2024-08-28 11:06:40,815:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,816:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:40,816:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:40,816:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:40,892:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2024-08-28 11:06:40,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,892:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:40,893:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:40,893:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:40,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.
2024-08-28 11:06:40,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:40,981:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:40,981:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:40,981:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:41,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.
2024-08-28 11:06:41,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,081:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:41,082:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:41,082:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:41,200:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.
2024-08-28 11:06:41,200:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,200:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:41,200:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:41,201:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:41,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
2024-08-28 11:06:41,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,297:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:41,297:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:41,297:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:41,416:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-08-28 11:06:41,416:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,416:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:41,416:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:41,416:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:41,527:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:41,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,528:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:41,528:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:41,528:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:41,641:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000177 seconds.
2024-08-28 11:06:41,641:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,641:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:41,641:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:41,642:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:41,727:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000174 seconds.
2024-08-28 11:06:41,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,727:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:41,728:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:41,728:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:41,815:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-08-28 11:06:41,815:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,815:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:41,816:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:41,816:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:41,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.
2024-08-28 11:06:41,888:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,888:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:41,888:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:41,888:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:41,960:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-08-28 11:06:41,960:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:41,960:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:41,960:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:41,961:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:42,041:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-08-28 11:06:42,042:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,042:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:42,042:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:42,042:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2024-08-28 11:06:42,137:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,137:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:42,137:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:42,138:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
2024-08-28 11:06:42,266:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,266:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:42,266:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:42,266:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-28 11:06:42,390:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,391:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:42,391:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:42,391:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,481:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000178 seconds.
2024-08-28 11:06:42,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,481:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:42,481:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:42,481:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2024-08-28 11:06:42,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,568:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:42,568:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:42,569:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:06:42,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,650:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:42,650:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:42,651:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.
2024-08-28 11:06:42,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,728:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:42,728:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:42,729:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:42,809:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-08-28 11:06:42,809:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,810:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:42,810:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:42,810:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:42,909:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-08-28 11:06:42,909:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:42,909:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:42,909:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:42,909:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:43,018:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2024-08-28 11:06:43,018:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,018:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:43,018:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:43,019:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:43,201:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000275 seconds.
2024-08-28 11:06:43,201:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,201:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:06:43,201:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:43,202:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:43,360:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2024-08-28 11:06:43,361:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,361:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:43,361:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:43,361:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:43,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2024-08-28 11:06:43,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,490:INFO:[LightGBM] [Info] Total Bins 1540
2024-08-28 11:06:43,491:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:43,491:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:43,564:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.
2024-08-28 11:06:43,564:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,564:INFO:[LightGBM] [Info] Total Bins 1529
2024-08-28 11:06:43,564:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:43,565:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:43,646:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2024-08-28 11:06:43,646:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,646:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:43,646:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:43,646:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:43,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.
2024-08-28 11:06:43,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,735:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:43,735:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:43,735:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:43,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-08-28 11:06:43,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,873:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:43,873:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:43,873:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:43,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-28 11:06:43,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:43,980:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:06:43,980:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:43,981:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:44,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.
2024-08-28 11:06:44,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,069:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:44,069:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:44,069:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:44,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-08-28 11:06:44,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,161:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:44,161:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:44,161:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:44,248:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2024-08-28 11:06:44,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,249:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:44,249:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:44,250:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:44,334:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2024-08-28 11:06:44,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,334:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:44,337:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:44,338:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:44,424:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2024-08-28 11:06:44,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,425:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:44,425:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:44,425:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:44,508:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-08-28 11:06:44,508:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,508:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:44,508:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:44,508:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:44,613:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-28 11:06:44,613:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,613:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:44,613:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:44,613:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:44,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-08-28 11:06:44,714:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,714:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:44,714:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:44,714:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:44,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2024-08-28 11:06:44,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,797:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:44,797:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:44,797:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:44,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.
2024-08-28 11:06:44,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,859:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:44,859:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:44,859:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:44,920:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-08-28 11:06:44,920:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,920:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:44,920:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:44,920:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:44,985:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.
2024-08-28 11:06:44,985:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:44,985:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:44,985:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:44,985:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:45,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.
2024-08-28 11:06:45,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,050:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:45,050:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:45,050:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:45,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-08-28 11:06:45,137:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,137:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:45,138:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:45,138:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,250:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.
2024-08-28 11:06:45,250:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,250:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:45,250:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:45,250:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2024-08-28 11:06:45,398:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,398:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:45,398:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:45,398:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,522:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-28 11:06:45,522:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,523:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:45,523:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:45,523:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-28 11:06:45,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,599:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:45,601:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:45,601:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-08-28 11:06:45,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,708:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:45,708:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:45,709:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.
2024-08-28 11:06:45,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,763:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:45,763:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:45,764:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.
2024-08-28 11:06:45,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,820:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:45,820:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 5
2024-08-28 11:06:45,820:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:45,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-28 11:06:45,879:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,879:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:45,879:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:45,879:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:45,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
2024-08-28 11:06:45,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:45,950:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:45,951:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:45,951:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:46,037:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.
2024-08-28 11:06:46,037:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,038:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:46,038:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:46,038:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:46,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2024-08-28 11:06:46,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,113:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:46,113:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:46,113:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:46,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2024-08-28 11:06:46,173:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,173:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:46,173:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:46,174:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:46,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-08-28 11:06:46,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,231:INFO:[LightGBM] [Info] Total Bins 1288
2024-08-28 11:06:46,232:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:46,232:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:46,290:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.
2024-08-28 11:06:46,290:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,290:INFO:[LightGBM] [Info] Total Bins 1285
2024-08-28 11:06:46,290:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:46,290:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:46,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.
2024-08-28 11:06:46,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,347:INFO:[LightGBM] [Info] Total Bins 1274
2024-08-28 11:06:46,347:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:46,347:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:46,403:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2024-08-28 11:06:46,403:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,403:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:46,403:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:46,403:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:06:46,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,472:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:46,472:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:46,472:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:06:46,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,543:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:46,544:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:46,544:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,613:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2024-08-28 11:06:46,613:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,613:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:46,613:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:46,613:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,672:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2024-08-28 11:06:46,672:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,672:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:46,672:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:46,672:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:46,731:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,731:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:46,731:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:46,731:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.
2024-08-28 11:06:46,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,790:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:46,790:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:46,790:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,844:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.
2024-08-28 11:06:46,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,844:INFO:[LightGBM] [Info] Total Bins 1275
2024-08-28 11:06:46,844:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 5
2024-08-28 11:06:46,844:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:46,902:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:06:46,902:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,902:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:46,902:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:46,902:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:46,975:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-28 11:06:46,975:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:46,975:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:46,975:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:46,976:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:47,061:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2024-08-28 11:06:47,062:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,062:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:47,062:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:47,062:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:47,198:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-28 11:06:47,198:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,198:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:47,198:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:47,199:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:47,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:06:47,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,283:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:47,283:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:47,284:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:47,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:47,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,367:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:47,367:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:47,368:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:47,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.
2024-08-28 11:06:47,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,427:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:47,427:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:47,427:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:47,499:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:06:47,499:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,499:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:47,499:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:47,500:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:47,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-28 11:06:47,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,580:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:47,580:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:47,580:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:47,677:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-28 11:06:47,677:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,677:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:47,677:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:47,677:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:47,741:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.
2024-08-28 11:06:47,741:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,741:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:47,741:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:47,741:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:47,799:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-28 11:06:47,799:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,800:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:47,800:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:47,800:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:47,874:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.
2024-08-28 11:06:47,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,875:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:47,875:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:47,875:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:47,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.
2024-08-28 11:06:47,948:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:47,949:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:47,949:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:47,949:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:48,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.
2024-08-28 11:06:48,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,015:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:48,015:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:48,015:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:48,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.
2024-08-28 11:06:48,098:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,098:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:48,098:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:48,099:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:48,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:48,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,182:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:48,182:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:48,182:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:48,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-08-28 11:06:48,251:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,251:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:48,251:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:48,251:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:48,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-08-28 11:06:48,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,308:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:48,309:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:48,309:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:48,368:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-28 11:06:48,368:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,368:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:48,368:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:48,368:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:48,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.
2024-08-28 11:06:48,425:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,425:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:48,425:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:48,425:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:48,496:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.
2024-08-28 11:06:48,496:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,496:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:48,496:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:48,496:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:48,567:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-28 11:06:48,567:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,567:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:48,568:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:48,568:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:48,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:06:48,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,644:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:48,644:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:48,644:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:48,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2024-08-28 11:06:48,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,756:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:48,756:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:48,756:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:48,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.
2024-08-28 11:06:48,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,818:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:48,818:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:48,818:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:48,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.
2024-08-28 11:06:48,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,875:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:48,875:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:48,875:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:48,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.
2024-08-28 11:06:48,929:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,929:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:48,929:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:48,929:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:48,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.
2024-08-28 11:06:48,988:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:48,988:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:48,988:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:48,988:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:49,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-08-28 11:06:49,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,084:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:49,084:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:49,084:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:49,202:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-08-28 11:06:49,202:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,202:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:49,203:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:49,203:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:49,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-08-28 11:06:49,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,315:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:06:49,315:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:49,315:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:49,395:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-28 11:06:49,395:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,395:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:49,395:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:49,395:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:49,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-08-28 11:06:49,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,454:INFO:[LightGBM] [Info] Total Bins 1540
2024-08-28 11:06:49,455:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:49,455:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:49,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.
2024-08-28 11:06:49,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,509:INFO:[LightGBM] [Info] Total Bins 1529
2024-08-28 11:06:49,509:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:49,510:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:49,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-08-28 11:06:49,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,569:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:49,569:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:49,569:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:49,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-08-28 11:06:49,672:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,672:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:49,672:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:49,672:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:49,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:06:49,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,744:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:06:49,744:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:49,745:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:49,804:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:06:49,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,805:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:49,805:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:49,805:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:49,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2024-08-28 11:06:49,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,871:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:49,871:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:49,871:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:49,933:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.
2024-08-28 11:06:49,933:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,933:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:49,933:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:49,933:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:49,996:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.
2024-08-28 11:06:49,996:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:49,996:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:49,996:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:49,997:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:50,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
2024-08-28 11:06:50,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,064:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:50,064:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:50,064:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:50,166:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-08-28 11:06:50,166:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,166:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:50,166:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:50,167:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:50,271:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-28 11:06:50,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,271:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:50,271:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:50,271:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:50,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2024-08-28 11:06:50,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,376:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:50,376:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:50,376:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:50,441:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-28 11:06:50,441:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,441:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:50,442:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:50,442:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:50,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.
2024-08-28 11:06:50,513:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,514:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:50,514:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:50,514:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:50,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2024-08-28 11:06:50,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,582:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:50,582:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:50,582:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:50,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-08-28 11:06:50,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,645:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:50,645:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:50,645:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:50,716:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-08-28 11:06:50,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,716:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:50,716:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:50,716:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:50,788:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:06:50,788:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,788:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:50,788:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:50,788:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:50,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-08-28 11:06:50,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,857:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:50,857:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:50,857:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:50,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.
2024-08-28 11:06:50,914:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,914:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:50,914:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:50,914:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:50,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.
2024-08-28 11:06:50,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:50,978:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:50,978:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:50,979:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:51,049:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.
2024-08-28 11:06:51,049:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,049:INFO:[LightGBM] [Info] Total Bins 1530
2024-08-28 11:06:51,049:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 6
2024-08-28 11:06:51,049:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:51,127:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.
2024-08-28 11:06:51,127:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,127:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:51,127:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:51,127:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:51,234:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-28 11:06:51,234:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,234:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:51,234:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:51,234:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:51,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-08-28 11:06:51,343:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,343:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:51,343:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:51,343:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:51,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:51,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,467:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:51,467:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:51,468:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:51,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2024-08-28 11:06:51,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,540:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:51,540:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:51,541:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:51,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.
2024-08-28 11:06:51,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,601:INFO:[LightGBM] [Info] Total Bins 1288
2024-08-28 11:06:51,601:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:51,602:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:51,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.
2024-08-28 11:06:51,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,662:INFO:[LightGBM] [Info] Total Bins 1285
2024-08-28 11:06:51,662:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:51,662:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:51,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.
2024-08-28 11:06:51,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,722:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:51,722:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:51,722:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:51,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-28 11:06:51,793:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,793:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:51,794:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:51,794:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:51,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-28 11:06:51,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,865:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:51,865:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:51,865:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:51,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.
2024-08-28 11:06:51,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:51,954:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:51,954:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:51,955:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:52,047:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-08-28 11:06:52,047:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,047:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:52,047:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:52,047:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:52,105:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-08-28 11:06:52,105:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,105:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:52,105:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:52,106:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:52,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.
2024-08-28 11:06:52,164:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:52,164:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:52,164:INFO:[LightGBM] [Info] Total Bins 1286
2024-08-28 11:06:52,164:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 6
2024-08-28 11:06:52,164:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:52,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2024-08-28 11:06:52,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,237:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:52,238:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:52,238:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:52,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-08-28 11:06:52,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,342:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:52,342:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:52,342:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:52,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-08-28 11:06:52,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,420:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:52,420:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:52,420:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:52,511:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.
2024-08-28 11:06:52,512:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,512:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:52,512:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:52,512:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:52,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.
2024-08-28 11:06:52,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,571:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:52,571:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:52,571:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:52,634:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
2024-08-28 11:06:52,634:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,634:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:52,634:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:52,634:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:52,695:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.
2024-08-28 11:06:52,695:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,695:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:52,695:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:52,695:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:52,767:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-28 11:06:52,767:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,767:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:52,767:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:52,767:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:52,839:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-08-28 11:06:52,839:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,839:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:52,839:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:52,839:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:52,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.
2024-08-28 11:06:52,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,900:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:52,900:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:52,900:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:52,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-28 11:06:52,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:52,982:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:52,983:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:52,983:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:53,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.
2024-08-28 11:06:53,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,078:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:53,078:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:53,078:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:53,168:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000278 seconds.
2024-08-28 11:06:53,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,169:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:53,169:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:53,169:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:53,335:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-08-28 11:06:53,336:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,336:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:53,336:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:53,336:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:53,472:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.
2024-08-28 11:06:53,472:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,472:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:53,472:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:53,472:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:53,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-28 11:06:53,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,610:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:53,610:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:53,611:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:53,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-28 11:06:53,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,713:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:53,713:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:53,714:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:53,800:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.
2024-08-28 11:06:53,800:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,800:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:53,800:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:53,800:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:53,886:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2024-08-28 11:06:53,886:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:53,886:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:53,886:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:53,886:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:54,014:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000221 seconds.
2024-08-28 11:06:54,014:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:54,014:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:54,014:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:54,014:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:54,015:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:54,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-08-28 11:06:54,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,123:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:54,123:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:54,123:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:54,230:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000188 seconds.
2024-08-28 11:06:54,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,231:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:54,231:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:54,231:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:54,319:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-28 11:06:54,319:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,320:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:54,320:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:54,320:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:54,400:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-08-28 11:06:54,400:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,400:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:54,400:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:54,400:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:54,489:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.
2024-08-28 11:06:54,489:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,489:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:54,489:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:54,489:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:54,620:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.
2024-08-28 11:06:54,620:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,620:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:54,620:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:54,620:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:54,732:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-08-28 11:06:54,732:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,732:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:54,732:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:54,732:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:54,840:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.
2024-08-28 11:06:54,840:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,840:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:06:54,840:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:54,840:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:54,926:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:54,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:54,926:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:54,926:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:54,926:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:55,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.
2024-08-28 11:06:55,013:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:55,013:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:55,013:INFO:[LightGBM] [Info] Total Bins 1540
2024-08-28 11:06:55,013:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:55,013:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:06:55,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.
2024-08-28 11:06:55,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,113:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:55,113:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:55,113:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:55,241:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2024-08-28 11:06:55,241:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,241:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:55,241:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:55,242:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:55,388:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.
2024-08-28 11:06:55,388:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,389:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:06:55,389:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:55,389:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:55,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-08-28 11:06:55,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,489:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:55,489:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:55,489:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:55,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-08-28 11:06:55,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,582:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:55,582:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:55,582:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:55,674:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.
2024-08-28 11:06:55,674:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,675:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:55,675:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:55,675:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:06:55,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2024-08-28 11:06:55,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,763:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:55,763:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:55,763:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:55,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2024-08-28 11:06:55,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:55,893:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:55,893:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:55,893:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:56,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-28 11:06:56,035:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,035:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:56,035:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:56,035:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:56,163:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-08-28 11:06:56,163:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,163:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:56,164:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:56,164:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:56,268:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2024-08-28 11:06:56,268:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,268:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:56,268:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:56,268:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:56,367:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2024-08-28 11:06:56,367:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,367:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:56,367:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:56,367:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:06:56,464:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.
2024-08-28 11:06:56,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,464:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:56,464:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:56,464:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:56,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-28 11:06:56,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,579:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:56,579:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:56,579:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:56,687:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:06:56,687:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,687:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:56,687:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:56,687:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:56,793:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:56,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,794:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:56,794:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:56,794:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:56,868:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-28 11:06:56,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,868:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:56,868:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:56,868:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:56,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.
2024-08-28 11:06:56,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:56,950:INFO:[LightGBM] [Info] Total Bins 1541
2024-08-28 11:06:56,950:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 7
2024-08-28 11:06:56,950:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:06:57,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-28 11:06:57,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,013:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:57,013:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:57,013:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:57,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-28 11:06:57,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,083:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:57,083:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:57,083:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:57,155:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.
2024-08-28 11:06:57,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,155:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:57,155:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:57,155:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:57,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.
2024-08-28 11:06:57,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,223:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:57,223:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:57,223:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:57,315:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.
2024-08-28 11:06:57,315:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,315:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:57,316:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:57,316:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:57,437:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2024-08-28 11:06:57,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,438:INFO:[LightGBM] [Info] Total Bins 1288
2024-08-28 11:06:57,438:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:57,438:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:06:57,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2024-08-28 11:06:57,552:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,552:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:57,552:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:06:57,552:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:57,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:06:57,631:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,631:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:57,631:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:06:57,631:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:57,700:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:06:57,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,700:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:57,700:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:06:57,700:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:57,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2024-08-28 11:06:57,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,769:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:57,769:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:06:57,770:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:57,858:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-28 11:06:57,858:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,858:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:57,859:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:06:57,859:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:57,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.
2024-08-28 11:06:57,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:57,947:INFO:[LightGBM] [Info] Total Bins 1289
2024-08-28 11:06:57,947:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 7
2024-08-28 11:06:57,947:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:06:58,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-08-28 11:06:58,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,030:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:58,030:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:58,030:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:58,102:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:06:58,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,103:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:58,103:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:58,103:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:58,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000285 seconds.
2024-08-28 11:06:58,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,197:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:58,197:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:58,198:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:58,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.
2024-08-28 11:06:58,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,297:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:58,297:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:58,297:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:58,370:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.
2024-08-28 11:06:58,370:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,370:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:58,370:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:58,371:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:06:58,432:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-08-28 11:06:58,432:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,432:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:58,433:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:58,433:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:58,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-08-28 11:06:58,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,584:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:58,584:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:58,584:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:58,681:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-08-28 11:06:58,682:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,682:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:06:58,682:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:58,682:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:58,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000514 seconds.
2024-08-28 11:06:58,758:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,758:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:58,758:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:58,758:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:58,846:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.
2024-08-28 11:06:58,846:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:06:58,846:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:06:58,847:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:58,847:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:58,847:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:06:58,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.
2024-08-28 11:06:58,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:58,956:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:06:58,957:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:58,957:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:59,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-08-28 11:06:59,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,059:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:06:59,059:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:59,060:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:59,175:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-28 11:06:59,175:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,175:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:06:59,175:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:59,175:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:59,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-08-28 11:06:59,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,283:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:06:59,283:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:59,283:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:59,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2024-08-28 11:06:59,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,385:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:06:59,385:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:59,386:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:06:59,492:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-28 11:06:59,492:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,492:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:06:59,492:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:59,494:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:59,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-08-28 11:06:59,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,593:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:59,593:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:06:59,593:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:59,689:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.
2024-08-28 11:06:59,689:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,689:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:06:59,689:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:06:59,690:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:59,798:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:06:59,798:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,798:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:06:59,798:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:06:59,799:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:59,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.
2024-08-28 11:06:59,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,857:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:06:59,857:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:06:59,857:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:06:59,930:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-08-28 11:06:59,930:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:06:59,930:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:06:59,931:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:06:59,931:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:00,065:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
2024-08-28 11:07:00,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,065:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:07:00,066:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:00,066:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:00,218:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2024-08-28 11:07:00,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,218:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:00,219:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:00,219:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:00,312:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:07:00,312:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,312:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:07:00,312:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:00,312:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:00,452:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.
2024-08-28 11:07:00,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,452:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:07:00,452:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:07:00,453:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:00,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:07:00,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,517:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:00,518:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:00,518:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:00,590:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-08-28 11:07:00,590:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,590:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:00,591:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:00,591:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:00,712:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.
2024-08-28 11:07:00,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,713:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:07:00,713:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:00,713:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:00,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2024-08-28 11:07:00,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,790:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:00,790:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:00,791:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:00,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-08-28 11:07:00,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,853:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:07:00,853:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:07:00,853:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:00,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:07:00,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,915:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:00,915:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:00,915:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:00,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:07:00,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:00,986:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:00,986:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:00,986:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:01,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.
2024-08-28 11:07:01,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,085:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:01,085:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:01,085:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:01,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:07:01,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,168:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:01,168:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:01,168:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:01,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.
2024-08-28 11:07:01,253:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,253:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:07:01,253:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:07:01,253:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:01,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2024-08-28 11:07:01,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,340:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:01,340:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:01,340:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:01,456:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.
2024-08-28 11:07:01,457:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,457:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:01,457:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:01,457:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:01,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-28 11:07:01,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,574:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:01,574:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:01,574:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:01,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-08-28 11:07:01,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,658:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:01,658:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:01,658:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:01,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2024-08-28 11:07:01,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,721:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:07:01,721:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 8
2024-08-28 11:07:01,721:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:01,810:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2024-08-28 11:07:01,810:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,810:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:01,810:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:01,810:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:01,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.
2024-08-28 11:07:01,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:01,894:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:01,894:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:01,895:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:01,972:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.
2024-08-28 11:07:01,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:07:01,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:07:01,972:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:01,972:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:07:01,972:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:02,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:07:02,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,084:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:02,084:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:07:02,084:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:02,148:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000162 seconds.
2024-08-28 11:07:02,149:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,149:INFO:[LightGBM] [Info] Total Bins 1543
2024-08-28 11:07:02,149:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:07:02,149:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:02,212:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-08-28 11:07:02,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,213:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:02,213:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:02,213:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:02,288:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.
2024-08-28 11:07:02,288:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:07:02,288:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:07:02,288:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:02,288:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:02,288:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:02,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.
2024-08-28 11:07:02,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,369:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:02,369:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:07:02,370:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:02,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.
2024-08-28 11:07:02,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,450:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:02,450:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:07:02,451:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:02,508:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:07:02,508:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,508:INFO:[LightGBM] [Info] Total Bins 1544
2024-08-28 11:07:02,508:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 8
2024-08-28 11:07:02,509:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:02,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.
2024-08-28 11:07:02,570:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,571:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:02,571:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:02,571:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:02,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-28 11:07:02,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,649:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:02,649:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:02,649:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:02,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-08-28 11:07:02,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,724:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:02,724:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:02,724:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:02,800:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.
2024-08-28 11:07:02,800:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,800:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:02,800:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:02,800:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:02,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.
2024-08-28 11:07:02,866:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,866:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:02,866:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:02,866:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:02,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
2024-08-28 11:07:02,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:02,942:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:02,942:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:02,942:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:03,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.
2024-08-28 11:07:03,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,021:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:07:03,021:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:03,021:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:03,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:07:03,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,084:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:03,084:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:03,084:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:03,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.
2024-08-28 11:07:03,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,153:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:03,153:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:03,153:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:03,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.
2024-08-28 11:07:03,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,226:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:03,226:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:03,226:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:03,311:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-08-28 11:07:03,311:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,311:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:03,311:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:03,311:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:03,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-08-28 11:07:03,483:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,484:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:03,484:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:03,484:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:03,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.
2024-08-28 11:07:03,575:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,576:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:03,576:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:03,576:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:03,672:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000210 seconds.
2024-08-28 11:07:03,673:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,673:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:03,673:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:03,673:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:03,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.
2024-08-28 11:07:03,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,748:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:03,749:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:03,749:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:03,823:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.
2024-08-28 11:07:03,823:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,824:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:03,824:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:03,824:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:03,888:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-08-28 11:07:03,888:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,889:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:03,889:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:03,889:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:03,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.
2024-08-28 11:07:03,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:03,964:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:07:03,964:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:03,964:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:04,036:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.
2024-08-28 11:07:04,036:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,036:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:04,036:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:04,037:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:04,113:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.
2024-08-28 11:07:04,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,113:INFO:[LightGBM] [Info] Total Bins 1797
2024-08-28 11:07:04,113:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:04,114:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:04,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2024-08-28 11:07:04,181:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,181:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:04,181:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:04,182:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:04,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.
2024-08-28 11:07:04,281:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,281:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:04,281:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:04,281:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:04,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:07:04,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,365:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:07:04,365:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:04,365:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:04,425:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.
2024-08-28 11:07:04,425:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,425:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:04,425:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:04,426:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:04,496:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-08-28 11:07:04,496:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,496:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:04,498:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:04,498:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:04,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.
2024-08-28 11:07:04,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,569:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:04,570:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:04,570:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:04,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.
2024-08-28 11:07:04,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,645:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:04,645:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:04,645:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:04,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.
2024-08-28 11:07:04,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,721:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:04,721:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:04,721:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:04,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.
2024-08-28 11:07:04,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,783:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:04,783:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:04,783:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:04,854:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.
2024-08-28 11:07:04,854:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,855:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:04,855:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:04,855:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:04,930:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-28 11:07:04,930:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:04,931:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:04,931:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:04,931:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:05,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000206 seconds.
2024-08-28 11:07:05,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,018:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:05,018:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 9
2024-08-28 11:07:05,018:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:05,108:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2024-08-28 11:07:05,108:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,108:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:05,108:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:05,108:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:05,181:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-28 11:07:05,181:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,181:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:05,181:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:05,182:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:05,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-08-28 11:07:05,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,253:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:05,253:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:07:05,253:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:05,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-28 11:07:05,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,339:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:05,339:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:07:05,340:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:05,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-08-28 11:07:05,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,484:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:05,484:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:05,486:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:05,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-08-28 11:07:05,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,703:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:05,704:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:05,704:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:05,831:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.
2024-08-28 11:07:05,831:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:05,831:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:05,831:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:07:05,832:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:06,058:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.
2024-08-28 11:07:06,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:07:06,058:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:07:06,058:INFO:[LightGBM] [Info] Total Bins 1798
2024-08-28 11:07:06,058:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 9
2024-08-28 11:07:06,059:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:06,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-08-28 11:07:06,209:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:06,210:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:06,210:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:06,210:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:06,363:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2024-08-28 11:07:06,363:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:06,363:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:06,363:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:06,363:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:06,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2024-08-28 11:07:06,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:06,474:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:06,474:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:06,474:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:06,601:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2024-08-28 11:07:06,601:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:06,601:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:06,601:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:06,601:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:06,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-08-28 11:07:06,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:06,744:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:06,744:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:06,744:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:06,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2024-08-28 11:07:06,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:06,826:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:07:06,826:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:06,826:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:06,909:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.
2024-08-28 11:07:06,909:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:06,910:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:06,910:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:06,910:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:07,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.
2024-08-28 11:07:07,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:07,055:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:07,055:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:07,055:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:07,179:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-08-28 11:07:07,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:07,180:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:07,180:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:07,180:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:07,343:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2024-08-28 11:07:07,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:07,344:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:07,344:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:07,344:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:07,505:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-08-28 11:07:07,505:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:07,506:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:07,506:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:07,506:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:07,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:07:07,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:07,628:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:07,628:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:07,629:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:07,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.
2024-08-28 11:07:07,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:07,747:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:07,747:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:07,748:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:07,913:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.
2024-08-28 11:07:07,913:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:07,913:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:07:07,913:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:07,914:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:08,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.
2024-08-28 11:07:08,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,015:INFO:[LightGBM] [Info] Total Bins 1799
2024-08-28 11:07:08,015:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:08,015:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:08,108:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.
2024-08-28 11:07:08,108:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,108:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:08,108:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:08,109:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:08,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:07:08,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,284:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:08,284:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:08,284:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:08,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:07:08,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,464:INFO:[LightGBM] [Info] Total Bins 1802
2024-08-28 11:07:08,464:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:08,464:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:08,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:07:08,575:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,575:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:08,575:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:08,575:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:08,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2024-08-28 11:07:08,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,704:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:08,705:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:08,705:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:08,790:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.
2024-08-28 11:07:08,790:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:07:08,790:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:07:08,790:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:08,790:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:08,790:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:08,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:07:08,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,872:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:08,872:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:08,872:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:08,942:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-08-28 11:07:08,942:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:08,943:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:08,943:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:08,943:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:09,025:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.
2024-08-28 11:07:09,025:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,025:INFO:[LightGBM] [Info] Total Bins 1801
2024-08-28 11:07:09,025:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 10
2024-08-28 11:07:09,025:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:09,104:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000259 seconds.
2024-08-28 11:07:09,104:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,104:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:09,104:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:09,105:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:09,183:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:07:09,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,183:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:09,183:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:09,183:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:09,260:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000198 seconds.
2024-08-28 11:07:09,262:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,262:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:09,262:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:07:09,262:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:09,338:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000276 seconds.
2024-08-28 11:07:09,338:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,338:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:09,338:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:09,338:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:09,454:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.
2024-08-28 11:07:09,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,455:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:09,455:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:09,455:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:09,572:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2024-08-28 11:07:09,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,572:INFO:[LightGBM] [Info] Total Bins 1800
2024-08-28 11:07:09,572:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 10
2024-08-28 11:07:09,572:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:09,669:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2024-08-28 11:07:09,669:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,669:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:09,669:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:09,670:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:09,749:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.
2024-08-28 11:07:09,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,749:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:09,749:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:09,749:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:09,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
2024-08-28 11:07:09,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,844:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:09,844:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:09,844:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:09,954:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-28 11:07:09,954:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:09,954:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:09,954:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:09,954:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:10,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.
2024-08-28 11:07:10,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,044:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:10,044:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:10,044:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:10,132:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000268 seconds.
2024-08-28 11:07:10,133:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,133:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:10,133:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:10,133:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:10,241:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2024-08-28 11:07:10,241:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,241:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:10,241:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:10,241:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:10,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.
2024-08-28 11:07:10,316:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,318:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:10,318:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:10,318:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:10,431:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.
2024-08-28 11:07:10,431:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,431:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:10,431:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:10,431:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:10,516:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
2024-08-28 11:07:10,516:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,516:INFO:[LightGBM] [Info] Total Bins 1803
2024-08-28 11:07:10,517:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:10,517:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:10,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000260 seconds.
2024-08-28 11:07:10,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,599:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:10,599:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:10,599:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:10,693:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-28 11:07:10,693:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,693:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:10,693:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:10,693:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:10,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.
2024-08-28 11:07:10,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,787:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:10,787:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:10,787:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:10,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.
2024-08-28 11:07:10,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,871:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:10,871:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:10,871:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:10,951:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2024-08-28 11:07:10,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:10,951:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:10,951:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:10,951:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:11,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-28 11:07:11,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,027:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:11,027:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 11
2024-08-28 11:07:11,028:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:11,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.
2024-08-28 11:07:11,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,106:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:11,106:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:11,107:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:11,188:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-28 11:07:11,188:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,188:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:11,188:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:11,188:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:11,263:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2024-08-28 11:07:11,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,263:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:11,263:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:11,263:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:11,334:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.
2024-08-28 11:07:11,335:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,335:INFO:[LightGBM] [Info] Total Bins 1804
2024-08-28 11:07:11,335:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 11
2024-08-28 11:07:11,335:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:11,419:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000249 seconds.
2024-08-28 11:07:11,419:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,419:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:11,419:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:11,419:INFO:[LightGBM] [Info] Start training from score 40777.934521
2024-08-28 11:07:11,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000274 seconds.
2024-08-28 11:07:11,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,544:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:11,544:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:11,544:INFO:[LightGBM] [Info] Start training from score 40638.286471
2024-08-28 11:07:11,678:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.
2024-08-28 11:07:11,680:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,680:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:11,680:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:11,680:INFO:[LightGBM] [Info] Start training from score 40599.344728
2024-08-28 11:07:11,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
2024-08-28 11:07:11,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,763:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:11,763:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:11,764:INFO:[LightGBM] [Info] Start training from score 40948.823303
2024-08-28 11:07:11,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.
2024-08-28 11:07:11,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,852:INFO:[LightGBM] [Info] Total Bins 1805
2024-08-28 11:07:11,852:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:11,852:INFO:[LightGBM] [Info] Start training from score 40911.085219
2024-08-28 11:07:11,941:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.
2024-08-28 11:07:11,941:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:11,941:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:11,941:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:11,941:INFO:[LightGBM] [Info] Start training from score 40859.311507
2024-08-28 11:07:12,024:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.
2024-08-28 11:07:12,024:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:12,025:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:12,025:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:12,025:INFO:[LightGBM] [Info] Start training from score 40794.476168
2024-08-28 11:07:12,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.
2024-08-28 11:07:12,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:12,101:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:12,102:INFO:[LightGBM] [Info] Number of data points in the train set: 2077, number of used features: 12
2024-08-28 11:07:12,102:INFO:[LightGBM] [Info] Start training from score 40806.454983
2024-08-28 11:07:12,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000215 seconds.
2024-08-28 11:07:12,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-08-28 11:07:12,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-08-28 11:07:12,190:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:12,190:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:12,190:INFO:[LightGBM] [Info] Start training from score 40951.203080
2024-08-28 11:07:12,273:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2024-08-28 11:07:12,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:12,273:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:12,273:INFO:[LightGBM] [Info] Number of data points in the train set: 2078, number of used features: 12
2024-08-28 11:07:12,273:INFO:[LightGBM] [Info] Start training from score 40745.151107
2024-08-28 11:07:12,368:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
2024-08-28 11:07:12,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:12,369:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:12,369:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:07:12,369:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:07:12,648:INFO:Visual Rendered Successfully
2024-08-28 11:07:12,780:INFO:plot_model() successfully completed......................................
2024-08-28 11:07:12,822:INFO:PyCaret RegressionExperiment
2024-08-28 11:07:12,822:INFO:Logging name: reg-default-name
2024-08-28 11:07:12,822:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-28 11:07:12,822:INFO:version 3.3.2
2024-08-28 11:07:12,822:INFO:Initializing setup()
2024-08-28 11:07:12,822:INFO:self.USI: 17ac
2024-08-28 11:07:12,822:INFO:self._variable_keys: {'data', 'html_param', 'pipeline', '_ml_usecase', 'y', 'X_test', 'exp_name_log', 'gpu_param', 'X_train', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'fold_generator', 'seed', 'USI', 'memory', 'fold_groups_param', 'idx', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'y_train', 'target_param'}
2024-08-28 11:07:12,822:INFO:Checking environment
2024-08-28 11:07:12,822:INFO:python_version: 3.11.9
2024-08-28 11:07:12,822:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 11:07:12,822:INFO:machine: AMD64
2024-08-28 11:07:12,822:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 11:07:12,828:INFO:Memory: svmem(total=16867028992, available=3561041920, percent=78.9, used=13305987072, free=3561041920)
2024-08-28 11:07:12,828:INFO:Physical Core: 6
2024-08-28 11:07:12,828:INFO:Logical Core: 12
2024-08-28 11:07:12,828:INFO:Checking libraries
2024-08-28 11:07:12,828:INFO:System:
2024-08-28 11:07:12,828:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 11:07:12,828:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 11:07:12,828:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 11:07:12,828:INFO:PyCaret required dependencies:
2024-08-28 11:07:12,828:INFO:                 pip: 23.2.1
2024-08-28 11:07:12,828:INFO:          setuptools: 67.8.0
2024-08-28 11:07:12,828:INFO:             pycaret: 3.3.2
2024-08-28 11:07:12,828:INFO:             IPython: 8.14.0
2024-08-28 11:07:12,828:INFO:          ipywidgets: 8.1.5
2024-08-28 11:07:12,829:INFO:                tqdm: 4.66.5
2024-08-28 11:07:12,829:INFO:               numpy: 1.24.3
2024-08-28 11:07:12,829:INFO:              pandas: 2.0.3
2024-08-28 11:07:12,829:INFO:              jinja2: 3.1.4
2024-08-28 11:07:12,829:INFO:               scipy: 1.10.1
2024-08-28 11:07:12,829:INFO:              joblib: 1.2.0
2024-08-28 11:07:12,829:INFO:             sklearn: 1.4.2
2024-08-28 11:07:12,829:INFO:                pyod: 2.0.1
2024-08-28 11:07:12,829:INFO:            imblearn: 0.12.3
2024-08-28 11:07:12,829:INFO:   category_encoders: 2.6.3
2024-08-28 11:07:12,829:INFO:            lightgbm: 4.5.0
2024-08-28 11:07:12,829:INFO:               numba: 0.60.0
2024-08-28 11:07:12,829:INFO:            requests: 2.32.3
2024-08-28 11:07:12,829:INFO:          matplotlib: 3.7.1
2024-08-28 11:07:12,829:INFO:          scikitplot: 0.3.7
2024-08-28 11:07:12,829:INFO:         yellowbrick: 1.5
2024-08-28 11:07:12,829:INFO:              plotly: 5.16.1
2024-08-28 11:07:12,829:INFO:    plotly-resampler: Not installed
2024-08-28 11:07:12,829:INFO:             kaleido: 0.2.1
2024-08-28 11:07:12,829:INFO:           schemdraw: 0.15
2024-08-28 11:07:12,829:INFO:         statsmodels: 0.14.2
2024-08-28 11:07:12,829:INFO:              sktime: 0.26.0
2024-08-28 11:07:12,829:INFO:               tbats: 1.1.3
2024-08-28 11:07:12,829:INFO:            pmdarima: 2.0.4
2024-08-28 11:07:12,829:INFO:              psutil: 5.9.0
2024-08-28 11:07:12,829:INFO:          markupsafe: 2.1.3
2024-08-28 11:07:12,829:INFO:             pickle5: Not installed
2024-08-28 11:07:12,829:INFO:         cloudpickle: 3.0.0
2024-08-28 11:07:12,829:INFO:         deprecation: 2.1.0
2024-08-28 11:07:12,829:INFO:              xxhash: 3.5.0
2024-08-28 11:07:12,829:INFO:           wurlitzer: Not installed
2024-08-28 11:07:12,829:INFO:PyCaret optional dependencies:
2024-08-28 11:07:12,829:INFO:                shap: Not installed
2024-08-28 11:07:12,829:INFO:           interpret: Not installed
2024-08-28 11:07:12,829:INFO:                umap: Not installed
2024-08-28 11:07:12,829:INFO:     ydata_profiling: Not installed
2024-08-28 11:07:12,830:INFO:  explainerdashboard: Not installed
2024-08-28 11:07:12,830:INFO:             autoviz: Not installed
2024-08-28 11:07:12,830:INFO:           fairlearn: Not installed
2024-08-28 11:07:12,830:INFO:          deepchecks: Not installed
2024-08-28 11:07:12,830:INFO:             xgboost: 2.0.2
2024-08-28 11:07:12,830:INFO:            catboost: Not installed
2024-08-28 11:07:12,830:INFO:              kmodes: Not installed
2024-08-28 11:07:12,830:INFO:             mlxtend: Not installed
2024-08-28 11:07:12,830:INFO:       statsforecast: Not installed
2024-08-28 11:07:12,830:INFO:        tune_sklearn: Not installed
2024-08-28 11:07:12,830:INFO:                 ray: Not installed
2024-08-28 11:07:12,830:INFO:            hyperopt: Not installed
2024-08-28 11:07:12,830:INFO:              optuna: Not installed
2024-08-28 11:07:12,830:INFO:               skopt: Not installed
2024-08-28 11:07:12,830:INFO:              mlflow: Not installed
2024-08-28 11:07:12,830:INFO:              gradio: 4.41.0
2024-08-28 11:07:12,830:INFO:             fastapi: 0.112.1
2024-08-28 11:07:12,830:INFO:             uvicorn: 0.30.6
2024-08-28 11:07:12,830:INFO:              m2cgen: Not installed
2024-08-28 11:07:12,830:INFO:           evidently: Not installed
2024-08-28 11:07:12,830:INFO:               fugue: Not installed
2024-08-28 11:07:12,830:INFO:           streamlit: Not installed
2024-08-28 11:07:12,830:INFO:             prophet: Not installed
2024-08-28 11:07:12,830:INFO:None
2024-08-28 11:07:12,830:INFO:Set up data.
2024-08-28 11:07:12,834:INFO:Set up folding strategy.
2024-08-28 11:07:12,834:INFO:Set up train/test split.
2024-08-28 11:07:12,838:INFO:Set up index.
2024-08-28 11:07:12,838:INFO:Assigning column types.
2024-08-28 11:07:12,842:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-28 11:07:12,842:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,851:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,937:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:12,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:12,939:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,943:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,947:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:07:12,993:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,028:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,030:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-28 11:07:13,033:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,037:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,084:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,120:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,126:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,130:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,213:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,215:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-28 11:07:13,222:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,269:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,305:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,315:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,364:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,401:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,404:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-28 11:07:13,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,494:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,591:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,593:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-28 11:07:13,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,685:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:07:13,781:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,784:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-28 11:07:13,876:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,968:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:13,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:13,971:INFO:Preparing preprocessing pipeline...
2024-08-28 11:07:13,971:INFO:Set up simple imputation.
2024-08-28 11:07:13,988:INFO:Finished creating preprocessing pipeline.
2024-08-28 11:07:13,990:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-08-28 11:07:13,990:INFO:Creating final display dataframe.
2024-08-28 11:07:14,042:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               age
2                   Target type        Regression
3           Original data shape        (3298, 13)
4        Transformed data shape        (3298, 13)
5   Transformed train set shape        (2308, 13)
6    Transformed test set shape         (990, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              17ac
2024-08-28 11:07:14,153:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:14,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:14,249:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:07:14,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:07:14,252:INFO:setup() successfully completed in 1.43s...............
2024-08-28 11:07:14,252:INFO:Initializing compare_models()
2024-08-28 11:07:14,252:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-08-28 11:07:14,252:INFO:Checking exceptions
2024-08-28 11:07:14,254:INFO:Preparing display monitor
2024-08-28 11:07:14,270:INFO:Initializing Linear Regression
2024-08-28 11:07:14,270:INFO:Total runtime is 0.0 minutes
2024-08-28 11:07:14,273:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:14,275:INFO:Initializing create_model()
2024-08-28 11:07:14,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:14,275:INFO:Checking exceptions
2024-08-28 11:07:14,275:INFO:Importing libraries
2024-08-28 11:07:14,275:INFO:Copying training dataset
2024-08-28 11:07:14,281:INFO:Defining folds
2024-08-28 11:07:14,281:INFO:Declaring metric variables
2024-08-28 11:07:14,284:INFO:Importing untrained model
2024-08-28 11:07:14,286:INFO:Linear Regression Imported successfully
2024-08-28 11:07:14,293:INFO:Starting cross validation
2024-08-28 11:07:14,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:14,359:INFO:Calculating mean and std
2024-08-28 11:07:14,359:INFO:Creating metrics dataframe
2024-08-28 11:07:14,361:INFO:Uploading results into container
2024-08-28 11:07:14,362:INFO:Uploading model into container now
2024-08-28 11:07:14,362:INFO:_master_model_container: 1
2024-08-28 11:07:14,362:INFO:_display_container: 2
2024-08-28 11:07:14,362:INFO:LinearRegression(n_jobs=-1)
2024-08-28 11:07:14,362:INFO:create_model() successfully completed......................................
2024-08-28 11:07:14,482:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:14,482:INFO:Creating metrics dataframe
2024-08-28 11:07:14,488:INFO:Initializing Lasso Regression
2024-08-28 11:07:14,488:INFO:Total runtime is 0.003628087043762207 minutes
2024-08-28 11:07:14,491:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:14,492:INFO:Initializing create_model()
2024-08-28 11:07:14,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:14,492:INFO:Checking exceptions
2024-08-28 11:07:14,492:INFO:Importing libraries
2024-08-28 11:07:14,492:INFO:Copying training dataset
2024-08-28 11:07:14,496:INFO:Defining folds
2024-08-28 11:07:14,496:INFO:Declaring metric variables
2024-08-28 11:07:14,498:INFO:Importing untrained model
2024-08-28 11:07:14,501:INFO:Lasso Regression Imported successfully
2024-08-28 11:07:14,506:INFO:Starting cross validation
2024-08-28 11:07:14,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:14,566:INFO:Calculating mean and std
2024-08-28 11:07:14,567:INFO:Creating metrics dataframe
2024-08-28 11:07:14,568:INFO:Uploading results into container
2024-08-28 11:07:14,568:INFO:Uploading model into container now
2024-08-28 11:07:14,569:INFO:_master_model_container: 2
2024-08-28 11:07:14,569:INFO:_display_container: 2
2024-08-28 11:07:14,569:INFO:Lasso(random_state=123)
2024-08-28 11:07:14,569:INFO:create_model() successfully completed......................................
2024-08-28 11:07:14,691:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:14,691:INFO:Creating metrics dataframe
2024-08-28 11:07:14,698:INFO:Initializing Ridge Regression
2024-08-28 11:07:14,698:INFO:Total runtime is 0.007125627994537353 minutes
2024-08-28 11:07:14,701:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:14,701:INFO:Initializing create_model()
2024-08-28 11:07:14,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:14,701:INFO:Checking exceptions
2024-08-28 11:07:14,701:INFO:Importing libraries
2024-08-28 11:07:14,701:INFO:Copying training dataset
2024-08-28 11:07:14,705:INFO:Defining folds
2024-08-28 11:07:14,705:INFO:Declaring metric variables
2024-08-28 11:07:14,708:INFO:Importing untrained model
2024-08-28 11:07:14,711:INFO:Ridge Regression Imported successfully
2024-08-28 11:07:14,717:INFO:Starting cross validation
2024-08-28 11:07:14,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:14,780:INFO:Calculating mean and std
2024-08-28 11:07:14,781:INFO:Creating metrics dataframe
2024-08-28 11:07:14,782:INFO:Uploading results into container
2024-08-28 11:07:14,782:INFO:Uploading model into container now
2024-08-28 11:07:14,782:INFO:_master_model_container: 3
2024-08-28 11:07:14,782:INFO:_display_container: 2
2024-08-28 11:07:14,783:INFO:Ridge(random_state=123)
2024-08-28 11:07:14,783:INFO:create_model() successfully completed......................................
2024-08-28 11:07:14,900:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:14,900:INFO:Creating metrics dataframe
2024-08-28 11:07:14,907:INFO:Initializing Elastic Net
2024-08-28 11:07:14,907:INFO:Total runtime is 0.010612086455027262 minutes
2024-08-28 11:07:14,910:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:14,910:INFO:Initializing create_model()
2024-08-28 11:07:14,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:14,910:INFO:Checking exceptions
2024-08-28 11:07:14,910:INFO:Importing libraries
2024-08-28 11:07:14,910:INFO:Copying training dataset
2024-08-28 11:07:14,914:INFO:Defining folds
2024-08-28 11:07:14,914:INFO:Declaring metric variables
2024-08-28 11:07:14,917:INFO:Importing untrained model
2024-08-28 11:07:14,920:INFO:Elastic Net Imported successfully
2024-08-28 11:07:14,931:INFO:Starting cross validation
2024-08-28 11:07:14,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:15,008:INFO:Calculating mean and std
2024-08-28 11:07:15,008:INFO:Creating metrics dataframe
2024-08-28 11:07:15,010:INFO:Uploading results into container
2024-08-28 11:07:15,010:INFO:Uploading model into container now
2024-08-28 11:07:15,010:INFO:_master_model_container: 4
2024-08-28 11:07:15,010:INFO:_display_container: 2
2024-08-28 11:07:15,011:INFO:ElasticNet(random_state=123)
2024-08-28 11:07:15,011:INFO:create_model() successfully completed......................................
2024-08-28 11:07:15,130:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:15,130:INFO:Creating metrics dataframe
2024-08-28 11:07:15,137:INFO:Initializing Least Angle Regression
2024-08-28 11:07:15,137:INFO:Total runtime is 0.014441259702046712 minutes
2024-08-28 11:07:15,140:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:15,140:INFO:Initializing create_model()
2024-08-28 11:07:15,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:15,140:INFO:Checking exceptions
2024-08-28 11:07:15,140:INFO:Importing libraries
2024-08-28 11:07:15,140:INFO:Copying training dataset
2024-08-28 11:07:15,145:INFO:Defining folds
2024-08-28 11:07:15,145:INFO:Declaring metric variables
2024-08-28 11:07:15,148:INFO:Importing untrained model
2024-08-28 11:07:15,151:INFO:Least Angle Regression Imported successfully
2024-08-28 11:07:15,155:INFO:Starting cross validation
2024-08-28 11:07:15,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:15,218:INFO:Calculating mean and std
2024-08-28 11:07:15,218:INFO:Creating metrics dataframe
2024-08-28 11:07:15,220:INFO:Uploading results into container
2024-08-28 11:07:15,220:INFO:Uploading model into container now
2024-08-28 11:07:15,220:INFO:_master_model_container: 5
2024-08-28 11:07:15,220:INFO:_display_container: 2
2024-08-28 11:07:15,220:INFO:Lars(random_state=123)
2024-08-28 11:07:15,220:INFO:create_model() successfully completed......................................
2024-08-28 11:07:15,339:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:15,339:INFO:Creating metrics dataframe
2024-08-28 11:07:15,345:INFO:Initializing Lasso Least Angle Regression
2024-08-28 11:07:15,346:INFO:Total runtime is 0.01792490084966024 minutes
2024-08-28 11:07:15,348:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:15,349:INFO:Initializing create_model()
2024-08-28 11:07:15,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:15,349:INFO:Checking exceptions
2024-08-28 11:07:15,349:INFO:Importing libraries
2024-08-28 11:07:15,349:INFO:Copying training dataset
2024-08-28 11:07:15,353:INFO:Defining folds
2024-08-28 11:07:15,354:INFO:Declaring metric variables
2024-08-28 11:07:15,356:INFO:Importing untrained model
2024-08-28 11:07:15,359:INFO:Lasso Least Angle Regression Imported successfully
2024-08-28 11:07:15,364:INFO:Starting cross validation
2024-08-28 11:07:15,365:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:15,425:INFO:Calculating mean and std
2024-08-28 11:07:15,425:INFO:Creating metrics dataframe
2024-08-28 11:07:15,428:INFO:Uploading results into container
2024-08-28 11:07:15,428:INFO:Uploading model into container now
2024-08-28 11:07:15,429:INFO:_master_model_container: 6
2024-08-28 11:07:15,429:INFO:_display_container: 2
2024-08-28 11:07:15,429:INFO:LassoLars(random_state=123)
2024-08-28 11:07:15,429:INFO:create_model() successfully completed......................................
2024-08-28 11:07:15,549:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:15,550:INFO:Creating metrics dataframe
2024-08-28 11:07:15,556:INFO:Initializing Orthogonal Matching Pursuit
2024-08-28 11:07:15,556:INFO:Total runtime is 0.02142859697341919 minutes
2024-08-28 11:07:15,559:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:15,559:INFO:Initializing create_model()
2024-08-28 11:07:15,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:15,559:INFO:Checking exceptions
2024-08-28 11:07:15,559:INFO:Importing libraries
2024-08-28 11:07:15,559:INFO:Copying training dataset
2024-08-28 11:07:15,566:INFO:Defining folds
2024-08-28 11:07:15,566:INFO:Declaring metric variables
2024-08-28 11:07:15,570:INFO:Importing untrained model
2024-08-28 11:07:15,573:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:07:15,581:INFO:Starting cross validation
2024-08-28 11:07:15,581:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:15,669:INFO:Calculating mean and std
2024-08-28 11:07:15,670:INFO:Creating metrics dataframe
2024-08-28 11:07:15,671:INFO:Uploading results into container
2024-08-28 11:07:15,672:INFO:Uploading model into container now
2024-08-28 11:07:15,673:INFO:_master_model_container: 7
2024-08-28 11:07:15,673:INFO:_display_container: 2
2024-08-28 11:07:15,674:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:07:15,674:INFO:create_model() successfully completed......................................
2024-08-28 11:07:15,811:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:15,811:INFO:Creating metrics dataframe
2024-08-28 11:07:15,819:INFO:Initializing Bayesian Ridge
2024-08-28 11:07:15,819:INFO:Total runtime is 0.02582013209660848 minutes
2024-08-28 11:07:15,823:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:15,823:INFO:Initializing create_model()
2024-08-28 11:07:15,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:15,823:INFO:Checking exceptions
2024-08-28 11:07:15,823:INFO:Importing libraries
2024-08-28 11:07:15,823:INFO:Copying training dataset
2024-08-28 11:07:15,829:INFO:Defining folds
2024-08-28 11:07:15,829:INFO:Declaring metric variables
2024-08-28 11:07:15,832:INFO:Importing untrained model
2024-08-28 11:07:15,836:INFO:Bayesian Ridge Imported successfully
2024-08-28 11:07:15,843:INFO:Starting cross validation
2024-08-28 11:07:15,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:15,915:INFO:Calculating mean and std
2024-08-28 11:07:15,915:INFO:Creating metrics dataframe
2024-08-28 11:07:15,916:INFO:Uploading results into container
2024-08-28 11:07:15,917:INFO:Uploading model into container now
2024-08-28 11:07:15,917:INFO:_master_model_container: 8
2024-08-28 11:07:15,917:INFO:_display_container: 2
2024-08-28 11:07:15,917:INFO:BayesianRidge()
2024-08-28 11:07:15,917:INFO:create_model() successfully completed......................................
2024-08-28 11:07:16,045:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:16,045:INFO:Creating metrics dataframe
2024-08-28 11:07:16,052:INFO:Initializing Passive Aggressive Regressor
2024-08-28 11:07:16,053:INFO:Total runtime is 0.029701693852742513 minutes
2024-08-28 11:07:16,056:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:16,056:INFO:Initializing create_model()
2024-08-28 11:07:16,057:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:16,057:INFO:Checking exceptions
2024-08-28 11:07:16,057:INFO:Importing libraries
2024-08-28 11:07:16,057:INFO:Copying training dataset
2024-08-28 11:07:16,061:INFO:Defining folds
2024-08-28 11:07:16,062:INFO:Declaring metric variables
2024-08-28 11:07:16,064:INFO:Importing untrained model
2024-08-28 11:07:16,068:INFO:Passive Aggressive Regressor Imported successfully
2024-08-28 11:07:16,073:INFO:Starting cross validation
2024-08-28 11:07:16,074:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:16,143:INFO:Calculating mean and std
2024-08-28 11:07:16,143:INFO:Creating metrics dataframe
2024-08-28 11:07:16,145:INFO:Uploading results into container
2024-08-28 11:07:16,145:INFO:Uploading model into container now
2024-08-28 11:07:16,146:INFO:_master_model_container: 9
2024-08-28 11:07:16,146:INFO:_display_container: 2
2024-08-28 11:07:16,146:INFO:PassiveAggressiveRegressor(random_state=123)
2024-08-28 11:07:16,146:INFO:create_model() successfully completed......................................
2024-08-28 11:07:16,264:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:16,264:INFO:Creating metrics dataframe
2024-08-28 11:07:16,270:INFO:Initializing Huber Regressor
2024-08-28 11:07:16,270:INFO:Total runtime is 0.03333822886149088 minutes
2024-08-28 11:07:16,273:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:16,273:INFO:Initializing create_model()
2024-08-28 11:07:16,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:16,273:INFO:Checking exceptions
2024-08-28 11:07:16,274:INFO:Importing libraries
2024-08-28 11:07:16,274:INFO:Copying training dataset
2024-08-28 11:07:16,278:INFO:Defining folds
2024-08-28 11:07:16,278:INFO:Declaring metric variables
2024-08-28 11:07:16,281:INFO:Importing untrained model
2024-08-28 11:07:16,285:INFO:Huber Regressor Imported successfully
2024-08-28 11:07:16,290:INFO:Starting cross validation
2024-08-28 11:07:16,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:16,380:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,386:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,392:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,402:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,403:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,406:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,412:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,418:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,421:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,429:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:07:16,436:INFO:Calculating mean and std
2024-08-28 11:07:16,437:INFO:Creating metrics dataframe
2024-08-28 11:07:16,438:INFO:Uploading results into container
2024-08-28 11:07:16,438:INFO:Uploading model into container now
2024-08-28 11:07:16,439:INFO:_master_model_container: 10
2024-08-28 11:07:16,439:INFO:_display_container: 2
2024-08-28 11:07:16,439:INFO:HuberRegressor()
2024-08-28 11:07:16,439:INFO:create_model() successfully completed......................................
2024-08-28 11:07:16,558:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:16,558:INFO:Creating metrics dataframe
2024-08-28 11:07:16,565:INFO:Initializing K Neighbors Regressor
2024-08-28 11:07:16,565:INFO:Total runtime is 0.03824657599131266 minutes
2024-08-28 11:07:16,567:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:16,568:INFO:Initializing create_model()
2024-08-28 11:07:16,568:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:16,568:INFO:Checking exceptions
2024-08-28 11:07:16,568:INFO:Importing libraries
2024-08-28 11:07:16,568:INFO:Copying training dataset
2024-08-28 11:07:16,573:INFO:Defining folds
2024-08-28 11:07:16,573:INFO:Declaring metric variables
2024-08-28 11:07:16,576:INFO:Importing untrained model
2024-08-28 11:07:16,579:INFO:K Neighbors Regressor Imported successfully
2024-08-28 11:07:16,584:INFO:Starting cross validation
2024-08-28 11:07:16,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:16,666:INFO:Calculating mean and std
2024-08-28 11:07:16,667:INFO:Creating metrics dataframe
2024-08-28 11:07:16,668:INFO:Uploading results into container
2024-08-28 11:07:16,668:INFO:Uploading model into container now
2024-08-28 11:07:16,669:INFO:_master_model_container: 11
2024-08-28 11:07:16,669:INFO:_display_container: 2
2024-08-28 11:07:16,669:INFO:KNeighborsRegressor(n_jobs=-1)
2024-08-28 11:07:16,669:INFO:create_model() successfully completed......................................
2024-08-28 11:07:16,789:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:16,789:INFO:Creating metrics dataframe
2024-08-28 11:07:16,798:INFO:Initializing Decision Tree Regressor
2024-08-28 11:07:16,798:INFO:Total runtime is 0.04213002920150757 minutes
2024-08-28 11:07:16,800:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:16,801:INFO:Initializing create_model()
2024-08-28 11:07:16,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:16,801:INFO:Checking exceptions
2024-08-28 11:07:16,801:INFO:Importing libraries
2024-08-28 11:07:16,801:INFO:Copying training dataset
2024-08-28 11:07:16,806:INFO:Defining folds
2024-08-28 11:07:16,806:INFO:Declaring metric variables
2024-08-28 11:07:16,810:INFO:Importing untrained model
2024-08-28 11:07:16,815:INFO:Decision Tree Regressor Imported successfully
2024-08-28 11:07:16,820:INFO:Starting cross validation
2024-08-28 11:07:16,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:16,917:INFO:Calculating mean and std
2024-08-28 11:07:16,918:INFO:Creating metrics dataframe
2024-08-28 11:07:16,920:INFO:Uploading results into container
2024-08-28 11:07:16,920:INFO:Uploading model into container now
2024-08-28 11:07:16,920:INFO:_master_model_container: 12
2024-08-28 11:07:16,920:INFO:_display_container: 2
2024-08-28 11:07:16,921:INFO:DecisionTreeRegressor(random_state=123)
2024-08-28 11:07:16,921:INFO:create_model() successfully completed......................................
2024-08-28 11:07:17,042:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:17,043:INFO:Creating metrics dataframe
2024-08-28 11:07:17,050:INFO:Initializing Random Forest Regressor
2024-08-28 11:07:17,050:INFO:Total runtime is 0.046338029702504474 minutes
2024-08-28 11:07:17,053:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:17,053:INFO:Initializing create_model()
2024-08-28 11:07:17,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:17,053:INFO:Checking exceptions
2024-08-28 11:07:17,053:INFO:Importing libraries
2024-08-28 11:07:17,053:INFO:Copying training dataset
2024-08-28 11:07:17,059:INFO:Defining folds
2024-08-28 11:07:17,059:INFO:Declaring metric variables
2024-08-28 11:07:17,062:INFO:Importing untrained model
2024-08-28 11:07:17,064:INFO:Random Forest Regressor Imported successfully
2024-08-28 11:07:17,069:INFO:Starting cross validation
2024-08-28 11:07:17,070:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:19,566:INFO:Calculating mean and std
2024-08-28 11:07:19,568:INFO:Creating metrics dataframe
2024-08-28 11:07:19,570:INFO:Uploading results into container
2024-08-28 11:07:19,570:INFO:Uploading model into container now
2024-08-28 11:07:19,571:INFO:_master_model_container: 13
2024-08-28 11:07:19,571:INFO:_display_container: 2
2024-08-28 11:07:19,571:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:19,571:INFO:create_model() successfully completed......................................
2024-08-28 11:07:19,714:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:19,714:INFO:Creating metrics dataframe
2024-08-28 11:07:19,723:INFO:Initializing Extra Trees Regressor
2024-08-28 11:07:19,723:INFO:Total runtime is 0.09088499546051025 minutes
2024-08-28 11:07:19,727:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:19,728:INFO:Initializing create_model()
2024-08-28 11:07:19,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:19,728:INFO:Checking exceptions
2024-08-28 11:07:19,728:INFO:Importing libraries
2024-08-28 11:07:19,728:INFO:Copying training dataset
2024-08-28 11:07:19,733:INFO:Defining folds
2024-08-28 11:07:19,733:INFO:Declaring metric variables
2024-08-28 11:07:19,736:INFO:Importing untrained model
2024-08-28 11:07:19,740:INFO:Extra Trees Regressor Imported successfully
2024-08-28 11:07:19,746:INFO:Starting cross validation
2024-08-28 11:07:19,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:21,273:INFO:Calculating mean and std
2024-08-28 11:07:21,275:INFO:Creating metrics dataframe
2024-08-28 11:07:21,277:INFO:Uploading results into container
2024-08-28 11:07:21,277:INFO:Uploading model into container now
2024-08-28 11:07:21,278:INFO:_master_model_container: 14
2024-08-28 11:07:21,278:INFO:_display_container: 2
2024-08-28 11:07:21,279:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:21,279:INFO:create_model() successfully completed......................................
2024-08-28 11:07:21,418:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:21,419:INFO:Creating metrics dataframe
2024-08-28 11:07:21,428:INFO:Initializing AdaBoost Regressor
2024-08-28 11:07:21,428:INFO:Total runtime is 0.11929593880971273 minutes
2024-08-28 11:07:21,431:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:21,431:INFO:Initializing create_model()
2024-08-28 11:07:21,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:21,431:INFO:Checking exceptions
2024-08-28 11:07:21,431:INFO:Importing libraries
2024-08-28 11:07:21,431:INFO:Copying training dataset
2024-08-28 11:07:21,436:INFO:Defining folds
2024-08-28 11:07:21,436:INFO:Declaring metric variables
2024-08-28 11:07:21,440:INFO:Importing untrained model
2024-08-28 11:07:21,443:INFO:AdaBoost Regressor Imported successfully
2024-08-28 11:07:21,450:INFO:Starting cross validation
2024-08-28 11:07:21,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:21,949:INFO:Calculating mean and std
2024-08-28 11:07:21,950:INFO:Creating metrics dataframe
2024-08-28 11:07:21,952:INFO:Uploading results into container
2024-08-28 11:07:21,952:INFO:Uploading model into container now
2024-08-28 11:07:21,953:INFO:_master_model_container: 15
2024-08-28 11:07:21,953:INFO:_display_container: 2
2024-08-28 11:07:21,953:INFO:AdaBoostRegressor(random_state=123)
2024-08-28 11:07:21,953:INFO:create_model() successfully completed......................................
2024-08-28 11:07:22,091:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:22,092:INFO:Creating metrics dataframe
2024-08-28 11:07:22,100:INFO:Initializing Gradient Boosting Regressor
2024-08-28 11:07:22,100:INFO:Total runtime is 0.13050177097320556 minutes
2024-08-28 11:07:22,103:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:22,104:INFO:Initializing create_model()
2024-08-28 11:07:22,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:22,104:INFO:Checking exceptions
2024-08-28 11:07:22,104:INFO:Importing libraries
2024-08-28 11:07:22,104:INFO:Copying training dataset
2024-08-28 11:07:22,109:INFO:Defining folds
2024-08-28 11:07:22,110:INFO:Declaring metric variables
2024-08-28 11:07:22,113:INFO:Importing untrained model
2024-08-28 11:07:22,116:INFO:Gradient Boosting Regressor Imported successfully
2024-08-28 11:07:22,121:INFO:Starting cross validation
2024-08-28 11:07:22,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:23,126:INFO:Calculating mean and std
2024-08-28 11:07:23,127:INFO:Creating metrics dataframe
2024-08-28 11:07:23,129:INFO:Uploading results into container
2024-08-28 11:07:23,130:INFO:Uploading model into container now
2024-08-28 11:07:23,130:INFO:_master_model_container: 16
2024-08-28 11:07:23,130:INFO:_display_container: 2
2024-08-28 11:07:23,131:INFO:GradientBoostingRegressor(random_state=123)
2024-08-28 11:07:23,131:INFO:create_model() successfully completed......................................
2024-08-28 11:07:23,265:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:23,266:INFO:Creating metrics dataframe
2024-08-28 11:07:23,275:INFO:Initializing Extreme Gradient Boosting
2024-08-28 11:07:23,275:INFO:Total runtime is 0.15007575750350952 minutes
2024-08-28 11:07:23,278:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:23,278:INFO:Initializing create_model()
2024-08-28 11:07:23,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:23,279:INFO:Checking exceptions
2024-08-28 11:07:23,279:INFO:Importing libraries
2024-08-28 11:07:23,279:INFO:Copying training dataset
2024-08-28 11:07:23,284:INFO:Defining folds
2024-08-28 11:07:23,285:INFO:Declaring metric variables
2024-08-28 11:07:23,288:INFO:Importing untrained model
2024-08-28 11:07:23,292:INFO:Extreme Gradient Boosting Imported successfully
2024-08-28 11:07:23,299:INFO:Starting cross validation
2024-08-28 11:07:23,299:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:23,826:INFO:Calculating mean and std
2024-08-28 11:07:23,827:INFO:Creating metrics dataframe
2024-08-28 11:07:23,830:INFO:Uploading results into container
2024-08-28 11:07:23,831:INFO:Uploading model into container now
2024-08-28 11:07:23,831:INFO:_master_model_container: 17
2024-08-28 11:07:23,831:INFO:_display_container: 2
2024-08-28 11:07:23,832:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-08-28 11:07:23,833:INFO:create_model() successfully completed......................................
2024-08-28 11:07:23,982:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:23,982:INFO:Creating metrics dataframe
2024-08-28 11:07:23,992:INFO:Initializing Light Gradient Boosting Machine
2024-08-28 11:07:23,992:INFO:Total runtime is 0.16203771034876505 minutes
2024-08-28 11:07:23,995:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:23,996:INFO:Initializing create_model()
2024-08-28 11:07:23,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:23,996:INFO:Checking exceptions
2024-08-28 11:07:23,996:INFO:Importing libraries
2024-08-28 11:07:23,996:INFO:Copying training dataset
2024-08-28 11:07:24,001:INFO:Defining folds
2024-08-28 11:07:24,003:INFO:Declaring metric variables
2024-08-28 11:07:24,006:INFO:Importing untrained model
2024-08-28 11:07:24,010:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:07:24,015:INFO:Starting cross validation
2024-08-28 11:07:24,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:25,175:INFO:Calculating mean and std
2024-08-28 11:07:25,177:INFO:Creating metrics dataframe
2024-08-28 11:07:25,180:INFO:Uploading results into container
2024-08-28 11:07:25,182:INFO:Uploading model into container now
2024-08-28 11:07:25,183:INFO:_master_model_container: 18
2024-08-28 11:07:25,183:INFO:_display_container: 2
2024-08-28 11:07:25,184:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:25,184:INFO:create_model() successfully completed......................................
2024-08-28 11:07:25,350:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:25,350:INFO:Creating metrics dataframe
2024-08-28 11:07:25,363:INFO:Initializing Dummy Regressor
2024-08-28 11:07:25,363:INFO:Total runtime is 0.18487720886866252 minutes
2024-08-28 11:07:25,366:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:25,367:INFO:Initializing create_model()
2024-08-28 11:07:25,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155CFB55190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:25,367:INFO:Checking exceptions
2024-08-28 11:07:25,367:INFO:Importing libraries
2024-08-28 11:07:25,367:INFO:Copying training dataset
2024-08-28 11:07:25,373:INFO:Defining folds
2024-08-28 11:07:25,373:INFO:Declaring metric variables
2024-08-28 11:07:25,376:INFO:Importing untrained model
2024-08-28 11:07:25,379:INFO:Dummy Regressor Imported successfully
2024-08-28 11:07:25,386:INFO:Starting cross validation
2024-08-28 11:07:25,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:25,454:INFO:Calculating mean and std
2024-08-28 11:07:25,454:INFO:Creating metrics dataframe
2024-08-28 11:07:25,455:INFO:Uploading results into container
2024-08-28 11:07:25,455:INFO:Uploading model into container now
2024-08-28 11:07:25,457:INFO:_master_model_container: 19
2024-08-28 11:07:25,457:INFO:_display_container: 2
2024-08-28 11:07:25,457:INFO:DummyRegressor()
2024-08-28 11:07:25,457:INFO:create_model() successfully completed......................................
2024-08-28 11:07:25,586:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:25,586:INFO:Creating metrics dataframe
2024-08-28 11:07:25,603:INFO:Initializing create_model()
2024-08-28 11:07:25,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:25,603:INFO:Checking exceptions
2024-08-28 11:07:25,604:INFO:Importing libraries
2024-08-28 11:07:25,604:INFO:Copying training dataset
2024-08-28 11:07:25,608:INFO:Defining folds
2024-08-28 11:07:25,609:INFO:Declaring metric variables
2024-08-28 11:07:25,609:INFO:Importing untrained model
2024-08-28 11:07:25,609:INFO:Declaring custom model
2024-08-28 11:07:25,609:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:07:25,610:INFO:Cross validation set to False
2024-08-28 11:07:25,610:INFO:Fitting Model
2024-08-28 11:07:25,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.
2024-08-28 11:07:25,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:25,617:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:25,617:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:07:25,617:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:07:25,713:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:25,713:INFO:create_model() successfully completed......................................
2024-08-28 11:07:25,931:INFO:_master_model_container: 19
2024-08-28 11:07:25,931:INFO:_display_container: 2
2024-08-28 11:07:25,931:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:25,931:INFO:compare_models() successfully completed......................................
2024-08-28 11:07:25,932:INFO:Initializing create_model()
2024-08-28 11:07:25,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:25,932:INFO:Checking exceptions
2024-08-28 11:07:25,946:INFO:Importing libraries
2024-08-28 11:07:25,946:INFO:Copying training dataset
2024-08-28 11:07:25,956:INFO:Defining folds
2024-08-28 11:07:25,956:INFO:Declaring metric variables
2024-08-28 11:07:25,961:INFO:Importing untrained model
2024-08-28 11:07:25,961:INFO:Declaring custom model
2024-08-28 11:07:25,967:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:07:25,975:INFO:Starting cross validation
2024-08-28 11:07:25,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:27,239:INFO:Calculating mean and std
2024-08-28 11:07:27,241:INFO:Creating metrics dataframe
2024-08-28 11:07:27,248:INFO:Finalizing model
2024-08-28 11:07:27,262:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2024-08-28 11:07:27,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:27,263:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:27,263:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:07:27,263:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:07:27,481:INFO:Uploading results into container
2024-08-28 11:07:27,482:INFO:Uploading model into container now
2024-08-28 11:07:27,495:INFO:_master_model_container: 20
2024-08-28 11:07:27,495:INFO:_display_container: 3
2024-08-28 11:07:27,496:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:27,496:INFO:create_model() successfully completed......................................
2024-08-28 11:07:27,665:INFO:Initializing tune_model()
2024-08-28 11:07:27,666:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-28 11:07:27,666:INFO:Checking exceptions
2024-08-28 11:07:27,680:INFO:Copying training dataset
2024-08-28 11:07:27,684:INFO:Checking base model
2024-08-28 11:07:27,685:INFO:Base model : Light Gradient Boosting Machine
2024-08-28 11:07:27,688:INFO:Declaring metric variables
2024-08-28 11:07:27,691:INFO:Defining Hyperparameters
2024-08-28 11:07:27,830:INFO:Tuning with n_jobs=-1
2024-08-28 11:07:27,830:INFO:Initializing RandomizedSearchCV
2024-08-28 11:07:40,272:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-08-28 11:07:40,274:INFO:Hyperparameter search completed
2024-08-28 11:07:40,274:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:40,275:INFO:Initializing create_model()
2024-08-28 11:07:40,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D05431D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-08-28 11:07:40,275:INFO:Checking exceptions
2024-08-28 11:07:40,275:INFO:Importing libraries
2024-08-28 11:07:40,275:INFO:Copying training dataset
2024-08-28 11:07:40,284:INFO:Defining folds
2024-08-28 11:07:40,284:INFO:Declaring metric variables
2024-08-28 11:07:40,289:INFO:Importing untrained model
2024-08-28 11:07:40,290:INFO:Declaring custom model
2024-08-28 11:07:40,296:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:07:40,305:INFO:Starting cross validation
2024-08-28 11:07:40,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:42,502:INFO:Calculating mean and std
2024-08-28 11:07:42,504:INFO:Creating metrics dataframe
2024-08-28 11:07:42,511:INFO:Finalizing model
2024-08-28 11:07:42,522:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-08-28 11:07:42,523:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-08-28 11:07:42,523:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-08-28 11:07:42,525:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-08-28 11:07:42,525:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-08-28 11:07:42,525:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-08-28 11:07:42,526:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2024-08-28 11:07:42,526:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:42,527:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:42,528:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:07:42,528:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:07:42,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-08-28 11:07:42,764:INFO:Uploading results into container
2024-08-28 11:07:42,765:INFO:Uploading model into container now
2024-08-28 11:07:42,766:INFO:_master_model_container: 21
2024-08-28 11:07:42,766:INFO:_display_container: 4
2024-08-28 11:07:42,767:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2024-08-28 11:07:42,767:INFO:create_model() successfully completed......................................
2024-08-28 11:07:42,932:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:42,932:INFO:choose_better activated
2024-08-28 11:07:42,936:INFO:SubProcess create_model() called ==================================
2024-08-28 11:07:42,936:INFO:Initializing create_model()
2024-08-28 11:07:42,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:42,936:INFO:Checking exceptions
2024-08-28 11:07:42,938:INFO:Importing libraries
2024-08-28 11:07:42,938:INFO:Copying training dataset
2024-08-28 11:07:42,943:INFO:Defining folds
2024-08-28 11:07:42,943:INFO:Declaring metric variables
2024-08-28 11:07:42,943:INFO:Importing untrained model
2024-08-28 11:07:42,943:INFO:Declaring custom model
2024-08-28 11:07:42,944:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:07:42,944:INFO:Starting cross validation
2024-08-28 11:07:42,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:07:44,134:INFO:Calculating mean and std
2024-08-28 11:07:44,135:INFO:Creating metrics dataframe
2024-08-28 11:07:44,138:INFO:Finalizing model
2024-08-28 11:07:44,151:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2024-08-28 11:07:44,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:44,151:INFO:[LightGBM] [Info] Total Bins 1806
2024-08-28 11:07:44,151:INFO:[LightGBM] [Info] Number of data points in the train set: 2308, number of used features: 12
2024-08-28 11:07:44,152:INFO:[LightGBM] [Info] Start training from score 40803.211438
2024-08-28 11:07:44,309:INFO:Uploading results into container
2024-08-28 11:07:44,310:INFO:Uploading model into container now
2024-08-28 11:07:44,311:INFO:_master_model_container: 22
2024-08-28 11:07:44,311:INFO:_display_container: 5
2024-08-28 11:07:44,311:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:44,312:INFO:create_model() successfully completed......................................
2024-08-28 11:07:44,473:INFO:SubProcess create_model() end ==================================
2024-08-28 11:07:44,473:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.9845
2024-08-28 11:07:44,473:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.9796
2024-08-28 11:07:44,475:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2024-08-28 11:07:44,475:INFO:choose_better completed
2024-08-28 11:07:44,475:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-08-28 11:07:44,483:INFO:_master_model_container: 22
2024-08-28 11:07:44,483:INFO:_display_container: 4
2024-08-28 11:07:44,484:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:44,484:INFO:tune_model() successfully completed......................................
2024-08-28 11:07:44,613:INFO:Initializing finalize_model()
2024-08-28 11:07:44,613:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-28 11:07:44,614:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:07:44,617:INFO:Initializing create_model()
2024-08-28 11:07:44,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:07:44,617:INFO:Checking exceptions
2024-08-28 11:07:44,618:INFO:Importing libraries
2024-08-28 11:07:44,618:INFO:Copying training dataset
2024-08-28 11:07:44,618:INFO:Defining folds
2024-08-28 11:07:44,618:INFO:Declaring metric variables
2024-08-28 11:07:44,618:INFO:Importing untrained model
2024-08-28 11:07:44,618:INFO:Declaring custom model
2024-08-28 11:07:44,619:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:07:44,619:INFO:Cross validation set to False
2024-08-28 11:07:44,619:INFO:Fitting Model
2024-08-28 11:07:44,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.
2024-08-28 11:07:44,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-08-28 11:07:44,627:INFO:[LightGBM] [Info] Total Bins 1807
2024-08-28 11:07:44,627:INFO:[LightGBM] [Info] Number of data points in the train set: 3298, number of used features: 12
2024-08-28 11:07:44,627:INFO:[LightGBM] [Info] Start training from score 40625.855670
2024-08-28 11:07:44,713:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-28 11:07:44,713:INFO:create_model() successfully completed......................................
2024-08-28 11:07:44,861:INFO:_master_model_container: 22
2024-08-28 11:07:44,861:INFO:_display_container: 4
2024-08-28 11:07:44,866:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-08-28 11:07:44,866:INFO:finalize_model() successfully completed......................................
2024-08-28 11:07:44,992:INFO:Initializing predict_model()
2024-08-28 11:07:44,992:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000155CFBD1DA0>)
2024-08-28 11:07:44,992:INFO:Checking exceptions
2024-08-28 11:07:44,992:INFO:Preloading libraries
2024-08-28 11:07:44,993:INFO:Set up data.
2024-08-28 11:07:44,996:INFO:Set up index.
2024-08-28 11:07:45,162:INFO:Initializing evaluate_model()
2024-08-28 11:07:45,162:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-08-28 11:07:45,173:INFO:Initializing plot_model()
2024-08-28 11:07:45,173:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:07:45,173:INFO:Checking exceptions
2024-08-28 11:07:45,175:INFO:Preloading libraries
2024-08-28 11:07:45,180:INFO:Copying training dataset
2024-08-28 11:07:45,180:INFO:Plot type: pipeline
2024-08-28 11:07:45,269:INFO:Visual Rendered Successfully
2024-08-28 11:07:45,397:INFO:plot_model() successfully completed......................................
2024-08-28 11:07:45,412:INFO:Initializing plot_model()
2024-08-28 11:07:45,412:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C28B5DD0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:07:45,412:INFO:Checking exceptions
2024-08-28 11:07:45,414:INFO:Preloading libraries
2024-08-28 11:07:45,420:INFO:Copying training dataset
2024-08-28 11:07:45,420:INFO:Plot type: parameter
2024-08-28 11:07:45,425:INFO:Visual Rendered Successfully
2024-08-28 11:07:45,577:INFO:plot_model() successfully completed......................................
2024-08-28 11:07:54,467:INFO:Initializing plot_model()
2024-08-28 11:07:54,468:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:07:54,468:INFO:Checking exceptions
2024-08-28 11:07:54,470:INFO:Preloading libraries
2024-08-28 11:07:54,474:INFO:Copying training dataset
2024-08-28 11:07:54,474:INFO:Plot type: feature
2024-08-28 11:07:54,474:WARNING:No coef_ found. Trying feature_importances_
2024-08-28 11:07:54,649:INFO:Visual Rendered Successfully
2024-08-28 11:07:54,763:INFO:plot_model() successfully completed......................................
2024-08-28 11:08:00,587:INFO:Initializing plot_model()
2024-08-28 11:08:00,587:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:08:00,587:INFO:Checking exceptions
2024-08-28 11:08:00,589:INFO:Preloading libraries
2024-08-28 11:08:00,595:INFO:Copying training dataset
2024-08-28 11:08:00,595:INFO:Plot type: feature_all
2024-08-28 11:08:00,621:WARNING:No coef_ found. Trying feature_importances_
2024-08-28 11:08:00,793:INFO:Visual Rendered Successfully
2024-08-28 11:08:00,907:INFO:plot_model() successfully completed......................................
2024-08-28 11:08:01,892:INFO:Initializing plot_model()
2024-08-28 11:08:01,892:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=tree, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:08:01,892:INFO:Checking exceptions
2024-08-28 11:08:05,492:INFO:Initializing plot_model()
2024-08-28 11:08:05,493:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=residuals_interactive, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:08:05,493:INFO:Checking exceptions
2024-08-28 11:08:05,495:INFO:Preloading libraries
2024-08-28 11:08:05,498:INFO:Copying training dataset
2024-08-28 11:08:05,498:INFO:Plot type: residuals_interactive
2024-08-28 11:08:05,617:INFO:Calculated model residuals
2024-08-28 11:08:08,346:INFO:Calculated Tunkey-Anscombe Plot
2024-08-28 11:08:08,635:INFO:Calculated Normal QQ Plot
2024-08-28 11:08:09,431:INFO:Calculated Scale-Location Plot
2024-08-28 11:08:10,241:INFO:Calculated Residual vs Leverage Plot inc. Cook's distance
2024-08-28 11:08:10,418:INFO:Visual Rendered Successfully
2024-08-28 11:08:10,564:INFO:plot_model() successfully completed......................................
2024-08-28 11:08:10,583:INFO:Initializing plot_model()
2024-08-28 11:08:10,583:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:08:10,583:INFO:Checking exceptions
2024-08-28 11:08:10,585:INFO:Preloading libraries
2024-08-28 11:08:10,591:INFO:Copying training dataset
2024-08-28 11:08:10,591:INFO:Plot type: parameter
2024-08-28 11:08:10,596:INFO:Visual Rendered Successfully
2024-08-28 11:08:10,772:INFO:plot_model() successfully completed......................................
2024-08-28 11:08:14,660:INFO:Initializing plot_model()
2024-08-28 11:08:14,660:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=vc, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:08:14,660:INFO:Checking exceptions
2024-08-28 11:08:14,662:INFO:Preloading libraries
2024-08-28 11:08:14,668:INFO:Copying training dataset
2024-08-28 11:08:14,668:INFO:Plot type: vc
2024-08-28 11:08:14,668:INFO:Determining param_name
2024-08-28 11:08:14,668:INFO:param_name: max_depth
2024-08-28 11:08:14,758:INFO:Fitting Model
2024-08-28 11:08:21,918:INFO:Visual Rendered Successfully
2024-08-28 11:08:22,049:INFO:plot_model() successfully completed......................................
2024-08-28 11:08:22,100:INFO:Initializing plot_model()
2024-08-28 11:08:22,101:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:08:22,101:INFO:Checking exceptions
2024-08-28 11:08:22,105:INFO:Preloading libraries
2024-08-28 11:08:22,127:INFO:Copying training dataset
2024-08-28 11:08:22,127:INFO:Plot type: pipeline
2024-08-28 11:08:22,225:INFO:Visual Rendered Successfully
2024-08-28 11:08:22,357:INFO:plot_model() successfully completed......................................
2024-08-28 11:08:23,121:INFO:Initializing plot_model()
2024-08-28 11:08:23,121:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=vc, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:08:23,122:INFO:Checking exceptions
2024-08-28 11:08:23,125:INFO:Preloading libraries
2024-08-28 11:08:23,129:INFO:Copying training dataset
2024-08-28 11:08:23,129:INFO:Plot type: vc
2024-08-28 11:08:23,130:INFO:Determining param_name
2024-08-28 11:08:23,130:INFO:param_name: max_depth
2024-08-28 11:08:23,219:INFO:Fitting Model
2024-08-28 11:08:29,852:INFO:Visual Rendered Successfully
2024-08-28 11:08:29,990:INFO:plot_model() successfully completed......................................
2024-08-28 11:18:47,780:INFO:Initializing plot_model()
2024-08-28 11:18:47,780:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:18:47,780:INFO:Checking exceptions
2024-08-28 11:18:47,786:INFO:Preloading libraries
2024-08-28 11:18:47,791:INFO:Copying training dataset
2024-08-28 11:18:47,791:INFO:Plot type: feature_all
2024-08-28 11:18:47,817:WARNING:No coef_ found. Trying feature_importances_
2024-08-28 11:18:47,987:INFO:Visual Rendered Successfully
2024-08-28 11:18:48,128:INFO:plot_model() successfully completed......................................
2024-08-28 11:18:49,341:INFO:Initializing plot_model()
2024-08-28 11:18:49,341:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:18:49,342:INFO:Checking exceptions
2024-08-28 11:18:49,344:INFO:Preloading libraries
2024-08-28 11:18:49,348:INFO:Copying training dataset
2024-08-28 11:18:49,348:INFO:Plot type: feature
2024-08-28 11:18:49,349:WARNING:No coef_ found. Trying feature_importances_
2024-08-28 11:18:49,506:INFO:Visual Rendered Successfully
2024-08-28 11:18:49,640:INFO:plot_model() successfully completed......................................
2024-08-28 11:18:50,502:INFO:Initializing plot_model()
2024-08-28 11:18:50,503:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:18:50,503:INFO:Checking exceptions
2024-08-28 11:18:50,505:INFO:Preloading libraries
2024-08-28 11:18:50,508:INFO:Copying training dataset
2024-08-28 11:18:50,508:INFO:Plot type: pipeline
2024-08-28 11:18:50,589:INFO:Visual Rendered Successfully
2024-08-28 11:18:50,721:INFO:plot_model() successfully completed......................................
2024-08-28 11:18:52,331:INFO:Initializing plot_model()
2024-08-28 11:18:52,331:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:18:52,331:INFO:Checking exceptions
2024-08-28 11:18:52,334:INFO:Preloading libraries
2024-08-28 11:18:52,339:INFO:Copying training dataset
2024-08-28 11:18:52,339:INFO:Plot type: parameter
2024-08-28 11:18:52,344:INFO:Visual Rendered Successfully
2024-08-28 11:18:52,509:INFO:plot_model() successfully completed......................................
2024-08-28 11:18:56,592:INFO:Initializing plot_model()
2024-08-28 11:18:56,592:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:18:56,592:INFO:Checking exceptions
2024-08-28 11:18:56,595:INFO:Preloading libraries
2024-08-28 11:18:56,598:INFO:Copying training dataset
2024-08-28 11:18:56,599:INFO:Plot type: residuals
2024-08-28 11:18:56,701:INFO:Fitting Model
2024-08-28 11:18:56,741:INFO:Scoring test/hold-out set
2024-08-28 11:18:57,060:INFO:Visual Rendered Successfully
2024-08-28 11:18:57,187:INFO:plot_model() successfully completed......................................
2024-08-28 11:18:58,406:INFO:Initializing plot_model()
2024-08-28 11:18:58,406:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:18:58,406:INFO:Checking exceptions
2024-08-28 11:18:58,410:INFO:Preloading libraries
2024-08-28 11:18:58,415:INFO:Copying training dataset
2024-08-28 11:18:58,415:INFO:Plot type: error
2024-08-28 11:18:58,503:INFO:Fitting Model
2024-08-28 11:18:58,504:INFO:Scoring test/hold-out set
2024-08-28 11:18:58,700:INFO:Visual Rendered Successfully
2024-08-28 11:18:58,858:INFO:plot_model() successfully completed......................................
2024-08-28 11:19:00,099:INFO:Initializing plot_model()
2024-08-28 11:19:00,099:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155C2BE0890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['uranium_lead_ratio',
                                             'carbon_14_ratio',
                                             'radioactive_decay_series',
                                             'stratigraphic_layer_depth',
                                             'geological_period',
                                             'paleomagnetic_data',
                                             'inclusion_of_other_fossils',
                                             'isotopic_composition',
                                             'surrounding_rock_type',
                                             'stratigraphic_position',
                                             'fossil_size', 'fossil_weight'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), plot=cooks, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:19:00,099:INFO:Checking exceptions
2024-08-28 11:19:00,102:INFO:Preloading libraries
2024-08-28 11:19:00,105:INFO:Copying training dataset
2024-08-28 11:19:00,105:INFO:Plot type: cooks
2024-08-28 11:19:00,189:INFO:Fitting Model
2024-08-28 11:19:00,408:INFO:Visual Rendered Successfully
2024-08-28 11:19:00,542:INFO:plot_model() successfully completed......................................
2024-08-28 11:19:39,593:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning:

The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent


2024-08-28 11:20:26,953:INFO:PyCaret RegressionExperiment
2024-08-28 11:20:26,953:INFO:Logging name: reg-default-name
2024-08-28 11:20:26,953:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-28 11:20:26,953:INFO:version 3.3.2
2024-08-28 11:20:26,953:INFO:Initializing setup()
2024-08-28 11:20:26,953:INFO:self.USI: 6ed8
2024-08-28 11:20:26,953:INFO:self._variable_keys: {'data', 'html_param', 'pipeline', '_ml_usecase', 'y', 'X_test', 'exp_name_log', 'gpu_param', 'X_train', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'fold_generator', 'seed', 'USI', 'memory', 'fold_groups_param', 'idx', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'y_train', 'target_param'}
2024-08-28 11:20:26,953:INFO:Checking environment
2024-08-28 11:20:26,953:INFO:python_version: 3.11.9
2024-08-28 11:20:26,953:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 11:20:26,953:INFO:machine: AMD64
2024-08-28 11:20:26,953:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 11:20:26,958:INFO:Memory: svmem(total=16867028992, available=6033301504, percent=64.2, used=10833727488, free=6033301504)
2024-08-28 11:20:26,958:INFO:Physical Core: 6
2024-08-28 11:20:26,958:INFO:Logical Core: 12
2024-08-28 11:20:26,958:INFO:Checking libraries
2024-08-28 11:20:26,958:INFO:System:
2024-08-28 11:20:26,958:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 11:20:26,958:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 11:20:26,958:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 11:20:26,958:INFO:PyCaret required dependencies:
2024-08-28 11:20:26,958:INFO:                 pip: 23.2.1
2024-08-28 11:20:26,958:INFO:          setuptools: 67.8.0
2024-08-28 11:20:26,958:INFO:             pycaret: 3.3.2
2024-08-28 11:20:26,958:INFO:             IPython: 8.14.0
2024-08-28 11:20:26,958:INFO:          ipywidgets: 8.1.5
2024-08-28 11:20:26,958:INFO:                tqdm: 4.66.5
2024-08-28 11:20:26,958:INFO:               numpy: 1.24.3
2024-08-28 11:20:26,958:INFO:              pandas: 2.0.3
2024-08-28 11:20:26,959:INFO:              jinja2: 3.1.4
2024-08-28 11:20:26,959:INFO:               scipy: 1.10.1
2024-08-28 11:20:26,959:INFO:              joblib: 1.2.0
2024-08-28 11:20:26,959:INFO:             sklearn: 1.4.2
2024-08-28 11:20:26,959:INFO:                pyod: 2.0.1
2024-08-28 11:20:26,959:INFO:            imblearn: 0.12.3
2024-08-28 11:20:26,959:INFO:   category_encoders: 2.6.3
2024-08-28 11:20:26,959:INFO:            lightgbm: 4.5.0
2024-08-28 11:20:26,959:INFO:               numba: 0.60.0
2024-08-28 11:20:26,959:INFO:            requests: 2.32.3
2024-08-28 11:20:26,959:INFO:          matplotlib: 3.7.1
2024-08-28 11:20:26,959:INFO:          scikitplot: 0.3.7
2024-08-28 11:20:26,959:INFO:         yellowbrick: 1.5
2024-08-28 11:20:26,959:INFO:              plotly: 5.16.1
2024-08-28 11:20:26,959:INFO:    plotly-resampler: Not installed
2024-08-28 11:20:26,959:INFO:             kaleido: 0.2.1
2024-08-28 11:20:26,959:INFO:           schemdraw: 0.15
2024-08-28 11:20:26,959:INFO:         statsmodels: 0.14.2
2024-08-28 11:20:26,959:INFO:              sktime: 0.26.0
2024-08-28 11:20:26,959:INFO:               tbats: 1.1.3
2024-08-28 11:20:26,959:INFO:            pmdarima: 2.0.4
2024-08-28 11:20:26,959:INFO:              psutil: 5.9.0
2024-08-28 11:20:26,959:INFO:          markupsafe: 2.1.3
2024-08-28 11:20:26,959:INFO:             pickle5: Not installed
2024-08-28 11:20:26,959:INFO:         cloudpickle: 3.0.0
2024-08-28 11:20:26,959:INFO:         deprecation: 2.1.0
2024-08-28 11:20:26,959:INFO:              xxhash: 3.5.0
2024-08-28 11:20:26,959:INFO:           wurlitzer: Not installed
2024-08-28 11:20:26,959:INFO:PyCaret optional dependencies:
2024-08-28 11:20:26,959:INFO:                shap: Not installed
2024-08-28 11:20:26,959:INFO:           interpret: Not installed
2024-08-28 11:20:26,959:INFO:                umap: Not installed
2024-08-28 11:20:26,959:INFO:     ydata_profiling: Not installed
2024-08-28 11:20:26,959:INFO:  explainerdashboard: Not installed
2024-08-28 11:20:26,960:INFO:             autoviz: Not installed
2024-08-28 11:20:26,960:INFO:           fairlearn: Not installed
2024-08-28 11:20:26,960:INFO:          deepchecks: Not installed
2024-08-28 11:20:26,960:INFO:             xgboost: 2.0.2
2024-08-28 11:20:26,960:INFO:            catboost: Not installed
2024-08-28 11:20:26,960:INFO:              kmodes: Not installed
2024-08-28 11:20:26,960:INFO:             mlxtend: Not installed
2024-08-28 11:20:26,960:INFO:       statsforecast: Not installed
2024-08-28 11:20:26,960:INFO:        tune_sklearn: Not installed
2024-08-28 11:20:26,960:INFO:                 ray: Not installed
2024-08-28 11:20:26,960:INFO:            hyperopt: Not installed
2024-08-28 11:20:26,960:INFO:              optuna: Not installed
2024-08-28 11:20:26,960:INFO:               skopt: Not installed
2024-08-28 11:20:26,960:INFO:              mlflow: Not installed
2024-08-28 11:20:26,960:INFO:              gradio: 4.41.0
2024-08-28 11:20:26,960:INFO:             fastapi: 0.112.1
2024-08-28 11:20:26,960:INFO:             uvicorn: 0.30.6
2024-08-28 11:20:26,960:INFO:              m2cgen: Not installed
2024-08-28 11:20:26,960:INFO:           evidently: Not installed
2024-08-28 11:20:26,960:INFO:               fugue: Not installed
2024-08-28 11:20:26,960:INFO:           streamlit: Not installed
2024-08-28 11:20:26,960:INFO:             prophet: Not installed
2024-08-28 11:20:26,960:INFO:None
2024-08-28 11:20:26,960:INFO:Set up data.
2024-08-28 11:20:26,969:INFO:Set up folding strategy.
2024-08-28 11:20:26,969:INFO:Set up train/test split.
2024-08-28 11:20:26,975:INFO:Set up index.
2024-08-28 11:20:26,975:INFO:Assigning column types.
2024-08-28 11:20:26,981:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-28 11:20:26,981:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:20:26,984:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:20:26,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,073:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,075:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,079:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,129:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,163:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,165:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-28 11:20:27,169:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,173:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,253:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,260:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,263:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,345:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,347:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,348:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-28 11:20:27,355:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,437:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,445:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,526:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,528:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-28 11:20:27,582:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,618:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,620:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,708:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,711:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-28 11:20:27,764:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,799:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,867:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:20:27,903:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:27,905:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:27,905:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-28 11:20:28,003:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:28,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:28,099:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:28,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:28,102:INFO:Preparing preprocessing pipeline...
2024-08-28 11:20:28,102:INFO:Set up simple imputation.
2024-08-28 11:20:28,128:INFO:Finished creating preprocessing pipeline.
2024-08-28 11:20:28,131:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Gender', '10percentage',
                                             '12graduation', '12percentage',
                                             'CollegeTier', 'Degree',
                                             'Specialization', 'collegeGPA',
                                             'CollegeCityTier', 'CollegeState',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerProgramming',
                                             'ElectronicsAndSemicon',
                                             'ComputerScience',
                                             'MechanicalEngg', 'ElectricalEngg',
                                             'TelecomEngg', 'CivilEngg',
                                             'conscientiousness',
                                             'agreeableness', 'extraversion',
                                             'nueroticism',
                                             'openess_to_experience',
                                             'birth_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2024-08-28 11:20:28,131:INFO:Creating final display dataframe.
2024-08-28 11:20:28,205:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Salary
2                   Target type        Regression
3           Original data shape        (2248, 29)
4        Transformed data shape        (2248, 29)
5   Transformed train set shape        (1573, 29)
6    Transformed test set shape         (675, 29)
7              Numeric features                28
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              6ed8
2024-08-28 11:20:28,333:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:28,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:28,424:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:20:28,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:20:28,427:INFO:setup() successfully completed in 1.48s...............
2024-08-28 11:20:28,427:INFO:Initializing compare_models()
2024-08-28 11:20:28,427:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-08-28 11:20:28,427:INFO:Checking exceptions
2024-08-28 11:20:28,429:INFO:Preparing display monitor
2024-08-28 11:20:28,446:INFO:Initializing Linear Regression
2024-08-28 11:20:28,446:INFO:Total runtime is 0.0 minutes
2024-08-28 11:20:28,450:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:28,451:INFO:Initializing create_model()
2024-08-28 11:20:28,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:28,451:INFO:Checking exceptions
2024-08-28 11:20:28,451:INFO:Importing libraries
2024-08-28 11:20:28,451:INFO:Copying training dataset
2024-08-28 11:20:28,457:INFO:Defining folds
2024-08-28 11:20:28,457:INFO:Declaring metric variables
2024-08-28 11:20:28,460:INFO:Importing untrained model
2024-08-28 11:20:28,463:INFO:Linear Regression Imported successfully
2024-08-28 11:20:28,470:INFO:Starting cross validation
2024-08-28 11:20:28,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:33,777:INFO:Calculating mean and std
2024-08-28 11:20:33,780:INFO:Creating metrics dataframe
2024-08-28 11:20:33,784:INFO:Uploading results into container
2024-08-28 11:20:33,785:INFO:Uploading model into container now
2024-08-28 11:20:33,786:INFO:_master_model_container: 1
2024-08-28 11:20:33,786:INFO:_display_container: 2
2024-08-28 11:20:33,787:INFO:LinearRegression(n_jobs=-1)
2024-08-28 11:20:33,787:INFO:create_model() successfully completed......................................
2024-08-28 11:20:34,036:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:34,036:INFO:Creating metrics dataframe
2024-08-28 11:20:34,042:INFO:Initializing Lasso Regression
2024-08-28 11:20:34,042:INFO:Total runtime is 0.09326854149500528 minutes
2024-08-28 11:20:34,044:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:34,044:INFO:Initializing create_model()
2024-08-28 11:20:34,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:34,045:INFO:Checking exceptions
2024-08-28 11:20:34,045:INFO:Importing libraries
2024-08-28 11:20:34,045:INFO:Copying training dataset
2024-08-28 11:20:34,052:INFO:Defining folds
2024-08-28 11:20:34,052:INFO:Declaring metric variables
2024-08-28 11:20:34,055:INFO:Importing untrained model
2024-08-28 11:20:34,057:INFO:Lasso Regression Imported successfully
2024-08-28 11:20:34,062:INFO:Starting cross validation
2024-08-28 11:20:34,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:35,990:INFO:Calculating mean and std
2024-08-28 11:20:35,992:INFO:Creating metrics dataframe
2024-08-28 11:20:35,993:INFO:Uploading results into container
2024-08-28 11:20:35,993:INFO:Uploading model into container now
2024-08-28 11:20:35,994:INFO:_master_model_container: 2
2024-08-28 11:20:35,994:INFO:_display_container: 2
2024-08-28 11:20:35,994:INFO:Lasso(random_state=123)
2024-08-28 11:20:35,994:INFO:create_model() successfully completed......................................
2024-08-28 11:20:36,143:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:36,143:INFO:Creating metrics dataframe
2024-08-28 11:20:36,149:INFO:Initializing Ridge Regression
2024-08-28 11:20:36,149:INFO:Total runtime is 0.12838780879974365 minutes
2024-08-28 11:20:36,152:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:36,152:INFO:Initializing create_model()
2024-08-28 11:20:36,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:36,152:INFO:Checking exceptions
2024-08-28 11:20:36,152:INFO:Importing libraries
2024-08-28 11:20:36,152:INFO:Copying training dataset
2024-08-28 11:20:36,159:INFO:Defining folds
2024-08-28 11:20:36,159:INFO:Declaring metric variables
2024-08-28 11:20:36,162:INFO:Importing untrained model
2024-08-28 11:20:36,165:INFO:Ridge Regression Imported successfully
2024-08-28 11:20:36,169:INFO:Starting cross validation
2024-08-28 11:20:36,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:36,253:INFO:Calculating mean and std
2024-08-28 11:20:36,253:INFO:Creating metrics dataframe
2024-08-28 11:20:36,255:INFO:Uploading results into container
2024-08-28 11:20:36,255:INFO:Uploading model into container now
2024-08-28 11:20:36,256:INFO:_master_model_container: 3
2024-08-28 11:20:36,256:INFO:_display_container: 2
2024-08-28 11:20:36,256:INFO:Ridge(random_state=123)
2024-08-28 11:20:36,256:INFO:create_model() successfully completed......................................
2024-08-28 11:20:36,399:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:36,401:INFO:Creating metrics dataframe
2024-08-28 11:20:36,406:INFO:Initializing Elastic Net
2024-08-28 11:20:36,406:INFO:Total runtime is 0.13266692558924356 minutes
2024-08-28 11:20:36,409:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:36,409:INFO:Initializing create_model()
2024-08-28 11:20:36,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:36,410:INFO:Checking exceptions
2024-08-28 11:20:36,410:INFO:Importing libraries
2024-08-28 11:20:36,410:INFO:Copying training dataset
2024-08-28 11:20:36,417:INFO:Defining folds
2024-08-28 11:20:36,417:INFO:Declaring metric variables
2024-08-28 11:20:36,420:INFO:Importing untrained model
2024-08-28 11:20:36,422:INFO:Elastic Net Imported successfully
2024-08-28 11:20:36,427:INFO:Starting cross validation
2024-08-28 11:20:36,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:36,496:INFO:Calculating mean and std
2024-08-28 11:20:36,497:INFO:Creating metrics dataframe
2024-08-28 11:20:36,498:INFO:Uploading results into container
2024-08-28 11:20:36,498:INFO:Uploading model into container now
2024-08-28 11:20:36,498:INFO:_master_model_container: 4
2024-08-28 11:20:36,499:INFO:_display_container: 2
2024-08-28 11:20:36,499:INFO:ElasticNet(random_state=123)
2024-08-28 11:20:36,499:INFO:create_model() successfully completed......................................
2024-08-28 11:20:36,634:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:36,634:INFO:Creating metrics dataframe
2024-08-28 11:20:36,640:INFO:Initializing Least Angle Regression
2024-08-28 11:20:36,640:INFO:Total runtime is 0.13656295935312907 minutes
2024-08-28 11:20:36,643:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:36,643:INFO:Initializing create_model()
2024-08-28 11:20:36,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:36,643:INFO:Checking exceptions
2024-08-28 11:20:36,643:INFO:Importing libraries
2024-08-28 11:20:36,643:INFO:Copying training dataset
2024-08-28 11:20:36,649:INFO:Defining folds
2024-08-28 11:20:36,649:INFO:Declaring metric variables
2024-08-28 11:20:36,652:INFO:Importing untrained model
2024-08-28 11:20:36,655:INFO:Least Angle Regression Imported successfully
2024-08-28 11:20:36,660:INFO:Starting cross validation
2024-08-28 11:20:36,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:36,737:INFO:Calculating mean and std
2024-08-28 11:20:36,738:INFO:Creating metrics dataframe
2024-08-28 11:20:36,739:INFO:Uploading results into container
2024-08-28 11:20:36,740:INFO:Uploading model into container now
2024-08-28 11:20:36,740:INFO:_master_model_container: 5
2024-08-28 11:20:36,740:INFO:_display_container: 2
2024-08-28 11:20:36,740:INFO:Lars(random_state=123)
2024-08-28 11:20:36,740:INFO:create_model() successfully completed......................................
2024-08-28 11:20:36,878:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:36,878:INFO:Creating metrics dataframe
2024-08-28 11:20:36,883:INFO:Initializing Lasso Least Angle Regression
2024-08-28 11:20:36,883:INFO:Total runtime is 0.14061878522237142 minutes
2024-08-28 11:20:36,886:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:36,886:INFO:Initializing create_model()
2024-08-28 11:20:36,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:36,886:INFO:Checking exceptions
2024-08-28 11:20:36,886:INFO:Importing libraries
2024-08-28 11:20:36,886:INFO:Copying training dataset
2024-08-28 11:20:36,894:INFO:Defining folds
2024-08-28 11:20:36,894:INFO:Declaring metric variables
2024-08-28 11:20:36,897:INFO:Importing untrained model
2024-08-28 11:20:36,899:INFO:Lasso Least Angle Regression Imported successfully
2024-08-28 11:20:36,904:INFO:Starting cross validation
2024-08-28 11:20:36,905:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:36,981:INFO:Calculating mean and std
2024-08-28 11:20:36,982:INFO:Creating metrics dataframe
2024-08-28 11:20:36,983:INFO:Uploading results into container
2024-08-28 11:20:36,983:INFO:Uploading model into container now
2024-08-28 11:20:36,983:INFO:_master_model_container: 6
2024-08-28 11:20:36,983:INFO:_display_container: 2
2024-08-28 11:20:36,983:INFO:LassoLars(random_state=123)
2024-08-28 11:20:36,983:INFO:create_model() successfully completed......................................
2024-08-28 11:20:37,119:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:37,119:INFO:Creating metrics dataframe
2024-08-28 11:20:37,125:INFO:Initializing Orthogonal Matching Pursuit
2024-08-28 11:20:37,125:INFO:Total runtime is 0.1446547269821167 minutes
2024-08-28 11:20:37,128:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:37,128:INFO:Initializing create_model()
2024-08-28 11:20:37,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:37,129:INFO:Checking exceptions
2024-08-28 11:20:37,129:INFO:Importing libraries
2024-08-28 11:20:37,129:INFO:Copying training dataset
2024-08-28 11:20:37,137:INFO:Defining folds
2024-08-28 11:20:37,137:INFO:Declaring metric variables
2024-08-28 11:20:37,140:INFO:Importing untrained model
2024-08-28 11:20:37,143:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:20:37,148:INFO:Starting cross validation
2024-08-28 11:20:37,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:37,217:INFO:Calculating mean and std
2024-08-28 11:20:37,218:INFO:Creating metrics dataframe
2024-08-28 11:20:37,219:INFO:Uploading results into container
2024-08-28 11:20:37,219:INFO:Uploading model into container now
2024-08-28 11:20:37,220:INFO:_master_model_container: 7
2024-08-28 11:20:37,220:INFO:_display_container: 2
2024-08-28 11:20:37,220:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:20:37,220:INFO:create_model() successfully completed......................................
2024-08-28 11:20:37,356:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:37,356:INFO:Creating metrics dataframe
2024-08-28 11:20:37,362:INFO:Initializing Bayesian Ridge
2024-08-28 11:20:37,362:INFO:Total runtime is 0.14860680898030598 minutes
2024-08-28 11:20:37,365:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:37,365:INFO:Initializing create_model()
2024-08-28 11:20:37,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:37,366:INFO:Checking exceptions
2024-08-28 11:20:37,366:INFO:Importing libraries
2024-08-28 11:20:37,366:INFO:Copying training dataset
2024-08-28 11:20:37,373:INFO:Defining folds
2024-08-28 11:20:37,373:INFO:Declaring metric variables
2024-08-28 11:20:37,376:INFO:Importing untrained model
2024-08-28 11:20:37,381:INFO:Bayesian Ridge Imported successfully
2024-08-28 11:20:37,385:INFO:Starting cross validation
2024-08-28 11:20:37,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:37,468:INFO:Calculating mean and std
2024-08-28 11:20:37,469:INFO:Creating metrics dataframe
2024-08-28 11:20:37,470:INFO:Uploading results into container
2024-08-28 11:20:37,470:INFO:Uploading model into container now
2024-08-28 11:20:37,471:INFO:_master_model_container: 8
2024-08-28 11:20:37,471:INFO:_display_container: 2
2024-08-28 11:20:37,471:INFO:BayesianRidge()
2024-08-28 11:20:37,471:INFO:create_model() successfully completed......................................
2024-08-28 11:20:37,605:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:37,605:INFO:Creating metrics dataframe
2024-08-28 11:20:37,612:INFO:Initializing Passive Aggressive Regressor
2024-08-28 11:20:37,613:INFO:Total runtime is 0.1527777671813965 minutes
2024-08-28 11:20:37,616:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:37,616:INFO:Initializing create_model()
2024-08-28 11:20:37,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:37,616:INFO:Checking exceptions
2024-08-28 11:20:37,616:INFO:Importing libraries
2024-08-28 11:20:37,616:INFO:Copying training dataset
2024-08-28 11:20:37,621:INFO:Defining folds
2024-08-28 11:20:37,621:INFO:Declaring metric variables
2024-08-28 11:20:37,624:INFO:Importing untrained model
2024-08-28 11:20:37,628:INFO:Passive Aggressive Regressor Imported successfully
2024-08-28 11:20:37,633:INFO:Starting cross validation
2024-08-28 11:20:37,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:37,950:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,961:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,961:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,969:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,969:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,970:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,977:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,980:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,985:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:37,996:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2024-08-28 11:20:38,003:INFO:Calculating mean and std
2024-08-28 11:20:38,004:INFO:Creating metrics dataframe
2024-08-28 11:20:38,006:INFO:Uploading results into container
2024-08-28 11:20:38,006:INFO:Uploading model into container now
2024-08-28 11:20:38,006:INFO:_master_model_container: 9
2024-08-28 11:20:38,006:INFO:_display_container: 2
2024-08-28 11:20:38,007:INFO:PassiveAggressiveRegressor(random_state=123)
2024-08-28 11:20:38,007:INFO:create_model() successfully completed......................................
2024-08-28 11:20:38,143:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:38,143:INFO:Creating metrics dataframe
2024-08-28 11:20:38,149:INFO:Initializing Huber Regressor
2024-08-28 11:20:38,149:INFO:Total runtime is 0.16171931425730388 minutes
2024-08-28 11:20:38,153:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:38,153:INFO:Initializing create_model()
2024-08-28 11:20:38,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:38,153:INFO:Checking exceptions
2024-08-28 11:20:38,153:INFO:Importing libraries
2024-08-28 11:20:38,153:INFO:Copying training dataset
2024-08-28 11:20:38,159:INFO:Defining folds
2024-08-28 11:20:38,160:INFO:Declaring metric variables
2024-08-28 11:20:38,163:INFO:Importing untrained model
2024-08-28 11:20:38,166:INFO:Huber Regressor Imported successfully
2024-08-28 11:20:38,171:INFO:Starting cross validation
2024-08-28 11:20:38,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:38,292:INFO:Calculating mean and std
2024-08-28 11:20:38,293:INFO:Creating metrics dataframe
2024-08-28 11:20:38,295:INFO:Uploading results into container
2024-08-28 11:20:38,295:INFO:Uploading model into container now
2024-08-28 11:20:38,296:INFO:_master_model_container: 10
2024-08-28 11:20:38,296:INFO:_display_container: 2
2024-08-28 11:20:38,296:INFO:HuberRegressor()
2024-08-28 11:20:38,296:INFO:create_model() successfully completed......................................
2024-08-28 11:20:38,435:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:38,435:INFO:Creating metrics dataframe
2024-08-28 11:20:38,443:INFO:Initializing K Neighbors Regressor
2024-08-28 11:20:38,443:INFO:Total runtime is 0.1666166623433431 minutes
2024-08-28 11:20:38,446:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:38,446:INFO:Initializing create_model()
2024-08-28 11:20:38,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:38,446:INFO:Checking exceptions
2024-08-28 11:20:38,447:INFO:Importing libraries
2024-08-28 11:20:38,447:INFO:Copying training dataset
2024-08-28 11:20:38,453:INFO:Defining folds
2024-08-28 11:20:38,453:INFO:Declaring metric variables
2024-08-28 11:20:38,456:INFO:Importing untrained model
2024-08-28 11:20:38,459:INFO:K Neighbors Regressor Imported successfully
2024-08-28 11:20:38,465:INFO:Starting cross validation
2024-08-28 11:20:38,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:38,659:INFO:Calculating mean and std
2024-08-28 11:20:38,660:INFO:Creating metrics dataframe
2024-08-28 11:20:38,660:INFO:Uploading results into container
2024-08-28 11:20:38,662:INFO:Uploading model into container now
2024-08-28 11:20:38,662:INFO:_master_model_container: 11
2024-08-28 11:20:38,662:INFO:_display_container: 2
2024-08-28 11:20:38,662:INFO:KNeighborsRegressor(n_jobs=-1)
2024-08-28 11:20:38,663:INFO:create_model() successfully completed......................................
2024-08-28 11:20:38,796:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:38,796:INFO:Creating metrics dataframe
2024-08-28 11:20:38,804:INFO:Initializing Decision Tree Regressor
2024-08-28 11:20:38,804:INFO:Total runtime is 0.17263404925664266 minutes
2024-08-28 11:20:38,806:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:38,807:INFO:Initializing create_model()
2024-08-28 11:20:38,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:38,807:INFO:Checking exceptions
2024-08-28 11:20:38,807:INFO:Importing libraries
2024-08-28 11:20:38,807:INFO:Copying training dataset
2024-08-28 11:20:38,813:INFO:Defining folds
2024-08-28 11:20:38,813:INFO:Declaring metric variables
2024-08-28 11:20:38,816:INFO:Importing untrained model
2024-08-28 11:20:38,820:INFO:Decision Tree Regressor Imported successfully
2024-08-28 11:20:38,824:INFO:Starting cross validation
2024-08-28 11:20:38,825:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:38,926:INFO:Calculating mean and std
2024-08-28 11:20:38,928:INFO:Creating metrics dataframe
2024-08-28 11:20:38,929:INFO:Uploading results into container
2024-08-28 11:20:38,930:INFO:Uploading model into container now
2024-08-28 11:20:38,930:INFO:_master_model_container: 12
2024-08-28 11:20:38,930:INFO:_display_container: 2
2024-08-28 11:20:38,930:INFO:DecisionTreeRegressor(random_state=123)
2024-08-28 11:20:38,930:INFO:create_model() successfully completed......................................
2024-08-28 11:20:39,067:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:39,067:INFO:Creating metrics dataframe
2024-08-28 11:20:39,074:INFO:Initializing Random Forest Regressor
2024-08-28 11:20:39,074:INFO:Total runtime is 0.17713791131973267 minutes
2024-08-28 11:20:39,076:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:39,077:INFO:Initializing create_model()
2024-08-28 11:20:39,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:39,077:INFO:Checking exceptions
2024-08-28 11:20:39,077:INFO:Importing libraries
2024-08-28 11:20:39,077:INFO:Copying training dataset
2024-08-28 11:20:39,083:INFO:Defining folds
2024-08-28 11:20:39,083:INFO:Declaring metric variables
2024-08-28 11:20:39,086:INFO:Importing untrained model
2024-08-28 11:20:39,090:INFO:Random Forest Regressor Imported successfully
2024-08-28 11:20:39,094:INFO:Starting cross validation
2024-08-28 11:20:39,096:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:41,772:INFO:Calculating mean and std
2024-08-28 11:20:41,773:INFO:Creating metrics dataframe
2024-08-28 11:20:41,775:INFO:Uploading results into container
2024-08-28 11:20:41,776:INFO:Uploading model into container now
2024-08-28 11:20:41,776:INFO:_master_model_container: 13
2024-08-28 11:20:41,776:INFO:_display_container: 2
2024-08-28 11:20:41,776:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:20:41,777:INFO:create_model() successfully completed......................................
2024-08-28 11:20:41,914:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:41,914:INFO:Creating metrics dataframe
2024-08-28 11:20:41,922:INFO:Initializing Extra Trees Regressor
2024-08-28 11:20:41,922:INFO:Total runtime is 0.2246038794517517 minutes
2024-08-28 11:20:41,925:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:41,925:INFO:Initializing create_model()
2024-08-28 11:20:41,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:41,925:INFO:Checking exceptions
2024-08-28 11:20:41,925:INFO:Importing libraries
2024-08-28 11:20:41,925:INFO:Copying training dataset
2024-08-28 11:20:41,931:INFO:Defining folds
2024-08-28 11:20:41,932:INFO:Declaring metric variables
2024-08-28 11:20:41,935:INFO:Importing untrained model
2024-08-28 11:20:41,939:INFO:Extra Trees Regressor Imported successfully
2024-08-28 11:20:41,944:INFO:Starting cross validation
2024-08-28 11:20:41,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:43,451:INFO:Calculating mean and std
2024-08-28 11:20:43,452:INFO:Creating metrics dataframe
2024-08-28 11:20:43,454:INFO:Uploading results into container
2024-08-28 11:20:43,454:INFO:Uploading model into container now
2024-08-28 11:20:43,454:INFO:_master_model_container: 14
2024-08-28 11:20:43,455:INFO:_display_container: 2
2024-08-28 11:20:43,455:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:20:43,455:INFO:create_model() successfully completed......................................
2024-08-28 11:20:43,590:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:43,590:INFO:Creating metrics dataframe
2024-08-28 11:20:43,599:INFO:Initializing AdaBoost Regressor
2024-08-28 11:20:43,600:INFO:Total runtime is 0.25255226691563926 minutes
2024-08-28 11:20:43,603:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:43,603:INFO:Initializing create_model()
2024-08-28 11:20:43,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:43,603:INFO:Checking exceptions
2024-08-28 11:20:43,603:INFO:Importing libraries
2024-08-28 11:20:43,603:INFO:Copying training dataset
2024-08-28 11:20:43,610:INFO:Defining folds
2024-08-28 11:20:43,610:INFO:Declaring metric variables
2024-08-28 11:20:43,612:INFO:Importing untrained model
2024-08-28 11:20:43,615:INFO:AdaBoost Regressor Imported successfully
2024-08-28 11:20:43,620:INFO:Starting cross validation
2024-08-28 11:20:43,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:44,026:INFO:Calculating mean and std
2024-08-28 11:20:44,027:INFO:Creating metrics dataframe
2024-08-28 11:20:44,028:INFO:Uploading results into container
2024-08-28 11:20:44,029:INFO:Uploading model into container now
2024-08-28 11:20:44,029:INFO:_master_model_container: 15
2024-08-28 11:20:44,029:INFO:_display_container: 2
2024-08-28 11:20:44,029:INFO:AdaBoostRegressor(random_state=123)
2024-08-28 11:20:44,030:INFO:create_model() successfully completed......................................
2024-08-28 11:20:44,164:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:44,164:INFO:Creating metrics dataframe
2024-08-28 11:20:44,172:INFO:Initializing Gradient Boosting Regressor
2024-08-28 11:20:44,172:INFO:Total runtime is 0.26209458510080974 minutes
2024-08-28 11:20:44,174:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:44,174:INFO:Initializing create_model()
2024-08-28 11:20:44,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:44,174:INFO:Checking exceptions
2024-08-28 11:20:44,175:INFO:Importing libraries
2024-08-28 11:20:44,175:INFO:Copying training dataset
2024-08-28 11:20:44,181:INFO:Defining folds
2024-08-28 11:20:44,181:INFO:Declaring metric variables
2024-08-28 11:20:44,184:INFO:Importing untrained model
2024-08-28 11:20:44,187:INFO:Gradient Boosting Regressor Imported successfully
2024-08-28 11:20:44,193:INFO:Starting cross validation
2024-08-28 11:20:44,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:44,844:INFO:Calculating mean and std
2024-08-28 11:20:44,845:INFO:Creating metrics dataframe
2024-08-28 11:20:44,847:INFO:Uploading results into container
2024-08-28 11:20:44,847:INFO:Uploading model into container now
2024-08-28 11:20:44,847:INFO:_master_model_container: 16
2024-08-28 11:20:44,848:INFO:_display_container: 2
2024-08-28 11:20:44,848:INFO:GradientBoostingRegressor(random_state=123)
2024-08-28 11:20:44,848:INFO:create_model() successfully completed......................................
2024-08-28 11:20:44,985:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:44,985:INFO:Creating metrics dataframe
2024-08-28 11:20:44,994:INFO:Initializing Extreme Gradient Boosting
2024-08-28 11:20:44,994:INFO:Total runtime is 0.2757942795753479 minutes
2024-08-28 11:20:44,997:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:44,997:INFO:Initializing create_model()
2024-08-28 11:20:44,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:44,997:INFO:Checking exceptions
2024-08-28 11:20:44,997:INFO:Importing libraries
2024-08-28 11:20:44,997:INFO:Copying training dataset
2024-08-28 11:20:45,003:INFO:Defining folds
2024-08-28 11:20:45,003:INFO:Declaring metric variables
2024-08-28 11:20:45,006:INFO:Importing untrained model
2024-08-28 11:20:45,010:INFO:Extreme Gradient Boosting Imported successfully
2024-08-28 11:20:45,014:INFO:Starting cross validation
2024-08-28 11:20:45,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:45,567:INFO:Calculating mean and std
2024-08-28 11:20:45,568:INFO:Creating metrics dataframe
2024-08-28 11:20:45,570:INFO:Uploading results into container
2024-08-28 11:20:45,570:INFO:Uploading model into container now
2024-08-28 11:20:45,570:INFO:_master_model_container: 17
2024-08-28 11:20:45,570:INFO:_display_container: 2
2024-08-28 11:20:45,571:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-08-28 11:20:45,571:INFO:create_model() successfully completed......................................
2024-08-28 11:20:45,708:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:45,708:INFO:Creating metrics dataframe
2024-08-28 11:20:45,716:INFO:Initializing Light Gradient Boosting Machine
2024-08-28 11:20:45,716:INFO:Total runtime is 0.28784035046895345 minutes
2024-08-28 11:20:45,719:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:45,719:INFO:Initializing create_model()
2024-08-28 11:20:45,719:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:45,719:INFO:Checking exceptions
2024-08-28 11:20:45,719:INFO:Importing libraries
2024-08-28 11:20:45,719:INFO:Copying training dataset
2024-08-28 11:20:45,726:INFO:Defining folds
2024-08-28 11:20:45,726:INFO:Declaring metric variables
2024-08-28 11:20:45,729:INFO:Importing untrained model
2024-08-28 11:20:45,732:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:20:45,738:INFO:Starting cross validation
2024-08-28 11:20:45,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:46,762:INFO:Calculating mean and std
2024-08-28 11:20:46,764:INFO:Creating metrics dataframe
2024-08-28 11:20:46,766:INFO:Uploading results into container
2024-08-28 11:20:46,766:INFO:Uploading model into container now
2024-08-28 11:20:46,767:INFO:_master_model_container: 18
2024-08-28 11:20:46,767:INFO:_display_container: 2
2024-08-28 11:20:46,767:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:20:46,767:INFO:create_model() successfully completed......................................
2024-08-28 11:20:46,935:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:46,935:INFO:Creating metrics dataframe
2024-08-28 11:20:46,944:INFO:Initializing Dummy Regressor
2024-08-28 11:20:46,944:INFO:Total runtime is 0.308292285601298 minutes
2024-08-28 11:20:46,948:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:46,948:INFO:Initializing create_model()
2024-08-28 11:20:46,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D45E9890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:46,948:INFO:Checking exceptions
2024-08-28 11:20:46,948:INFO:Importing libraries
2024-08-28 11:20:46,948:INFO:Copying training dataset
2024-08-28 11:20:46,954:INFO:Defining folds
2024-08-28 11:20:46,954:INFO:Declaring metric variables
2024-08-28 11:20:46,957:INFO:Importing untrained model
2024-08-28 11:20:46,961:INFO:Dummy Regressor Imported successfully
2024-08-28 11:20:46,966:INFO:Starting cross validation
2024-08-28 11:20:46,966:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:47,051:INFO:Calculating mean and std
2024-08-28 11:20:47,052:INFO:Creating metrics dataframe
2024-08-28 11:20:47,053:INFO:Uploading results into container
2024-08-28 11:20:47,055:INFO:Uploading model into container now
2024-08-28 11:20:47,055:INFO:_master_model_container: 19
2024-08-28 11:20:47,055:INFO:_display_container: 2
2024-08-28 11:20:47,056:INFO:DummyRegressor()
2024-08-28 11:20:47,056:INFO:create_model() successfully completed......................................
2024-08-28 11:20:47,192:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:47,192:INFO:Creating metrics dataframe
2024-08-28 11:20:47,208:INFO:Initializing create_model()
2024-08-28 11:20:47,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:47,209:INFO:Checking exceptions
2024-08-28 11:20:47,210:INFO:Importing libraries
2024-08-28 11:20:47,210:INFO:Copying training dataset
2024-08-28 11:20:47,216:INFO:Defining folds
2024-08-28 11:20:47,216:INFO:Declaring metric variables
2024-08-28 11:20:47,216:INFO:Importing untrained model
2024-08-28 11:20:47,216:INFO:Declaring custom model
2024-08-28 11:20:47,216:INFO:Huber Regressor Imported successfully
2024-08-28 11:20:47,217:INFO:Cross validation set to False
2024-08-28 11:20:47,217:INFO:Fitting Model
2024-08-28 11:20:47,273:INFO:HuberRegressor()
2024-08-28 11:20:47,273:INFO:create_model() successfully completed......................................
2024-08-28 11:20:47,439:INFO:_master_model_container: 19
2024-08-28 11:20:47,440:INFO:_display_container: 2
2024-08-28 11:20:47,440:INFO:HuberRegressor()
2024-08-28 11:20:47,440:INFO:compare_models() successfully completed......................................
2024-08-28 11:20:47,440:INFO:Initializing create_model()
2024-08-28 11:20:47,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:47,440:INFO:Checking exceptions
2024-08-28 11:20:47,454:INFO:Importing libraries
2024-08-28 11:20:47,455:INFO:Copying training dataset
2024-08-28 11:20:47,464:INFO:Defining folds
2024-08-28 11:20:47,464:INFO:Declaring metric variables
2024-08-28 11:20:47,468:INFO:Importing untrained model
2024-08-28 11:20:47,468:INFO:Declaring custom model
2024-08-28 11:20:47,472:INFO:Huber Regressor Imported successfully
2024-08-28 11:20:47,478:INFO:Starting cross validation
2024-08-28 11:20:47,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:47,626:INFO:Calculating mean and std
2024-08-28 11:20:47,626:INFO:Creating metrics dataframe
2024-08-28 11:20:47,630:INFO:Finalizing model
2024-08-28 11:20:47,677:INFO:Uploading results into container
2024-08-28 11:20:47,677:INFO:Uploading model into container now
2024-08-28 11:20:47,688:INFO:_master_model_container: 20
2024-08-28 11:20:47,689:INFO:_display_container: 3
2024-08-28 11:20:47,689:INFO:HuberRegressor()
2024-08-28 11:20:47,690:INFO:create_model() successfully completed......................................
2024-08-28 11:20:47,838:INFO:Initializing tune_model()
2024-08-28 11:20:47,838:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=HuberRegressor(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-28 11:20:47,839:INFO:Checking exceptions
2024-08-28 11:20:47,851:INFO:Copying training dataset
2024-08-28 11:20:47,855:INFO:Checking base model
2024-08-28 11:20:47,855:INFO:Base model : Huber Regressor
2024-08-28 11:20:47,857:INFO:Declaring metric variables
2024-08-28 11:20:47,860:INFO:Defining Hyperparameters
2024-08-28 11:20:48,002:INFO:Tuning with n_jobs=-1
2024-08-28 11:20:48,002:INFO:Initializing RandomizedSearchCV
2024-08-28 11:20:48,620:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__epsilon': 1.4, 'actual_estimator__alpha': 0.01}
2024-08-28 11:20:48,620:INFO:Hyperparameter search completed
2024-08-28 11:20:48,620:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:48,620:INFO:Initializing create_model()
2024-08-28 11:20:48,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155C152DBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'epsilon': 1.4, 'alpha': 0.01})
2024-08-28 11:20:48,620:INFO:Checking exceptions
2024-08-28 11:20:48,620:INFO:Importing libraries
2024-08-28 11:20:48,620:INFO:Copying training dataset
2024-08-28 11:20:48,625:INFO:Defining folds
2024-08-28 11:20:48,625:INFO:Declaring metric variables
2024-08-28 11:20:48,628:INFO:Importing untrained model
2024-08-28 11:20:48,628:INFO:Declaring custom model
2024-08-28 11:20:48,630:INFO:Huber Regressor Imported successfully
2024-08-28 11:20:48,635:INFO:Starting cross validation
2024-08-28 11:20:48,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:48,723:INFO:Calculating mean and std
2024-08-28 11:20:48,723:INFO:Creating metrics dataframe
2024-08-28 11:20:48,727:INFO:Finalizing model
2024-08-28 11:20:48,756:INFO:Uploading results into container
2024-08-28 11:20:48,757:INFO:Uploading model into container now
2024-08-28 11:20:48,758:INFO:_master_model_container: 21
2024-08-28 11:20:48,758:INFO:_display_container: 4
2024-08-28 11:20:48,758:INFO:HuberRegressor(alpha=0.01, epsilon=1.4)
2024-08-28 11:20:48,758:INFO:create_model() successfully completed......................................
2024-08-28 11:20:48,903:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:48,903:INFO:choose_better activated
2024-08-28 11:20:48,905:INFO:SubProcess create_model() called ==================================
2024-08-28 11:20:48,906:INFO:Initializing create_model()
2024-08-28 11:20:48,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:48,906:INFO:Checking exceptions
2024-08-28 11:20:48,908:INFO:Importing libraries
2024-08-28 11:20:48,908:INFO:Copying training dataset
2024-08-28 11:20:48,913:INFO:Defining folds
2024-08-28 11:20:48,913:INFO:Declaring metric variables
2024-08-28 11:20:48,913:INFO:Importing untrained model
2024-08-28 11:20:48,913:INFO:Declaring custom model
2024-08-28 11:20:48,913:INFO:Huber Regressor Imported successfully
2024-08-28 11:20:48,913:INFO:Starting cross validation
2024-08-28 11:20:48,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:20:49,026:INFO:Calculating mean and std
2024-08-28 11:20:49,026:INFO:Creating metrics dataframe
2024-08-28 11:20:49,027:INFO:Finalizing model
2024-08-28 11:20:49,072:INFO:Uploading results into container
2024-08-28 11:20:49,073:INFO:Uploading model into container now
2024-08-28 11:20:49,073:INFO:_master_model_container: 22
2024-08-28 11:20:49,073:INFO:_display_container: 5
2024-08-28 11:20:49,073:INFO:HuberRegressor()
2024-08-28 11:20:49,073:INFO:create_model() successfully completed......................................
2024-08-28 11:20:49,209:INFO:SubProcess create_model() end ==================================
2024-08-28 11:20:49,209:INFO:HuberRegressor() result for R2 is 0.1734
2024-08-28 11:20:49,209:INFO:HuberRegressor(alpha=0.01, epsilon=1.4) result for R2 is 0.1524
2024-08-28 11:20:49,210:INFO:HuberRegressor() is best model
2024-08-28 11:20:49,210:INFO:choose_better completed
2024-08-28 11:20:49,210:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-08-28 11:20:49,225:INFO:_master_model_container: 22
2024-08-28 11:20:49,225:INFO:_display_container: 4
2024-08-28 11:20:49,226:INFO:HuberRegressor()
2024-08-28 11:20:49,226:INFO:tune_model() successfully completed......................................
2024-08-28 11:20:49,385:INFO:Initializing finalize_model()
2024-08-28 11:20:49,385:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=HuberRegressor(), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-28 11:20:49,386:INFO:Finalizing HuberRegressor()
2024-08-28 11:20:49,390:INFO:Initializing create_model()
2024-08-28 11:20:49,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:20:49,390:INFO:Checking exceptions
2024-08-28 11:20:49,391:INFO:Importing libraries
2024-08-28 11:20:49,391:INFO:Copying training dataset
2024-08-28 11:20:49,391:INFO:Defining folds
2024-08-28 11:20:49,392:INFO:Declaring metric variables
2024-08-28 11:20:49,392:INFO:Importing untrained model
2024-08-28 11:20:49,392:INFO:Declaring custom model
2024-08-28 11:20:49,392:INFO:Huber Regressor Imported successfully
2024-08-28 11:20:49,392:INFO:Cross validation set to False
2024-08-28 11:20:49,393:INFO:Fitting Model
2024-08-28 11:20:49,443:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Gender', '10percentage',
                                             '12graduation', '12percentage',
                                             'CollegeTier', 'Degree',
                                             'Specialization', 'collegeGPA',
                                             'CollegeCityTier', 'CollegeState',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerProgramming',
                                             'ElectronicsAndSemicon',
                                             'ComputerScience',
                                             'MechanicalEngg', 'ElectricalEngg',
                                             'TelecomEngg', 'CivilEngg',
                                             'conscientiousness',
                                             'agreeableness', 'extraversion',
                                             'nueroticism',
                                             'openess_to_experience',
                                             'birth_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', HuberRegressor())])
2024-08-28 11:20:49,444:INFO:create_model() successfully completed......................................
2024-08-28 11:20:49,585:INFO:_master_model_container: 22
2024-08-28 11:20:49,585:INFO:_display_container: 4
2024-08-28 11:20:49,588:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Gender', '10percentage',
                                             '12graduation', '12percentage',
                                             'CollegeTier', 'Degree',
                                             'Specialization', 'collegeGPA',
                                             'CollegeCityTier', 'CollegeState',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerProgramming',
                                             'ElectronicsAndSemicon',
                                             'ComputerScience',
                                             'MechanicalEngg', 'ElectricalEngg',
                                             'TelecomEngg', 'CivilEngg',
                                             'conscientiousness',
                                             'agreeableness', 'extraversion',
                                             'nueroticism',
                                             'openess_to_experience',
                                             'birth_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', HuberRegressor())])
2024-08-28 11:20:49,589:INFO:finalize_model() successfully completed......................................
2024-08-28 11:20:49,731:INFO:Initializing predict_model()
2024-08-28 11:20:49,731:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Gender', '10percentage',
                                             '12graduation', '12percentage',
                                             'CollegeTier', 'Degree',
                                             'Specialization', 'collegeGPA',
                                             'CollegeCityTier', 'CollegeState',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerProgramming',
                                             'ElectronicsAndSemicon',
                                             'ComputerScience',
                                             'MechanicalEngg', 'ElectricalEngg',
                                             'TelecomEngg', 'CivilEngg',
                                             'conscientiousness',
                                             'agreeableness', 'extraversion',
                                             'nueroticism',
                                             'openess_to_experience',
                                             'birth_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', HuberRegressor())]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000155C10E2E80>)
2024-08-28 11:20:49,731:INFO:Checking exceptions
2024-08-28 11:20:49,731:INFO:Preloading libraries
2024-08-28 11:20:49,733:INFO:Set up data.
2024-08-28 11:20:49,738:INFO:Set up index.
2024-08-28 11:20:49,888:INFO:Initializing evaluate_model()
2024-08-28 11:20:49,888:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Gender', '10percentage',
                                             '12graduation', '12percentage',
                                             'CollegeTier', 'Degree',
                                             'Specialization', 'collegeGPA',
                                             'CollegeCityTier', 'CollegeState',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerProgramming',
                                             'ElectronicsAndSemicon',
                                             'ComputerScience',
                                             'MechanicalEngg', 'ElectricalEngg',
                                             'TelecomEngg', 'CivilEngg',
                                             'conscientiousness',
                                             'agreeableness', 'extraversion',
                                             'nueroticism',
                                             'openess_to_experience',
                                             'birth_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', HuberRegressor())]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-08-28 11:20:49,901:INFO:Initializing plot_model()
2024-08-28 11:20:49,901:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D38A9A90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Gender', '10percentage',
                                             '12graduation', '12percentage',
                                             'CollegeTier', 'Degree',
                                             'Specialization', 'collegeGPA',
                                             'CollegeCityTier', 'CollegeState',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerProgramming',
                                             'ElectronicsAndSemicon',
                                             'ComputerScience',
                                             'MechanicalEngg', 'ElectricalEngg',
                                             'TelecomEngg', 'CivilEngg',
                                             'conscientiousness',
                                             'agreeableness', 'extraversion',
                                             'nueroticism',
                                             'openess_to_experience',
                                             'birth_year'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', HuberRegressor())]), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2024-08-28 11:20:49,901:INFO:Checking exceptions
2024-08-28 11:20:49,903:INFO:Preloading libraries
2024-08-28 11:20:49,903:INFO:Copying training dataset
2024-08-28 11:20:49,903:INFO:Plot type: pipeline
2024-08-28 11:20:49,962:INFO:Visual Rendered Successfully
2024-08-28 11:20:50,097:INFO:plot_model() successfully completed......................................
2024-08-28 11:21:43,543:INFO:PyCaret RegressionExperiment
2024-08-28 11:21:43,543:INFO:Logging name: reg-default-name
2024-08-28 11:21:43,543:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-28 11:21:43,543:INFO:version 3.3.2
2024-08-28 11:21:43,543:INFO:Initializing setup()
2024-08-28 11:21:43,543:INFO:self.USI: 9577
2024-08-28 11:21:43,543:INFO:self._variable_keys: {'data', 'html_param', 'pipeline', '_ml_usecase', 'y', 'X_test', 'exp_name_log', 'gpu_param', 'X_train', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'fold_generator', 'seed', 'USI', 'memory', 'fold_groups_param', 'idx', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'y_train', 'target_param'}
2024-08-28 11:21:43,543:INFO:Checking environment
2024-08-28 11:21:43,543:INFO:python_version: 3.11.9
2024-08-28 11:21:43,544:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 11:21:43,544:INFO:machine: AMD64
2024-08-28 11:21:43,544:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 11:21:43,550:INFO:Memory: svmem(total=16867028992, available=4332232704, percent=74.3, used=12534796288, free=4332232704)
2024-08-28 11:21:43,550:INFO:Physical Core: 6
2024-08-28 11:21:43,551:INFO:Logical Core: 12
2024-08-28 11:21:43,551:INFO:Checking libraries
2024-08-28 11:21:43,551:INFO:System:
2024-08-28 11:21:43,551:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 11:21:43,551:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 11:21:43,551:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 11:21:43,551:INFO:PyCaret required dependencies:
2024-08-28 11:21:43,551:INFO:                 pip: 23.2.1
2024-08-28 11:21:43,551:INFO:          setuptools: 67.8.0
2024-08-28 11:21:43,551:INFO:             pycaret: 3.3.2
2024-08-28 11:21:43,551:INFO:             IPython: 8.14.0
2024-08-28 11:21:43,551:INFO:          ipywidgets: 8.1.5
2024-08-28 11:21:43,551:INFO:                tqdm: 4.66.5
2024-08-28 11:21:43,551:INFO:               numpy: 1.24.3
2024-08-28 11:21:43,551:INFO:              pandas: 2.0.3
2024-08-28 11:21:43,552:INFO:              jinja2: 3.1.4
2024-08-28 11:21:43,552:INFO:               scipy: 1.10.1
2024-08-28 11:21:43,552:INFO:              joblib: 1.2.0
2024-08-28 11:21:43,552:INFO:             sklearn: 1.4.2
2024-08-28 11:21:43,552:INFO:                pyod: 2.0.1
2024-08-28 11:21:43,552:INFO:            imblearn: 0.12.3
2024-08-28 11:21:43,552:INFO:   category_encoders: 2.6.3
2024-08-28 11:21:43,552:INFO:            lightgbm: 4.5.0
2024-08-28 11:21:43,552:INFO:               numba: 0.60.0
2024-08-28 11:21:43,552:INFO:            requests: 2.32.3
2024-08-28 11:21:43,552:INFO:          matplotlib: 3.7.1
2024-08-28 11:21:43,552:INFO:          scikitplot: 0.3.7
2024-08-28 11:21:43,552:INFO:         yellowbrick: 1.5
2024-08-28 11:21:43,552:INFO:              plotly: 5.16.1
2024-08-28 11:21:43,552:INFO:    plotly-resampler: Not installed
2024-08-28 11:21:43,552:INFO:             kaleido: 0.2.1
2024-08-28 11:21:43,552:INFO:           schemdraw: 0.15
2024-08-28 11:21:43,552:INFO:         statsmodels: 0.14.2
2024-08-28 11:21:43,552:INFO:              sktime: 0.26.0
2024-08-28 11:21:43,552:INFO:               tbats: 1.1.3
2024-08-28 11:21:43,552:INFO:            pmdarima: 2.0.4
2024-08-28 11:21:43,553:INFO:              psutil: 5.9.0
2024-08-28 11:21:43,553:INFO:          markupsafe: 2.1.3
2024-08-28 11:21:43,553:INFO:             pickle5: Not installed
2024-08-28 11:21:43,553:INFO:         cloudpickle: 3.0.0
2024-08-28 11:21:43,553:INFO:         deprecation: 2.1.0
2024-08-28 11:21:43,553:INFO:              xxhash: 3.5.0
2024-08-28 11:21:43,553:INFO:           wurlitzer: Not installed
2024-08-28 11:21:43,553:INFO:PyCaret optional dependencies:
2024-08-28 11:21:43,553:INFO:                shap: Not installed
2024-08-28 11:21:43,553:INFO:           interpret: Not installed
2024-08-28 11:21:43,553:INFO:                umap: Not installed
2024-08-28 11:21:43,553:INFO:     ydata_profiling: Not installed
2024-08-28 11:21:43,553:INFO:  explainerdashboard: Not installed
2024-08-28 11:21:43,553:INFO:             autoviz: Not installed
2024-08-28 11:21:43,553:INFO:           fairlearn: Not installed
2024-08-28 11:21:43,553:INFO:          deepchecks: Not installed
2024-08-28 11:21:43,553:INFO:             xgboost: 2.0.2
2024-08-28 11:21:43,553:INFO:            catboost: Not installed
2024-08-28 11:21:43,553:INFO:              kmodes: Not installed
2024-08-28 11:21:43,553:INFO:             mlxtend: Not installed
2024-08-28 11:21:43,553:INFO:       statsforecast: Not installed
2024-08-28 11:21:43,553:INFO:        tune_sklearn: Not installed
2024-08-28 11:21:43,553:INFO:                 ray: Not installed
2024-08-28 11:21:43,554:INFO:            hyperopt: Not installed
2024-08-28 11:21:43,554:INFO:              optuna: Not installed
2024-08-28 11:21:43,554:INFO:               skopt: Not installed
2024-08-28 11:21:43,554:INFO:              mlflow: Not installed
2024-08-28 11:21:43,554:INFO:              gradio: 4.41.0
2024-08-28 11:21:43,554:INFO:             fastapi: 0.112.1
2024-08-28 11:21:43,554:INFO:             uvicorn: 0.30.6
2024-08-28 11:21:43,554:INFO:              m2cgen: Not installed
2024-08-28 11:21:43,554:INFO:           evidently: Not installed
2024-08-28 11:21:43,554:INFO:               fugue: Not installed
2024-08-28 11:21:43,554:INFO:           streamlit: Not installed
2024-08-28 11:21:43,554:INFO:             prophet: Not installed
2024-08-28 11:21:43,554:INFO:None
2024-08-28 11:21:43,554:INFO:Set up data.
2024-08-28 11:21:43,573:INFO:Set up folding strategy.
2024-08-28 11:21:43,573:INFO:Set up train/test split.
2024-08-28 11:21:43,589:INFO:Set up index.
2024-08-28 11:21:43,589:INFO:Assigning column types.
2024-08-28 11:21:43,597:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-28 11:21:43,597:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,602:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,608:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,711:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,712:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:43,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:43,716:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,724:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,732:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,844:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:43,847:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:43,847:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-28 11:21:43,851:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,855:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,948:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,948:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:43,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:43,954:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 11:21:43,958:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,046:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,047:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,049:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-28 11:21:44,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,105:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,140:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,150:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,201:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,238:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,241:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-28 11:21:44,300:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,339:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,440:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,442:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-28 11:21:44,502:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,537:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 11:21:44,635:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,637:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-28 11:21:44,730:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,826:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:44,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:44,829:INFO:Preparing preprocessing pipeline...
2024-08-28 11:21:44,829:INFO:Set up date feature engineering.
2024-08-28 11:21:44,829:INFO:Set up simple imputation.
2024-08-28 11:21:44,834:INFO:Set up encoding of ordinal features.
2024-08-28 11:21:44,837:INFO:Set up encoding of categorical features.
2024-08-28 11:21:44,965:INFO:Finished creating preprocessing pipeline.
2024-08-28 11:21:44,983:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['DOB'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['10percentage', '12graduation',
                                             '12percentage', 'CollegeTier',
                                             'collegeGPA', 'CollegeCityTier',
                                             'GraduationYear', 'English...
                ('onehot_encoding',
                 TransformerWrapper(include=['Degree'],
                                    transformer=OneHotEncoder(cols=['Degree'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['10board', '12board',
                                             'Specialization', 'CollegeState'],
                                    transformer=TargetEncoder(cols=['10board',
                                                                    '12board',
                                                                    'Specialization',
                                                                    'CollegeState'],
                                                              handle_missing='return_nan')))])
2024-08-28 11:21:44,983:INFO:Creating final display dataframe.
2024-08-28 11:21:45,340:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            Salary
2                   Target type        Regression
3           Original data shape        (2998, 32)
4        Transformed data shape        (2998, 36)
5   Transformed train set shape        (2098, 36)
6    Transformed test set shape         (900, 36)
7              Numeric features                24
8                 Date features                 1
9          Categorical features                 6
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              9577
2024-08-28 11:21:45,441:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:45,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:45,539:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 11:21:45,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 11:21:45,542:INFO:setup() successfully completed in 2.0s...............
2024-08-28 11:21:45,542:INFO:Initializing compare_models()
2024-08-28 11:21:45,542:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-08-28 11:21:45,543:INFO:Checking exceptions
2024-08-28 11:21:45,546:INFO:Preparing display monitor
2024-08-28 11:21:45,562:INFO:Initializing Linear Regression
2024-08-28 11:21:45,562:INFO:Total runtime is 0.0 minutes
2024-08-28 11:21:45,564:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:45,565:INFO:Initializing create_model()
2024-08-28 11:21:45,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:45,565:INFO:Checking exceptions
2024-08-28 11:21:45,565:INFO:Importing libraries
2024-08-28 11:21:45,565:INFO:Copying training dataset
2024-08-28 11:21:45,577:INFO:Defining folds
2024-08-28 11:21:45,577:INFO:Declaring metric variables
2024-08-28 11:21:45,582:INFO:Importing untrained model
2024-08-28 11:21:45,588:INFO:Linear Regression Imported successfully
2024-08-28 11:21:45,600:INFO:Starting cross validation
2024-08-28 11:21:45,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:46,171:INFO:Calculating mean and std
2024-08-28 11:21:46,171:INFO:Creating metrics dataframe
2024-08-28 11:21:46,172:INFO:Uploading results into container
2024-08-28 11:21:46,173:INFO:Uploading model into container now
2024-08-28 11:21:46,173:INFO:_master_model_container: 1
2024-08-28 11:21:46,173:INFO:_display_container: 2
2024-08-28 11:21:46,173:INFO:LinearRegression(n_jobs=-1)
2024-08-28 11:21:46,173:INFO:create_model() successfully completed......................................
2024-08-28 11:21:46,332:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:46,332:INFO:Creating metrics dataframe
2024-08-28 11:21:46,339:INFO:Initializing Lasso Regression
2024-08-28 11:21:46,339:INFO:Total runtime is 0.012943804264068604 minutes
2024-08-28 11:21:46,342:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:46,343:INFO:Initializing create_model()
2024-08-28 11:21:46,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:46,343:INFO:Checking exceptions
2024-08-28 11:21:46,343:INFO:Importing libraries
2024-08-28 11:21:46,343:INFO:Copying training dataset
2024-08-28 11:21:46,350:INFO:Defining folds
2024-08-28 11:21:46,350:INFO:Declaring metric variables
2024-08-28 11:21:46,353:INFO:Importing untrained model
2024-08-28 11:21:46,356:INFO:Lasso Regression Imported successfully
2024-08-28 11:21:46,361:INFO:Starting cross validation
2024-08-28 11:21:46,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:46,635:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.521e+13, tolerance: 9.273e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,644:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.786e+13, tolerance: 9.871e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,653:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.427e+13, tolerance: 9.085e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,656:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e+13, tolerance: 8.828e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,674:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.235e+13, tolerance: 8.540e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,686:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+13, tolerance: 9.779e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,688:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e+13, tolerance: 9.459e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,696:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.244e+13, tolerance: 8.415e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,785:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.747e+13, tolerance: 9.901e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,799:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.810e+13, tolerance: 9.919e+09
  model = cd_fast.enet_coordinate_descent(

2024-08-28 11:21:46,843:INFO:Calculating mean and std
2024-08-28 11:21:46,844:INFO:Creating metrics dataframe
2024-08-28 11:21:46,845:INFO:Uploading results into container
2024-08-28 11:21:46,845:INFO:Uploading model into container now
2024-08-28 11:21:46,846:INFO:_master_model_container: 2
2024-08-28 11:21:46,846:INFO:_display_container: 2
2024-08-28 11:21:46,846:INFO:Lasso(random_state=123)
2024-08-28 11:21:46,846:INFO:create_model() successfully completed......................................
2024-08-28 11:21:46,998:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:46,998:INFO:Creating metrics dataframe
2024-08-28 11:21:47,005:INFO:Initializing Ridge Regression
2024-08-28 11:21:47,005:INFO:Total runtime is 0.02405219872792562 minutes
2024-08-28 11:21:47,007:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:47,008:INFO:Initializing create_model()
2024-08-28 11:21:47,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:47,008:INFO:Checking exceptions
2024-08-28 11:21:47,008:INFO:Importing libraries
2024-08-28 11:21:47,008:INFO:Copying training dataset
2024-08-28 11:21:47,015:INFO:Defining folds
2024-08-28 11:21:47,015:INFO:Declaring metric variables
2024-08-28 11:21:47,018:INFO:Importing untrained model
2024-08-28 11:21:47,021:INFO:Ridge Regression Imported successfully
2024-08-28 11:21:47,026:INFO:Starting cross validation
2024-08-28 11:21:47,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:47,312:INFO:Calculating mean and std
2024-08-28 11:21:47,313:INFO:Creating metrics dataframe
2024-08-28 11:21:47,314:INFO:Uploading results into container
2024-08-28 11:21:47,315:INFO:Uploading model into container now
2024-08-28 11:21:47,315:INFO:_master_model_container: 3
2024-08-28 11:21:47,315:INFO:_display_container: 2
2024-08-28 11:21:47,315:INFO:Ridge(random_state=123)
2024-08-28 11:21:47,315:INFO:create_model() successfully completed......................................
2024-08-28 11:21:47,470:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:47,471:INFO:Creating metrics dataframe
2024-08-28 11:21:47,478:INFO:Initializing Elastic Net
2024-08-28 11:21:47,479:INFO:Total runtime is 0.031957558790842694 minutes
2024-08-28 11:21:47,482:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:47,482:INFO:Initializing create_model()
2024-08-28 11:21:47,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:47,482:INFO:Checking exceptions
2024-08-28 11:21:47,482:INFO:Importing libraries
2024-08-28 11:21:47,482:INFO:Copying training dataset
2024-08-28 11:21:47,491:INFO:Defining folds
2024-08-28 11:21:47,492:INFO:Declaring metric variables
2024-08-28 11:21:47,496:INFO:Importing untrained model
2024-08-28 11:21:47,499:INFO:Elastic Net Imported successfully
2024-08-28 11:21:47,504:INFO:Starting cross validation
2024-08-28 11:21:47,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:47,844:INFO:Calculating mean and std
2024-08-28 11:21:47,845:INFO:Creating metrics dataframe
2024-08-28 11:21:47,847:INFO:Uploading results into container
2024-08-28 11:21:47,847:INFO:Uploading model into container now
2024-08-28 11:21:47,848:INFO:_master_model_container: 4
2024-08-28 11:21:47,848:INFO:_display_container: 2
2024-08-28 11:21:47,848:INFO:ElasticNet(random_state=123)
2024-08-28 11:21:47,848:INFO:create_model() successfully completed......................................
2024-08-28 11:21:47,987:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:47,987:INFO:Creating metrics dataframe
2024-08-28 11:21:47,994:INFO:Initializing Least Angle Regression
2024-08-28 11:21:47,994:INFO:Total runtime is 0.040534357229868576 minutes
2024-08-28 11:21:47,997:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:47,997:INFO:Initializing create_model()
2024-08-28 11:21:47,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:47,997:INFO:Checking exceptions
2024-08-28 11:21:47,997:INFO:Importing libraries
2024-08-28 11:21:47,997:INFO:Copying training dataset
2024-08-28 11:21:48,005:INFO:Defining folds
2024-08-28 11:21:48,005:INFO:Declaring metric variables
2024-08-28 11:21:48,009:INFO:Importing untrained model
2024-08-28 11:21:48,011:INFO:Least Angle Regression Imported successfully
2024-08-28 11:21:48,017:INFO:Starting cross validation
2024-08-28 11:21:48,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:48,318:INFO:Calculating mean and std
2024-08-28 11:21:48,319:INFO:Creating metrics dataframe
2024-08-28 11:21:48,320:INFO:Uploading results into container
2024-08-28 11:21:48,321:INFO:Uploading model into container now
2024-08-28 11:21:48,321:INFO:_master_model_container: 5
2024-08-28 11:21:48,321:INFO:_display_container: 2
2024-08-28 11:21:48,322:INFO:Lars(random_state=123)
2024-08-28 11:21:48,322:INFO:create_model() successfully completed......................................
2024-08-28 11:21:48,458:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:48,458:INFO:Creating metrics dataframe
2024-08-28 11:21:48,465:INFO:Initializing Lasso Least Angle Regression
2024-08-28 11:21:48,465:INFO:Total runtime is 0.04838171799977621 minutes
2024-08-28 11:21:48,468:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:48,468:INFO:Initializing create_model()
2024-08-28 11:21:48,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:48,468:INFO:Checking exceptions
2024-08-28 11:21:48,468:INFO:Importing libraries
2024-08-28 11:21:48,469:INFO:Copying training dataset
2024-08-28 11:21:48,475:INFO:Defining folds
2024-08-28 11:21:48,475:INFO:Declaring metric variables
2024-08-28 11:21:48,479:INFO:Importing untrained model
2024-08-28 11:21:48,482:INFO:Lasso Least Angle Regression Imported successfully
2024-08-28 11:21:48,491:INFO:Starting cross validation
2024-08-28 11:21:48,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:48,810:INFO:Calculating mean and std
2024-08-28 11:21:48,811:INFO:Creating metrics dataframe
2024-08-28 11:21:48,813:INFO:Uploading results into container
2024-08-28 11:21:48,813:INFO:Uploading model into container now
2024-08-28 11:21:48,813:INFO:_master_model_container: 6
2024-08-28 11:21:48,813:INFO:_display_container: 2
2024-08-28 11:21:48,814:INFO:LassoLars(random_state=123)
2024-08-28 11:21:48,814:INFO:create_model() successfully completed......................................
2024-08-28 11:21:48,951:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:48,951:INFO:Creating metrics dataframe
2024-08-28 11:21:48,957:INFO:Initializing Orthogonal Matching Pursuit
2024-08-28 11:21:48,957:INFO:Total runtime is 0.05658665895462037 minutes
2024-08-28 11:21:48,959:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:48,960:INFO:Initializing create_model()
2024-08-28 11:21:48,960:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:48,960:INFO:Checking exceptions
2024-08-28 11:21:48,960:INFO:Importing libraries
2024-08-28 11:21:48,960:INFO:Copying training dataset
2024-08-28 11:21:48,967:INFO:Defining folds
2024-08-28 11:21:48,968:INFO:Declaring metric variables
2024-08-28 11:21:48,971:INFO:Importing untrained model
2024-08-28 11:21:48,973:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 11:21:48,979:INFO:Starting cross validation
2024-08-28 11:21:48,981:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:49,257:INFO:Calculating mean and std
2024-08-28 11:21:49,258:INFO:Creating metrics dataframe
2024-08-28 11:21:49,259:INFO:Uploading results into container
2024-08-28 11:21:49,260:INFO:Uploading model into container now
2024-08-28 11:21:49,260:INFO:_master_model_container: 7
2024-08-28 11:21:49,260:INFO:_display_container: 2
2024-08-28 11:21:49,261:INFO:OrthogonalMatchingPursuit()
2024-08-28 11:21:49,261:INFO:create_model() successfully completed......................................
2024-08-28 11:21:49,398:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:49,398:INFO:Creating metrics dataframe
2024-08-28 11:21:49,405:INFO:Initializing Bayesian Ridge
2024-08-28 11:21:49,405:INFO:Total runtime is 0.06404540141423544 minutes
2024-08-28 11:21:49,408:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:49,408:INFO:Initializing create_model()
2024-08-28 11:21:49,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:49,408:INFO:Checking exceptions
2024-08-28 11:21:49,408:INFO:Importing libraries
2024-08-28 11:21:49,408:INFO:Copying training dataset
2024-08-28 11:21:49,415:INFO:Defining folds
2024-08-28 11:21:49,415:INFO:Declaring metric variables
2024-08-28 11:21:49,417:INFO:Importing untrained model
2024-08-28 11:21:49,420:INFO:Bayesian Ridge Imported successfully
2024-08-28 11:21:49,426:INFO:Starting cross validation
2024-08-28 11:21:49,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:49,704:INFO:Calculating mean and std
2024-08-28 11:21:49,705:INFO:Creating metrics dataframe
2024-08-28 11:21:49,706:INFO:Uploading results into container
2024-08-28 11:21:49,707:INFO:Uploading model into container now
2024-08-28 11:21:49,707:INFO:_master_model_container: 8
2024-08-28 11:21:49,707:INFO:_display_container: 2
2024-08-28 11:21:49,708:INFO:BayesianRidge()
2024-08-28 11:21:49,708:INFO:create_model() successfully completed......................................
2024-08-28 11:21:49,842:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:49,842:INFO:Creating metrics dataframe
2024-08-28 11:21:49,849:INFO:Initializing Passive Aggressive Regressor
2024-08-28 11:21:49,849:INFO:Total runtime is 0.07145116726557414 minutes
2024-08-28 11:21:49,852:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:49,852:INFO:Initializing create_model()
2024-08-28 11:21:49,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:49,852:INFO:Checking exceptions
2024-08-28 11:21:49,853:INFO:Importing libraries
2024-08-28 11:21:49,853:INFO:Copying training dataset
2024-08-28 11:21:49,860:INFO:Defining folds
2024-08-28 11:21:49,860:INFO:Declaring metric variables
2024-08-28 11:21:49,863:INFO:Importing untrained model
2024-08-28 11:21:49,866:INFO:Passive Aggressive Regressor Imported successfully
2024-08-28 11:21:49,871:INFO:Starting cross validation
2024-08-28 11:21:49,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:50,199:INFO:Calculating mean and std
2024-08-28 11:21:50,200:INFO:Creating metrics dataframe
2024-08-28 11:21:50,202:INFO:Uploading results into container
2024-08-28 11:21:50,202:INFO:Uploading model into container now
2024-08-28 11:21:50,202:INFO:_master_model_container: 9
2024-08-28 11:21:50,203:INFO:_display_container: 2
2024-08-28 11:21:50,203:INFO:PassiveAggressiveRegressor(random_state=123)
2024-08-28 11:21:50,203:INFO:create_model() successfully completed......................................
2024-08-28 11:21:50,344:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:50,344:INFO:Creating metrics dataframe
2024-08-28 11:21:50,350:INFO:Initializing Huber Regressor
2024-08-28 11:21:50,350:INFO:Total runtime is 0.0798057754834493 minutes
2024-08-28 11:21:50,352:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:50,353:INFO:Initializing create_model()
2024-08-28 11:21:50,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:50,353:INFO:Checking exceptions
2024-08-28 11:21:50,353:INFO:Importing libraries
2024-08-28 11:21:50,353:INFO:Copying training dataset
2024-08-28 11:21:50,360:INFO:Defining folds
2024-08-28 11:21:50,361:INFO:Declaring metric variables
2024-08-28 11:21:50,364:INFO:Importing untrained model
2024-08-28 11:21:50,367:INFO:Huber Regressor Imported successfully
2024-08-28 11:21:50,372:INFO:Starting cross validation
2024-08-28 11:21:50,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:50,617:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:21:50,656:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:21:50,665:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:21:50,677:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:21:50,689:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 11:21:50,741:INFO:Calculating mean and std
2024-08-28 11:21:50,742:INFO:Creating metrics dataframe
2024-08-28 11:21:50,743:INFO:Uploading results into container
2024-08-28 11:21:50,743:INFO:Uploading model into container now
2024-08-28 11:21:50,744:INFO:_master_model_container: 10
2024-08-28 11:21:50,744:INFO:_display_container: 2
2024-08-28 11:21:50,744:INFO:HuberRegressor()
2024-08-28 11:21:50,744:INFO:create_model() successfully completed......................................
2024-08-28 11:21:50,881:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:50,881:INFO:Creating metrics dataframe
2024-08-28 11:21:50,888:INFO:Initializing K Neighbors Regressor
2024-08-28 11:21:50,888:INFO:Total runtime is 0.08876506884892782 minutes
2024-08-28 11:21:50,890:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:50,891:INFO:Initializing create_model()
2024-08-28 11:21:50,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:50,891:INFO:Checking exceptions
2024-08-28 11:21:50,891:INFO:Importing libraries
2024-08-28 11:21:50,891:INFO:Copying training dataset
2024-08-28 11:21:50,898:INFO:Defining folds
2024-08-28 11:21:50,898:INFO:Declaring metric variables
2024-08-28 11:21:50,901:INFO:Importing untrained model
2024-08-28 11:21:50,904:INFO:K Neighbors Regressor Imported successfully
2024-08-28 11:21:50,909:INFO:Starting cross validation
2024-08-28 11:21:50,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:51,235:INFO:Calculating mean and std
2024-08-28 11:21:51,235:INFO:Creating metrics dataframe
2024-08-28 11:21:51,238:INFO:Uploading results into container
2024-08-28 11:21:51,238:INFO:Uploading model into container now
2024-08-28 11:21:51,238:INFO:_master_model_container: 11
2024-08-28 11:21:51,239:INFO:_display_container: 2
2024-08-28 11:21:51,239:INFO:KNeighborsRegressor(n_jobs=-1)
2024-08-28 11:21:51,239:INFO:create_model() successfully completed......................................
2024-08-28 11:21:51,376:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:51,377:INFO:Creating metrics dataframe
2024-08-28 11:21:51,385:INFO:Initializing Decision Tree Regressor
2024-08-28 11:21:51,385:INFO:Total runtime is 0.09704937934875489 minutes
2024-08-28 11:21:51,388:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:51,388:INFO:Initializing create_model()
2024-08-28 11:21:51,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:51,388:INFO:Checking exceptions
2024-08-28 11:21:51,388:INFO:Importing libraries
2024-08-28 11:21:51,388:INFO:Copying training dataset
2024-08-28 11:21:51,395:INFO:Defining folds
2024-08-28 11:21:51,395:INFO:Declaring metric variables
2024-08-28 11:21:51,399:INFO:Importing untrained model
2024-08-28 11:21:51,401:INFO:Decision Tree Regressor Imported successfully
2024-08-28 11:21:51,407:INFO:Starting cross validation
2024-08-28 11:21:51,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:51,748:INFO:Calculating mean and std
2024-08-28 11:21:51,748:INFO:Creating metrics dataframe
2024-08-28 11:21:51,750:INFO:Uploading results into container
2024-08-28 11:21:51,750:INFO:Uploading model into container now
2024-08-28 11:21:51,750:INFO:_master_model_container: 12
2024-08-28 11:21:51,751:INFO:_display_container: 2
2024-08-28 11:21:51,751:INFO:DecisionTreeRegressor(random_state=123)
2024-08-28 11:21:51,751:INFO:create_model() successfully completed......................................
2024-08-28 11:21:51,888:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:51,888:INFO:Creating metrics dataframe
2024-08-28 11:21:51,898:INFO:Initializing Random Forest Regressor
2024-08-28 11:21:51,898:INFO:Total runtime is 0.10559542179107667 minutes
2024-08-28 11:21:51,901:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:51,901:INFO:Initializing create_model()
2024-08-28 11:21:51,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:51,901:INFO:Checking exceptions
2024-08-28 11:21:51,901:INFO:Importing libraries
2024-08-28 11:21:51,901:INFO:Copying training dataset
2024-08-28 11:21:51,908:INFO:Defining folds
2024-08-28 11:21:51,908:INFO:Declaring metric variables
2024-08-28 11:21:51,911:INFO:Importing untrained model
2024-08-28 11:21:51,914:INFO:Random Forest Regressor Imported successfully
2024-08-28 11:21:51,919:INFO:Starting cross validation
2024-08-28 11:21:51,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:56,064:INFO:Calculating mean and std
2024-08-28 11:21:56,065:INFO:Creating metrics dataframe
2024-08-28 11:21:56,068:INFO:Uploading results into container
2024-08-28 11:21:56,069:INFO:Uploading model into container now
2024-08-28 11:21:56,069:INFO:_master_model_container: 13
2024-08-28 11:21:56,069:INFO:_display_container: 2
2024-08-28 11:21:56,070:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:21:56,070:INFO:create_model() successfully completed......................................
2024-08-28 11:21:56,211:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:56,211:INFO:Creating metrics dataframe
2024-08-28 11:21:56,219:INFO:Initializing Extra Trees Regressor
2024-08-28 11:21:56,219:INFO:Total runtime is 0.17762506802876793 minutes
2024-08-28 11:21:56,222:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:56,222:INFO:Initializing create_model()
2024-08-28 11:21:56,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:56,222:INFO:Checking exceptions
2024-08-28 11:21:56,222:INFO:Importing libraries
2024-08-28 11:21:56,222:INFO:Copying training dataset
2024-08-28 11:21:56,229:INFO:Defining folds
2024-08-28 11:21:56,230:INFO:Declaring metric variables
2024-08-28 11:21:56,233:INFO:Importing untrained model
2024-08-28 11:21:56,236:INFO:Extra Trees Regressor Imported successfully
2024-08-28 11:21:56,241:INFO:Starting cross validation
2024-08-28 11:21:56,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:58,790:INFO:Calculating mean and std
2024-08-28 11:21:58,791:INFO:Creating metrics dataframe
2024-08-28 11:21:58,792:INFO:Uploading results into container
2024-08-28 11:21:58,793:INFO:Uploading model into container now
2024-08-28 11:21:58,793:INFO:_master_model_container: 14
2024-08-28 11:21:58,793:INFO:_display_container: 2
2024-08-28 11:21:58,794:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:21:58,794:INFO:create_model() successfully completed......................................
2024-08-28 11:21:58,935:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:58,935:INFO:Creating metrics dataframe
2024-08-28 11:21:58,943:INFO:Initializing AdaBoost Regressor
2024-08-28 11:21:58,943:INFO:Total runtime is 0.2230143427848816 minutes
2024-08-28 11:21:58,945:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:58,945:INFO:Initializing create_model()
2024-08-28 11:21:58,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:58,946:INFO:Checking exceptions
2024-08-28 11:21:58,946:INFO:Importing libraries
2024-08-28 11:21:58,946:INFO:Copying training dataset
2024-08-28 11:21:58,953:INFO:Defining folds
2024-08-28 11:21:58,953:INFO:Declaring metric variables
2024-08-28 11:21:58,957:INFO:Importing untrained model
2024-08-28 11:21:58,960:INFO:AdaBoost Regressor Imported successfully
2024-08-28 11:21:58,964:INFO:Starting cross validation
2024-08-28 11:21:58,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:21:59,712:INFO:Calculating mean and std
2024-08-28 11:21:59,713:INFO:Creating metrics dataframe
2024-08-28 11:21:59,715:INFO:Uploading results into container
2024-08-28 11:21:59,715:INFO:Uploading model into container now
2024-08-28 11:21:59,716:INFO:_master_model_container: 15
2024-08-28 11:21:59,716:INFO:_display_container: 2
2024-08-28 11:21:59,716:INFO:AdaBoostRegressor(random_state=123)
2024-08-28 11:21:59,716:INFO:create_model() successfully completed......................................
2024-08-28 11:21:59,865:INFO:SubProcess create_model() end ==================================
2024-08-28 11:21:59,865:INFO:Creating metrics dataframe
2024-08-28 11:21:59,873:INFO:Initializing Gradient Boosting Regressor
2024-08-28 11:21:59,873:INFO:Total runtime is 0.2385199546813965 minutes
2024-08-28 11:21:59,875:INFO:SubProcess create_model() called ==================================
2024-08-28 11:21:59,876:INFO:Initializing create_model()
2024-08-28 11:21:59,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:21:59,876:INFO:Checking exceptions
2024-08-28 11:21:59,876:INFO:Importing libraries
2024-08-28 11:21:59,876:INFO:Copying training dataset
2024-08-28 11:21:59,884:INFO:Defining folds
2024-08-28 11:21:59,884:INFO:Declaring metric variables
2024-08-28 11:21:59,887:INFO:Importing untrained model
2024-08-28 11:21:59,891:INFO:Gradient Boosting Regressor Imported successfully
2024-08-28 11:21:59,895:INFO:Starting cross validation
2024-08-28 11:21:59,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:22:01,242:INFO:Calculating mean and std
2024-08-28 11:22:01,243:INFO:Creating metrics dataframe
2024-08-28 11:22:01,244:INFO:Uploading results into container
2024-08-28 11:22:01,245:INFO:Uploading model into container now
2024-08-28 11:22:01,245:INFO:_master_model_container: 16
2024-08-28 11:22:01,245:INFO:_display_container: 2
2024-08-28 11:22:01,246:INFO:GradientBoostingRegressor(random_state=123)
2024-08-28 11:22:01,246:INFO:create_model() successfully completed......................................
2024-08-28 11:22:01,384:INFO:SubProcess create_model() end ==================================
2024-08-28 11:22:01,384:INFO:Creating metrics dataframe
2024-08-28 11:22:01,391:INFO:Initializing Extreme Gradient Boosting
2024-08-28 11:22:01,391:INFO:Total runtime is 0.2638200799624125 minutes
2024-08-28 11:22:01,394:INFO:SubProcess create_model() called ==================================
2024-08-28 11:22:01,394:INFO:Initializing create_model()
2024-08-28 11:22:01,394:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:22:01,394:INFO:Checking exceptions
2024-08-28 11:22:01,394:INFO:Importing libraries
2024-08-28 11:22:01,394:INFO:Copying training dataset
2024-08-28 11:22:01,402:INFO:Defining folds
2024-08-28 11:22:01,403:INFO:Declaring metric variables
2024-08-28 11:22:01,406:INFO:Importing untrained model
2024-08-28 11:22:01,409:INFO:Extreme Gradient Boosting Imported successfully
2024-08-28 11:22:01,414:INFO:Starting cross validation
2024-08-28 11:22:01,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:22:02,228:INFO:Calculating mean and std
2024-08-28 11:22:02,229:INFO:Creating metrics dataframe
2024-08-28 11:22:02,231:INFO:Uploading results into container
2024-08-28 11:22:02,232:INFO:Uploading model into container now
2024-08-28 11:22:02,232:INFO:_master_model_container: 17
2024-08-28 11:22:02,232:INFO:_display_container: 2
2024-08-28 11:22:02,233:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, random_state=123, ...)
2024-08-28 11:22:02,233:INFO:create_model() successfully completed......................................
2024-08-28 11:22:02,371:INFO:SubProcess create_model() end ==================================
2024-08-28 11:22:02,371:INFO:Creating metrics dataframe
2024-08-28 11:22:02,381:INFO:Initializing Light Gradient Boosting Machine
2024-08-28 11:22:02,381:INFO:Total runtime is 0.28031246264775594 minutes
2024-08-28 11:22:02,383:INFO:SubProcess create_model() called ==================================
2024-08-28 11:22:02,383:INFO:Initializing create_model()
2024-08-28 11:22:02,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:22:02,383:INFO:Checking exceptions
2024-08-28 11:22:02,383:INFO:Importing libraries
2024-08-28 11:22:02,383:INFO:Copying training dataset
2024-08-28 11:22:02,391:INFO:Defining folds
2024-08-28 11:22:02,391:INFO:Declaring metric variables
2024-08-28 11:22:02,394:INFO:Importing untrained model
2024-08-28 11:22:02,397:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 11:22:02,403:INFO:Starting cross validation
2024-08-28 11:22:02,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:22:03,707:INFO:Calculating mean and std
2024-08-28 11:22:03,708:INFO:Creating metrics dataframe
2024-08-28 11:22:03,711:INFO:Uploading results into container
2024-08-28 11:22:03,711:INFO:Uploading model into container now
2024-08-28 11:22:03,712:INFO:_master_model_container: 18
2024-08-28 11:22:03,712:INFO:_display_container: 2
2024-08-28 11:22:03,712:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-08-28 11:22:03,713:INFO:create_model() successfully completed......................................
2024-08-28 11:22:03,880:INFO:SubProcess create_model() end ==================================
2024-08-28 11:22:03,880:INFO:Creating metrics dataframe
2024-08-28 11:22:03,889:INFO:Initializing Dummy Regressor
2024-08-28 11:22:03,889:INFO:Total runtime is 0.3054500857988993 minutes
2024-08-28 11:22:03,891:INFO:SubProcess create_model() called ==================================
2024-08-28 11:22:03,892:INFO:Initializing create_model()
2024-08-28 11:22:03,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D3ED6750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:22:03,892:INFO:Checking exceptions
2024-08-28 11:22:03,892:INFO:Importing libraries
2024-08-28 11:22:03,892:INFO:Copying training dataset
2024-08-28 11:22:03,899:INFO:Defining folds
2024-08-28 11:22:03,899:INFO:Declaring metric variables
2024-08-28 11:22:03,901:INFO:Importing untrained model
2024-08-28 11:22:03,904:INFO:Dummy Regressor Imported successfully
2024-08-28 11:22:03,909:INFO:Starting cross validation
2024-08-28 11:22:03,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:22:04,195:INFO:Calculating mean and std
2024-08-28 11:22:04,196:INFO:Creating metrics dataframe
2024-08-28 11:22:04,198:INFO:Uploading results into container
2024-08-28 11:22:04,198:INFO:Uploading model into container now
2024-08-28 11:22:04,199:INFO:_master_model_container: 19
2024-08-28 11:22:04,199:INFO:_display_container: 2
2024-08-28 11:22:04,199:INFO:DummyRegressor()
2024-08-28 11:22:04,199:INFO:create_model() successfully completed......................................
2024-08-28 11:22:04,337:INFO:SubProcess create_model() end ==================================
2024-08-28 11:22:04,337:INFO:Creating metrics dataframe
2024-08-28 11:22:04,353:INFO:Initializing create_model()
2024-08-28 11:22:04,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Ridge(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:22:04,353:INFO:Checking exceptions
2024-08-28 11:22:04,354:INFO:Importing libraries
2024-08-28 11:22:04,354:INFO:Copying training dataset
2024-08-28 11:22:04,362:INFO:Defining folds
2024-08-28 11:22:04,362:INFO:Declaring metric variables
2024-08-28 11:22:04,362:INFO:Importing untrained model
2024-08-28 11:22:04,362:INFO:Declaring custom model
2024-08-28 11:22:04,362:INFO:Ridge Regression Imported successfully
2024-08-28 11:22:04,364:INFO:Cross validation set to False
2024-08-28 11:22:04,364:INFO:Fitting Model
2024-08-28 11:22:04,433:INFO:Ridge(random_state=123)
2024-08-28 11:22:04,433:INFO:create_model() successfully completed......................................
2024-08-28 11:22:04,593:INFO:_master_model_container: 19
2024-08-28 11:22:04,593:INFO:_display_container: 2
2024-08-28 11:22:04,593:INFO:Ridge(random_state=123)
2024-08-28 11:22:04,594:INFO:compare_models() successfully completed......................................
2024-08-28 11:22:04,594:INFO:Initializing create_model()
2024-08-28 11:22:04,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Ridge(random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:22:04,594:INFO:Checking exceptions
2024-08-28 11:22:04,604:INFO:Importing libraries
2024-08-28 11:22:04,604:INFO:Copying training dataset
2024-08-28 11:22:04,613:INFO:Defining folds
2024-08-28 11:22:04,613:INFO:Declaring metric variables
2024-08-28 11:22:04,617:INFO:Importing untrained model
2024-08-28 11:22:04,617:INFO:Declaring custom model
2024-08-28 11:22:04,623:INFO:Ridge Regression Imported successfully
2024-08-28 11:22:04,631:INFO:Starting cross validation
2024-08-28 11:22:04,633:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:22:04,968:INFO:Calculating mean and std
2024-08-28 11:22:04,968:INFO:Creating metrics dataframe
2024-08-28 11:22:04,971:INFO:Finalizing model
2024-08-28 11:22:05,044:INFO:Uploading results into container
2024-08-28 11:22:05,045:INFO:Uploading model into container now
2024-08-28 11:22:05,052:INFO:_master_model_container: 20
2024-08-28 11:22:05,052:INFO:_display_container: 3
2024-08-28 11:22:05,052:INFO:Ridge(random_state=123)
2024-08-28 11:22:05,052:INFO:create_model() successfully completed......................................
2024-08-28 11:22:05,194:INFO:Initializing tune_model()
2024-08-28 11:22:05,194:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Ridge(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-28 11:22:05,194:INFO:Checking exceptions
2024-08-28 11:22:05,208:INFO:Copying training dataset
2024-08-28 11:22:05,215:INFO:Checking base model
2024-08-28 11:22:05,215:INFO:Base model : Ridge Regression
2024-08-28 11:22:05,219:INFO:Declaring metric variables
2024-08-28 11:22:05,221:INFO:Defining Hyperparameters
2024-08-28 11:22:05,362:INFO:Tuning with n_jobs=-1
2024-08-28 11:22:05,363:INFO:Initializing RandomizedSearchCV
2024-08-28 11:22:07,898:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 8.84}
2024-08-28 11:22:07,898:INFO:Hyperparameter search completed
2024-08-28 11:22:07,898:INFO:SubProcess create_model() called ==================================
2024-08-28 11:22:07,900:INFO:Initializing create_model()
2024-08-28 11:22:07,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Ridge(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D2330190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 8.84})
2024-08-28 11:22:07,900:INFO:Checking exceptions
2024-08-28 11:22:07,900:INFO:Importing libraries
2024-08-28 11:22:07,900:INFO:Copying training dataset
2024-08-28 11:22:07,908:INFO:Defining folds
2024-08-28 11:22:07,908:INFO:Declaring metric variables
2024-08-28 11:22:07,910:INFO:Importing untrained model
2024-08-28 11:22:07,910:INFO:Declaring custom model
2024-08-28 11:22:07,913:INFO:Ridge Regression Imported successfully
2024-08-28 11:22:07,918:INFO:Starting cross validation
2024-08-28 11:22:07,919:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:22:08,218:INFO:Calculating mean and std
2024-08-28 11:22:08,219:INFO:Creating metrics dataframe
2024-08-28 11:22:08,223:INFO:Finalizing model
2024-08-28 11:22:08,294:INFO:Uploading results into container
2024-08-28 11:22:08,294:INFO:Uploading model into container now
2024-08-28 11:22:08,295:INFO:_master_model_container: 21
2024-08-28 11:22:08,296:INFO:_display_container: 4
2024-08-28 11:22:08,296:INFO:Ridge(alpha=8.84, random_state=123)
2024-08-28 11:22:08,296:INFO:create_model() successfully completed......................................
2024-08-28 11:22:08,454:INFO:SubProcess create_model() end ==================================
2024-08-28 11:22:08,454:INFO:choose_better activated
2024-08-28 11:22:08,458:INFO:SubProcess create_model() called ==================================
2024-08-28 11:22:08,459:INFO:Initializing create_model()
2024-08-28 11:22:08,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Ridge(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:22:08,459:INFO:Checking exceptions
2024-08-28 11:22:08,460:INFO:Importing libraries
2024-08-28 11:22:08,460:INFO:Copying training dataset
2024-08-28 11:22:08,468:INFO:Defining folds
2024-08-28 11:22:08,468:INFO:Declaring metric variables
2024-08-28 11:22:08,469:INFO:Importing untrained model
2024-08-28 11:22:08,469:INFO:Declaring custom model
2024-08-28 11:22:08,469:INFO:Ridge Regression Imported successfully
2024-08-28 11:22:08,469:INFO:Starting cross validation
2024-08-28 11:22:08,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 11:22:08,780:INFO:Calculating mean and std
2024-08-28 11:22:08,780:INFO:Creating metrics dataframe
2024-08-28 11:22:08,782:INFO:Finalizing model
2024-08-28 11:22:08,848:INFO:Uploading results into container
2024-08-28 11:22:08,849:INFO:Uploading model into container now
2024-08-28 11:22:08,849:INFO:_master_model_container: 22
2024-08-28 11:22:08,849:INFO:_display_container: 5
2024-08-28 11:22:08,850:INFO:Ridge(random_state=123)
2024-08-28 11:22:08,850:INFO:create_model() successfully completed......................................
2024-08-28 11:22:08,988:INFO:SubProcess create_model() end ==================================
2024-08-28 11:22:08,989:INFO:Ridge(random_state=123) result for R2 is 0.129
2024-08-28 11:22:08,989:INFO:Ridge(alpha=8.84, random_state=123) result for R2 is 0.1302
2024-08-28 11:22:08,989:INFO:Ridge(alpha=8.84, random_state=123) is best model
2024-08-28 11:22:08,989:INFO:choose_better completed
2024-08-28 11:22:08,998:INFO:_master_model_container: 22
2024-08-28 11:22:08,998:INFO:_display_container: 4
2024-08-28 11:22:08,998:INFO:Ridge(alpha=8.84, random_state=123)
2024-08-28 11:22:08,998:INFO:tune_model() successfully completed......................................
2024-08-28 11:22:09,145:INFO:Initializing finalize_model()
2024-08-28 11:22:09,145:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Ridge(alpha=8.84, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-28 11:22:09,146:INFO:Finalizing Ridge(alpha=8.84, random_state=123)
2024-08-28 11:22:09,150:INFO:Initializing create_model()
2024-08-28 11:22:09,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Ridge(alpha=8.84, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 11:22:09,150:INFO:Checking exceptions
2024-08-28 11:22:09,151:INFO:Importing libraries
2024-08-28 11:22:09,152:INFO:Copying training dataset
2024-08-28 11:22:09,152:INFO:Defining folds
2024-08-28 11:22:09,152:INFO:Declaring metric variables
2024-08-28 11:22:09,152:INFO:Importing untrained model
2024-08-28 11:22:09,152:INFO:Declaring custom model
2024-08-28 11:22:09,152:INFO:Ridge Regression Imported successfully
2024-08-28 11:22:09,153:INFO:Cross validation set to False
2024-08-28 11:22:09,153:INFO:Fitting Model
2024-08-28 11:22:09,245:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['DOB'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['10percentage', '12graduation',
                                             '12percentage', 'CollegeTier',
                                             'collegeGPA', 'CollegeCityTier',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerPr...
                                    transformer=OneHotEncoder(cols=['Degree'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['10board', '12board',
                                             'Specialization', 'CollegeState'],
                                    transformer=TargetEncoder(cols=['10board',
                                                                    '12board',
                                                                    'Specialization',
                                                                    'CollegeState'],
                                                              handle_missing='return_nan'))),
                ('actual_estimator', Ridge(alpha=8.84, random_state=123))])
2024-08-28 11:22:09,245:INFO:create_model() successfully completed......................................
2024-08-28 11:22:09,380:INFO:_master_model_container: 22
2024-08-28 11:22:09,380:INFO:_display_container: 4
2024-08-28 11:22:09,396:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['DOB'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['10percentage', '12graduation',
                                             '12percentage', 'CollegeTier',
                                             'collegeGPA', 'CollegeCityTier',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerPr...
                                    transformer=OneHotEncoder(cols=['Degree'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['10board', '12board',
                                             'Specialization', 'CollegeState'],
                                    transformer=TargetEncoder(cols=['10board',
                                                                    '12board',
                                                                    'Specialization',
                                                                    'CollegeState'],
                                                              handle_missing='return_nan'))),
                ('actual_estimator', Ridge(alpha=8.84, random_state=123))])
2024-08-28 11:22:09,397:INFO:finalize_model() successfully completed......................................
2024-08-28 11:22:09,546:INFO:Initializing predict_model()
2024-08-28 11:22:09,546:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D21E9950>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['DOB'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['10percentage', '12graduation',
                                             '12percentage', 'CollegeTier',
                                             'collegeGPA', 'CollegeCityTier',
                                             'GraduationYear', 'English',
                                             'Logical', 'Quant', 'Domain',
                                             'ComputerPr...
                                    transformer=OneHotEncoder(cols=['Degree'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['10board', '12board',
                                             'Specialization', 'CollegeState'],
                                    transformer=TargetEncoder(cols=['10board',
                                                                    '12board',
                                                                    'Specialization',
                                                                    'CollegeState'],
                                                              handle_missing='return_nan'))),
                ('actual_estimator', Ridge(alpha=8.84, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000155D0259620>)
2024-08-28 11:22:09,547:INFO:Checking exceptions
2024-08-28 11:22:09,547:INFO:Preloading libraries
2024-08-28 11:22:09,548:INFO:Set up data.
2024-08-28 11:22:09,553:INFO:Set up index.
2024-08-28 14:52:02,708:INFO:PyCaret RegressionExperiment
2024-08-28 14:52:02,708:INFO:Logging name: reg-default-name
2024-08-28 14:52:02,708:INFO:ML Usecase: MLUsecase.REGRESSION
2024-08-28 14:52:02,708:INFO:version 3.3.2
2024-08-28 14:52:02,708:INFO:Initializing setup()
2024-08-28 14:52:02,708:INFO:self.USI: 2e7d
2024-08-28 14:52:02,708:INFO:self._variable_keys: {'data', 'html_param', 'pipeline', '_ml_usecase', 'y', 'X_test', 'exp_name_log', 'gpu_param', 'X_train', 'transform_target_param', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'fold_generator', 'seed', 'USI', 'memory', 'fold_groups_param', 'idx', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'y_train', 'target_param'}
2024-08-28 14:52:02,708:INFO:Checking environment
2024-08-28 14:52:02,708:INFO:python_version: 3.11.9
2024-08-28 14:52:02,708:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 14:52:02,708:INFO:machine: AMD64
2024-08-28 14:52:02,708:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 14:52:02,714:INFO:Memory: svmem(total=16867028992, available=5046181888, percent=70.1, used=11820847104, free=5046181888)
2024-08-28 14:52:02,714:INFO:Physical Core: 6
2024-08-28 14:52:02,714:INFO:Logical Core: 12
2024-08-28 14:52:02,714:INFO:Checking libraries
2024-08-28 14:52:02,714:INFO:System:
2024-08-28 14:52:02,714:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 14:52:02,714:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 14:52:02,714:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 14:52:02,714:INFO:PyCaret required dependencies:
2024-08-28 14:52:02,714:INFO:                 pip: 23.2.1
2024-08-28 14:52:02,714:INFO:          setuptools: 67.8.0
2024-08-28 14:52:02,714:INFO:             pycaret: 3.3.2
2024-08-28 14:52:02,714:INFO:             IPython: 8.14.0
2024-08-28 14:52:02,716:INFO:          ipywidgets: 8.1.5
2024-08-28 14:52:02,716:INFO:                tqdm: 4.66.5
2024-08-28 14:52:02,716:INFO:               numpy: 1.24.3
2024-08-28 14:52:02,716:INFO:              pandas: 2.0.3
2024-08-28 14:52:02,716:INFO:              jinja2: 3.1.4
2024-08-28 14:52:02,716:INFO:               scipy: 1.10.1
2024-08-28 14:52:02,716:INFO:              joblib: 1.2.0
2024-08-28 14:52:02,716:INFO:             sklearn: 1.4.2
2024-08-28 14:52:02,716:INFO:                pyod: 2.0.1
2024-08-28 14:52:02,716:INFO:            imblearn: 0.12.3
2024-08-28 14:52:02,716:INFO:   category_encoders: 2.6.3
2024-08-28 14:52:02,716:INFO:            lightgbm: 4.5.0
2024-08-28 14:52:02,716:INFO:               numba: 0.60.0
2024-08-28 14:52:02,716:INFO:            requests: 2.32.3
2024-08-28 14:52:02,716:INFO:          matplotlib: 3.7.1
2024-08-28 14:52:02,716:INFO:          scikitplot: 0.3.7
2024-08-28 14:52:02,716:INFO:         yellowbrick: 1.5
2024-08-28 14:52:02,716:INFO:              plotly: 5.16.1
2024-08-28 14:52:02,716:INFO:    plotly-resampler: Not installed
2024-08-28 14:52:02,716:INFO:             kaleido: 0.2.1
2024-08-28 14:52:02,716:INFO:           schemdraw: 0.15
2024-08-28 14:52:02,716:INFO:         statsmodels: 0.14.2
2024-08-28 14:52:02,716:INFO:              sktime: 0.26.0
2024-08-28 14:52:02,717:INFO:               tbats: 1.1.3
2024-08-28 14:52:02,717:INFO:            pmdarima: 2.0.4
2024-08-28 14:52:02,717:INFO:              psutil: 5.9.0
2024-08-28 14:52:02,717:INFO:          markupsafe: 2.1.3
2024-08-28 14:52:02,717:INFO:             pickle5: Not installed
2024-08-28 14:52:02,717:INFO:         cloudpickle: 3.0.0
2024-08-28 14:52:02,717:INFO:         deprecation: 2.1.0
2024-08-28 14:52:02,717:INFO:              xxhash: 3.5.0
2024-08-28 14:52:02,717:INFO:           wurlitzer: Not installed
2024-08-28 14:52:02,717:INFO:PyCaret optional dependencies:
2024-08-28 14:52:02,717:INFO:                shap: Not installed
2024-08-28 14:52:02,717:INFO:           interpret: Not installed
2024-08-28 14:52:02,717:INFO:                umap: Not installed
2024-08-28 14:52:02,717:INFO:     ydata_profiling: Not installed
2024-08-28 14:52:02,717:INFO:  explainerdashboard: Not installed
2024-08-28 14:52:02,717:INFO:             autoviz: Not installed
2024-08-28 14:52:02,717:INFO:           fairlearn: Not installed
2024-08-28 14:52:02,717:INFO:          deepchecks: Not installed
2024-08-28 14:52:02,717:INFO:             xgboost: 2.0.2
2024-08-28 14:52:02,717:INFO:            catboost: Not installed
2024-08-28 14:52:02,717:INFO:              kmodes: Not installed
2024-08-28 14:52:02,717:INFO:             mlxtend: Not installed
2024-08-28 14:52:02,717:INFO:       statsforecast: Not installed
2024-08-28 14:52:02,718:INFO:        tune_sklearn: Not installed
2024-08-28 14:52:02,718:INFO:                 ray: Not installed
2024-08-28 14:52:02,718:INFO:            hyperopt: Not installed
2024-08-28 14:52:02,718:INFO:              optuna: Not installed
2024-08-28 14:52:02,718:INFO:               skopt: Not installed
2024-08-28 14:52:02,718:INFO:              mlflow: Not installed
2024-08-28 14:52:02,718:INFO:              gradio: 4.41.0
2024-08-28 14:52:02,718:INFO:             fastapi: 0.112.1
2024-08-28 14:52:02,718:INFO:             uvicorn: 0.30.6
2024-08-28 14:52:02,718:INFO:              m2cgen: Not installed
2024-08-28 14:52:02,718:INFO:           evidently: Not installed
2024-08-28 14:52:02,718:INFO:               fugue: Not installed
2024-08-28 14:52:02,718:INFO:           streamlit: Not installed
2024-08-28 14:52:02,718:INFO:             prophet: Not installed
2024-08-28 14:52:02,718:INFO:None
2024-08-28 14:52:02,719:INFO:Set up data.
2024-08-28 14:52:02,732:INFO:Set up folding strategy.
2024-08-28 14:52:02,733:INFO:Set up train/test split.
2024-08-28 14:52:02,745:INFO:Set up index.
2024-08-28 14:52:02,745:INFO:Assigning column types.
2024-08-28 14:52:02,750:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-28 14:52:02,750:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,755:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,759:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,840:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,842:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:02,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:02,845:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,848:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,896:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,931:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,931:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:02,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:02,933:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-08-28 14:52:02,937:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,941:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 14:52:02,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,021:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,027:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,030:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,076:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,112:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,114:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-08-28 14:52:03,121:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,165:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,199:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,199:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,208:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,255:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,290:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,291:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-08-28 14:52:03,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,377:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,467:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,469:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-28 14:52:03,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,558:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,611:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-08-28 14:52:03,647:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,649:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-08-28 14:52:03,738:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,829:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:03,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:03,833:INFO:Preparing preprocessing pipeline...
2024-08-28 14:52:03,833:INFO:Set up simple imputation.
2024-08-28 14:52:03,836:INFO:Set up encoding of ordinal features.
2024-08-28 14:52:03,837:INFO:Set up encoding of categorical features.
2024-08-28 14:52:03,925:INFO:Finished creating preprocessing pipeline.
2024-08-28 14:52:03,947:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'RestingBP', 'Cholesterol',
                                             'FastingBS', 'MaxHR', 'Oldpeak'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Sex', 'ChestPainType',
                                             'RestingECG', 'ExerciseAngina',
                                             'ST_Slope'],
                                    transfor...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64},
                                                                        {'col': 'ExerciseAngina',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': N      0
Y      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['ChestPainType', 'RestingECG',
                                             'ST_Slope'],
                                    transformer=OneHotEncoder(cols=['ChestPainType',
                                                                    'RestingECG',
                                                                    'ST_Slope'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-08-28 14:52:03,948:INFO:Creating final display dataframe.
2024-08-28 14:52:04,138:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      HeartDisease
2                   Target type        Regression
3           Original data shape         (918, 12)
4        Transformed data shape         (918, 19)
5   Transformed train set shape         (642, 19)
6    Transformed test set shape         (276, 19)
7              Numeric features                 6
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              2e7d
2024-08-28 14:52:04,237:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:04,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:04,329:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:04,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:04,331:INFO:setup() successfully completed in 1.63s...............
2024-08-28 14:52:04,331:INFO:Initializing compare_models()
2024-08-28 14:52:04,331:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2024-08-28 14:52:04,331:INFO:Checking exceptions
2024-08-28 14:52:04,334:INFO:Preparing display monitor
2024-08-28 14:52:04,351:INFO:Initializing Linear Regression
2024-08-28 14:52:04,351:INFO:Total runtime is 0.0 minutes
2024-08-28 14:52:04,354:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:04,355:INFO:Initializing create_model()
2024-08-28 14:52:04,355:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:04,355:INFO:Checking exceptions
2024-08-28 14:52:04,355:INFO:Importing libraries
2024-08-28 14:52:04,355:INFO:Copying training dataset
2024-08-28 14:52:04,359:INFO:Defining folds
2024-08-28 14:52:04,359:INFO:Declaring metric variables
2024-08-28 14:52:04,362:INFO:Importing untrained model
2024-08-28 14:52:04,364:INFO:Linear Regression Imported successfully
2024-08-28 14:52:04,370:INFO:Starting cross validation
2024-08-28 14:52:04,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:10,343:INFO:Calculating mean and std
2024-08-28 14:52:10,346:INFO:Creating metrics dataframe
2024-08-28 14:52:10,350:INFO:Uploading results into container
2024-08-28 14:52:10,351:INFO:Uploading model into container now
2024-08-28 14:52:10,352:INFO:_master_model_container: 1
2024-08-28 14:52:10,353:INFO:_display_container: 2
2024-08-28 14:52:10,353:INFO:LinearRegression(n_jobs=-1)
2024-08-28 14:52:10,353:INFO:create_model() successfully completed......................................
2024-08-28 14:52:10,888:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:10,888:INFO:Creating metrics dataframe
2024-08-28 14:52:10,894:INFO:Initializing Lasso Regression
2024-08-28 14:52:10,894:INFO:Total runtime is 0.10904229879379272 minutes
2024-08-28 14:52:10,897:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:10,897:INFO:Initializing create_model()
2024-08-28 14:52:10,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:10,897:INFO:Checking exceptions
2024-08-28 14:52:10,897:INFO:Importing libraries
2024-08-28 14:52:10,897:INFO:Copying training dataset
2024-08-28 14:52:10,901:INFO:Defining folds
2024-08-28 14:52:10,901:INFO:Declaring metric variables
2024-08-28 14:52:10,904:INFO:Importing untrained model
2024-08-28 14:52:10,907:INFO:Lasso Regression Imported successfully
2024-08-28 14:52:10,912:INFO:Starting cross validation
2024-08-28 14:52:10,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:12,981:INFO:Calculating mean and std
2024-08-28 14:52:12,982:INFO:Creating metrics dataframe
2024-08-28 14:52:12,983:INFO:Uploading results into container
2024-08-28 14:52:12,983:INFO:Uploading model into container now
2024-08-28 14:52:12,985:INFO:_master_model_container: 2
2024-08-28 14:52:12,985:INFO:_display_container: 2
2024-08-28 14:52:12,985:INFO:Lasso(random_state=123)
2024-08-28 14:52:12,985:INFO:create_model() successfully completed......................................
2024-08-28 14:52:13,169:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:13,169:INFO:Creating metrics dataframe
2024-08-28 14:52:13,175:INFO:Initializing Ridge Regression
2024-08-28 14:52:13,175:INFO:Total runtime is 0.1470637798309326 minutes
2024-08-28 14:52:13,177:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:13,177:INFO:Initializing create_model()
2024-08-28 14:52:13,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:13,177:INFO:Checking exceptions
2024-08-28 14:52:13,177:INFO:Importing libraries
2024-08-28 14:52:13,177:INFO:Copying training dataset
2024-08-28 14:52:13,181:INFO:Defining folds
2024-08-28 14:52:13,181:INFO:Declaring metric variables
2024-08-28 14:52:13,184:INFO:Importing untrained model
2024-08-28 14:52:13,187:INFO:Ridge Regression Imported successfully
2024-08-28 14:52:13,192:INFO:Starting cross validation
2024-08-28 14:52:13,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:13,401:INFO:Calculating mean and std
2024-08-28 14:52:13,402:INFO:Creating metrics dataframe
2024-08-28 14:52:13,405:INFO:Uploading results into container
2024-08-28 14:52:13,406:INFO:Uploading model into container now
2024-08-28 14:52:13,406:INFO:_master_model_container: 3
2024-08-28 14:52:13,406:INFO:_display_container: 2
2024-08-28 14:52:13,406:INFO:Ridge(random_state=123)
2024-08-28 14:52:13,406:INFO:create_model() successfully completed......................................
2024-08-28 14:52:13,590:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:13,590:INFO:Creating metrics dataframe
2024-08-28 14:52:13,597:INFO:Initializing Elastic Net
2024-08-28 14:52:13,597:INFO:Total runtime is 0.15409313042958575 minutes
2024-08-28 14:52:13,600:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:13,601:INFO:Initializing create_model()
2024-08-28 14:52:13,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:13,601:INFO:Checking exceptions
2024-08-28 14:52:13,601:INFO:Importing libraries
2024-08-28 14:52:13,601:INFO:Copying training dataset
2024-08-28 14:52:13,604:INFO:Defining folds
2024-08-28 14:52:13,605:INFO:Declaring metric variables
2024-08-28 14:52:13,608:INFO:Importing untrained model
2024-08-28 14:52:13,611:INFO:Elastic Net Imported successfully
2024-08-28 14:52:13,617:INFO:Starting cross validation
2024-08-28 14:52:13,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:13,809:INFO:Calculating mean and std
2024-08-28 14:52:13,810:INFO:Creating metrics dataframe
2024-08-28 14:52:13,811:INFO:Uploading results into container
2024-08-28 14:52:13,813:INFO:Uploading model into container now
2024-08-28 14:52:13,813:INFO:_master_model_container: 4
2024-08-28 14:52:13,813:INFO:_display_container: 2
2024-08-28 14:52:13,813:INFO:ElasticNet(random_state=123)
2024-08-28 14:52:13,813:INFO:create_model() successfully completed......................................
2024-08-28 14:52:14,001:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:14,001:INFO:Creating metrics dataframe
2024-08-28 14:52:14,009:INFO:Initializing Least Angle Regression
2024-08-28 14:52:14,009:INFO:Total runtime is 0.1609687805175781 minutes
2024-08-28 14:52:14,013:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:14,013:INFO:Initializing create_model()
2024-08-28 14:52:14,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:14,014:INFO:Checking exceptions
2024-08-28 14:52:14,014:INFO:Importing libraries
2024-08-28 14:52:14,014:INFO:Copying training dataset
2024-08-28 14:52:14,018:INFO:Defining folds
2024-08-28 14:52:14,018:INFO:Declaring metric variables
2024-08-28 14:52:14,021:INFO:Importing untrained model
2024-08-28 14:52:14,023:INFO:Least Angle Regression Imported successfully
2024-08-28 14:52:14,028:INFO:Starting cross validation
2024-08-28 14:52:14,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:14,231:INFO:Calculating mean and std
2024-08-28 14:52:14,232:INFO:Creating metrics dataframe
2024-08-28 14:52:14,234:INFO:Uploading results into container
2024-08-28 14:52:14,234:INFO:Uploading model into container now
2024-08-28 14:52:14,235:INFO:_master_model_container: 5
2024-08-28 14:52:14,235:INFO:_display_container: 2
2024-08-28 14:52:14,235:INFO:Lars(random_state=123)
2024-08-28 14:52:14,235:INFO:create_model() successfully completed......................................
2024-08-28 14:52:14,427:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:14,427:INFO:Creating metrics dataframe
2024-08-28 14:52:14,434:INFO:Initializing Lasso Least Angle Regression
2024-08-28 14:52:14,434:INFO:Total runtime is 0.16804847717285154 minutes
2024-08-28 14:52:14,436:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:14,437:INFO:Initializing create_model()
2024-08-28 14:52:14,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:14,437:INFO:Checking exceptions
2024-08-28 14:52:14,437:INFO:Importing libraries
2024-08-28 14:52:14,437:INFO:Copying training dataset
2024-08-28 14:52:14,441:INFO:Defining folds
2024-08-28 14:52:14,441:INFO:Declaring metric variables
2024-08-28 14:52:14,444:INFO:Importing untrained model
2024-08-28 14:52:14,448:INFO:Lasso Least Angle Regression Imported successfully
2024-08-28 14:52:14,452:INFO:Starting cross validation
2024-08-28 14:52:14,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:14,656:INFO:Calculating mean and std
2024-08-28 14:52:14,657:INFO:Creating metrics dataframe
2024-08-28 14:52:14,658:INFO:Uploading results into container
2024-08-28 14:52:14,659:INFO:Uploading model into container now
2024-08-28 14:52:14,659:INFO:_master_model_container: 6
2024-08-28 14:52:14,659:INFO:_display_container: 2
2024-08-28 14:52:14,659:INFO:LassoLars(random_state=123)
2024-08-28 14:52:14,659:INFO:create_model() successfully completed......................................
2024-08-28 14:52:14,850:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:14,850:INFO:Creating metrics dataframe
2024-08-28 14:52:14,857:INFO:Initializing Orthogonal Matching Pursuit
2024-08-28 14:52:14,857:INFO:Total runtime is 0.1751071453094482 minutes
2024-08-28 14:52:14,859:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:14,859:INFO:Initializing create_model()
2024-08-28 14:52:14,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:14,859:INFO:Checking exceptions
2024-08-28 14:52:14,859:INFO:Importing libraries
2024-08-28 14:52:14,860:INFO:Copying training dataset
2024-08-28 14:52:14,864:INFO:Defining folds
2024-08-28 14:52:14,864:INFO:Declaring metric variables
2024-08-28 14:52:14,869:INFO:Importing untrained model
2024-08-28 14:52:14,876:INFO:Orthogonal Matching Pursuit Imported successfully
2024-08-28 14:52:14,886:INFO:Starting cross validation
2024-08-28 14:52:14,889:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:15,153:INFO:Calculating mean and std
2024-08-28 14:52:15,154:INFO:Creating metrics dataframe
2024-08-28 14:52:15,157:INFO:Uploading results into container
2024-08-28 14:52:15,157:INFO:Uploading model into container now
2024-08-28 14:52:15,158:INFO:_master_model_container: 7
2024-08-28 14:52:15,158:INFO:_display_container: 2
2024-08-28 14:52:15,158:INFO:OrthogonalMatchingPursuit()
2024-08-28 14:52:15,158:INFO:create_model() successfully completed......................................
2024-08-28 14:52:15,351:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:15,352:INFO:Creating metrics dataframe
2024-08-28 14:52:15,358:INFO:Initializing Bayesian Ridge
2024-08-28 14:52:15,359:INFO:Total runtime is 0.18346863190333046 minutes
2024-08-28 14:52:15,361:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:15,362:INFO:Initializing create_model()
2024-08-28 14:52:15,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:15,362:INFO:Checking exceptions
2024-08-28 14:52:15,362:INFO:Importing libraries
2024-08-28 14:52:15,362:INFO:Copying training dataset
2024-08-28 14:52:15,366:INFO:Defining folds
2024-08-28 14:52:15,366:INFO:Declaring metric variables
2024-08-28 14:52:15,368:INFO:Importing untrained model
2024-08-28 14:52:15,372:INFO:Bayesian Ridge Imported successfully
2024-08-28 14:52:15,377:INFO:Starting cross validation
2024-08-28 14:52:15,379:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:15,573:INFO:Calculating mean and std
2024-08-28 14:52:15,574:INFO:Creating metrics dataframe
2024-08-28 14:52:15,575:INFO:Uploading results into container
2024-08-28 14:52:15,575:INFO:Uploading model into container now
2024-08-28 14:52:15,576:INFO:_master_model_container: 8
2024-08-28 14:52:15,576:INFO:_display_container: 2
2024-08-28 14:52:15,576:INFO:BayesianRidge()
2024-08-28 14:52:15,576:INFO:create_model() successfully completed......................................
2024-08-28 14:52:15,751:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:15,751:INFO:Creating metrics dataframe
2024-08-28 14:52:15,759:INFO:Initializing Passive Aggressive Regressor
2024-08-28 14:52:15,759:INFO:Total runtime is 0.19012534221013386 minutes
2024-08-28 14:52:15,761:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:15,762:INFO:Initializing create_model()
2024-08-28 14:52:15,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:15,762:INFO:Checking exceptions
2024-08-28 14:52:15,762:INFO:Importing libraries
2024-08-28 14:52:15,762:INFO:Copying training dataset
2024-08-28 14:52:15,765:INFO:Defining folds
2024-08-28 14:52:15,765:INFO:Declaring metric variables
2024-08-28 14:52:15,768:INFO:Importing untrained model
2024-08-28 14:52:15,771:INFO:Passive Aggressive Regressor Imported successfully
2024-08-28 14:52:15,776:INFO:Starting cross validation
2024-08-28 14:52:15,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:15,970:INFO:Calculating mean and std
2024-08-28 14:52:15,971:INFO:Creating metrics dataframe
2024-08-28 14:52:15,972:INFO:Uploading results into container
2024-08-28 14:52:15,972:INFO:Uploading model into container now
2024-08-28 14:52:15,972:INFO:_master_model_container: 9
2024-08-28 14:52:15,972:INFO:_display_container: 2
2024-08-28 14:52:15,974:INFO:PassiveAggressiveRegressor(random_state=123)
2024-08-28 14:52:15,974:INFO:create_model() successfully completed......................................
2024-08-28 14:52:16,165:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:16,165:INFO:Creating metrics dataframe
2024-08-28 14:52:16,172:INFO:Initializing Huber Regressor
2024-08-28 14:52:16,172:INFO:Total runtime is 0.19702263673146564 minutes
2024-08-28 14:52:16,175:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:16,175:INFO:Initializing create_model()
2024-08-28 14:52:16,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:16,175:INFO:Checking exceptions
2024-08-28 14:52:16,175:INFO:Importing libraries
2024-08-28 14:52:16,176:INFO:Copying training dataset
2024-08-28 14:52:16,179:INFO:Defining folds
2024-08-28 14:52:16,179:INFO:Declaring metric variables
2024-08-28 14:52:16,182:INFO:Importing untrained model
2024-08-28 14:52:16,184:INFO:Huber Regressor Imported successfully
2024-08-28 14:52:16,189:INFO:Starting cross validation
2024-08-28 14:52:16,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:16,332:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,335:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,350:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,352:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,363:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,367:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,377:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,393:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,400:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,413:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-08-28 14:52:16,441:INFO:Calculating mean and std
2024-08-28 14:52:16,442:INFO:Creating metrics dataframe
2024-08-28 14:52:16,443:INFO:Uploading results into container
2024-08-28 14:52:16,444:INFO:Uploading model into container now
2024-08-28 14:52:16,444:INFO:_master_model_container: 10
2024-08-28 14:52:16,445:INFO:_display_container: 2
2024-08-28 14:52:16,445:INFO:HuberRegressor()
2024-08-28 14:52:16,445:INFO:create_model() successfully completed......................................
2024-08-28 14:52:16,629:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:16,629:INFO:Creating metrics dataframe
2024-08-28 14:52:16,638:INFO:Initializing K Neighbors Regressor
2024-08-28 14:52:16,638:INFO:Total runtime is 0.2047746737798055 minutes
2024-08-28 14:52:16,641:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:16,641:INFO:Initializing create_model()
2024-08-28 14:52:16,642:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:16,642:INFO:Checking exceptions
2024-08-28 14:52:16,642:INFO:Importing libraries
2024-08-28 14:52:16,642:INFO:Copying training dataset
2024-08-28 14:52:16,645:INFO:Defining folds
2024-08-28 14:52:16,645:INFO:Declaring metric variables
2024-08-28 14:52:16,648:INFO:Importing untrained model
2024-08-28 14:52:16,651:INFO:K Neighbors Regressor Imported successfully
2024-08-28 14:52:16,656:INFO:Starting cross validation
2024-08-28 14:52:16,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:17,001:INFO:Calculating mean and std
2024-08-28 14:52:17,002:INFO:Creating metrics dataframe
2024-08-28 14:52:17,003:INFO:Uploading results into container
2024-08-28 14:52:17,004:INFO:Uploading model into container now
2024-08-28 14:52:17,004:INFO:_master_model_container: 11
2024-08-28 14:52:17,004:INFO:_display_container: 2
2024-08-28 14:52:17,004:INFO:KNeighborsRegressor(n_jobs=-1)
2024-08-28 14:52:17,005:INFO:create_model() successfully completed......................................
2024-08-28 14:52:17,185:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:17,185:INFO:Creating metrics dataframe
2024-08-28 14:52:17,191:INFO:Initializing Decision Tree Regressor
2024-08-28 14:52:17,192:INFO:Total runtime is 0.21400569279988604 minutes
2024-08-28 14:52:17,194:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:17,195:INFO:Initializing create_model()
2024-08-28 14:52:17,195:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:17,195:INFO:Checking exceptions
2024-08-28 14:52:17,195:INFO:Importing libraries
2024-08-28 14:52:17,195:INFO:Copying training dataset
2024-08-28 14:52:17,199:INFO:Defining folds
2024-08-28 14:52:17,199:INFO:Declaring metric variables
2024-08-28 14:52:17,204:INFO:Importing untrained model
2024-08-28 14:52:17,210:INFO:Decision Tree Regressor Imported successfully
2024-08-28 14:52:17,218:INFO:Starting cross validation
2024-08-28 14:52:17,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:17,511:INFO:Calculating mean and std
2024-08-28 14:52:17,511:INFO:Creating metrics dataframe
2024-08-28 14:52:17,513:INFO:Uploading results into container
2024-08-28 14:52:17,513:INFO:Uploading model into container now
2024-08-28 14:52:17,514:INFO:_master_model_container: 12
2024-08-28 14:52:17,514:INFO:_display_container: 2
2024-08-28 14:52:17,514:INFO:DecisionTreeRegressor(random_state=123)
2024-08-28 14:52:17,514:INFO:create_model() successfully completed......................................
2024-08-28 14:52:17,700:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:17,700:INFO:Creating metrics dataframe
2024-08-28 14:52:17,707:INFO:Initializing Random Forest Regressor
2024-08-28 14:52:17,708:INFO:Total runtime is 0.2226191163063049 minutes
2024-08-28 14:52:17,710:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:17,710:INFO:Initializing create_model()
2024-08-28 14:52:17,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:17,710:INFO:Checking exceptions
2024-08-28 14:52:17,710:INFO:Importing libraries
2024-08-28 14:52:17,710:INFO:Copying training dataset
2024-08-28 14:52:17,714:INFO:Defining folds
2024-08-28 14:52:17,715:INFO:Declaring metric variables
2024-08-28 14:52:17,718:INFO:Importing untrained model
2024-08-28 14:52:17,720:INFO:Random Forest Regressor Imported successfully
2024-08-28 14:52:17,726:INFO:Starting cross validation
2024-08-28 14:52:17,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:18,406:INFO:Calculating mean and std
2024-08-28 14:52:18,407:INFO:Creating metrics dataframe
2024-08-28 14:52:18,409:INFO:Uploading results into container
2024-08-28 14:52:18,410:INFO:Uploading model into container now
2024-08-28 14:52:18,410:INFO:_master_model_container: 13
2024-08-28 14:52:18,410:INFO:_display_container: 2
2024-08-28 14:52:18,410:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-08-28 14:52:18,410:INFO:create_model() successfully completed......................................
2024-08-28 14:52:18,590:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:18,590:INFO:Creating metrics dataframe
2024-08-28 14:52:18,598:INFO:Initializing Extra Trees Regressor
2024-08-28 14:52:18,598:INFO:Total runtime is 0.23745443820953366 minutes
2024-08-28 14:52:18,601:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:18,601:INFO:Initializing create_model()
2024-08-28 14:52:18,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:18,601:INFO:Checking exceptions
2024-08-28 14:52:18,601:INFO:Importing libraries
2024-08-28 14:52:18,601:INFO:Copying training dataset
2024-08-28 14:52:18,606:INFO:Defining folds
2024-08-28 14:52:18,606:INFO:Declaring metric variables
2024-08-28 14:52:18,609:INFO:Importing untrained model
2024-08-28 14:52:18,612:INFO:Extra Trees Regressor Imported successfully
2024-08-28 14:52:18,617:INFO:Starting cross validation
2024-08-28 14:52:18,618:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:19,061:INFO:Calculating mean and std
2024-08-28 14:52:19,062:INFO:Creating metrics dataframe
2024-08-28 14:52:19,064:INFO:Uploading results into container
2024-08-28 14:52:19,064:INFO:Uploading model into container now
2024-08-28 14:52:19,064:INFO:_master_model_container: 14
2024-08-28 14:52:19,064:INFO:_display_container: 2
2024-08-28 14:52:19,064:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-08-28 14:52:19,064:INFO:create_model() successfully completed......................................
2024-08-28 14:52:19,239:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:19,240:INFO:Creating metrics dataframe
2024-08-28 14:52:19,248:INFO:Initializing AdaBoost Regressor
2024-08-28 14:52:19,248:INFO:Total runtime is 0.2482893625895182 minutes
2024-08-28 14:52:19,250:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:19,250:INFO:Initializing create_model()
2024-08-28 14:52:19,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:19,251:INFO:Checking exceptions
2024-08-28 14:52:19,251:INFO:Importing libraries
2024-08-28 14:52:19,251:INFO:Copying training dataset
2024-08-28 14:52:19,255:INFO:Defining folds
2024-08-28 14:52:19,255:INFO:Declaring metric variables
2024-08-28 14:52:19,257:INFO:Importing untrained model
2024-08-28 14:52:19,261:INFO:AdaBoost Regressor Imported successfully
2024-08-28 14:52:19,266:INFO:Starting cross validation
2024-08-28 14:52:19,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:19,546:INFO:Calculating mean and std
2024-08-28 14:52:19,547:INFO:Creating metrics dataframe
2024-08-28 14:52:19,549:INFO:Uploading results into container
2024-08-28 14:52:19,549:INFO:Uploading model into container now
2024-08-28 14:52:19,549:INFO:_master_model_container: 15
2024-08-28 14:52:19,550:INFO:_display_container: 2
2024-08-28 14:52:19,550:INFO:AdaBoostRegressor(random_state=123)
2024-08-28 14:52:19,550:INFO:create_model() successfully completed......................................
2024-08-28 14:52:19,738:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:19,739:INFO:Creating metrics dataframe
2024-08-28 14:52:19,748:INFO:Initializing Gradient Boosting Regressor
2024-08-28 14:52:19,748:INFO:Total runtime is 0.2566142439842224 minutes
2024-08-28 14:52:19,752:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:19,752:INFO:Initializing create_model()
2024-08-28 14:52:19,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:19,752:INFO:Checking exceptions
2024-08-28 14:52:19,752:INFO:Importing libraries
2024-08-28 14:52:19,752:INFO:Copying training dataset
2024-08-28 14:52:19,756:INFO:Defining folds
2024-08-28 14:52:19,756:INFO:Declaring metric variables
2024-08-28 14:52:19,759:INFO:Importing untrained model
2024-08-28 14:52:19,762:INFO:Gradient Boosting Regressor Imported successfully
2024-08-28 14:52:19,767:INFO:Starting cross validation
2024-08-28 14:52:19,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:20,137:INFO:Calculating mean and std
2024-08-28 14:52:20,138:INFO:Creating metrics dataframe
2024-08-28 14:52:20,139:INFO:Uploading results into container
2024-08-28 14:52:20,140:INFO:Uploading model into container now
2024-08-28 14:52:20,140:INFO:_master_model_container: 16
2024-08-28 14:52:20,140:INFO:_display_container: 2
2024-08-28 14:52:20,140:INFO:GradientBoostingRegressor(random_state=123)
2024-08-28 14:52:20,140:INFO:create_model() successfully completed......................................
2024-08-28 14:52:20,328:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:20,329:INFO:Creating metrics dataframe
2024-08-28 14:52:20,338:INFO:Initializing Extreme Gradient Boosting
2024-08-28 14:52:20,338:INFO:Total runtime is 0.26645497481028235 minutes
2024-08-28 14:52:20,340:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:20,341:INFO:Initializing create_model()
2024-08-28 14:52:20,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000155D3DBB490>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D4A70750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:20,341:INFO:Checking exceptions
2024-08-28 14:52:20,341:INFO:Importing libraries
2024-08-28 14:52:20,341:INFO:Copying training dataset
2024-08-28 14:52:20,345:INFO:Defining folds
2024-08-28 14:52:20,345:INFO:Declaring metric variables
2024-08-28 14:52:20,348:INFO:Importing untrained model
2024-08-28 14:52:20,351:INFO:Extreme Gradient Boosting Imported successfully
2024-08-28 14:52:20,356:INFO:Starting cross validation
2024-08-28 14:52:20,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:32,863:INFO:PyCaret ClassificationExperiment
2024-08-28 14:52:32,863:INFO:Logging name: clf-default-name
2024-08-28 14:52:32,863:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-08-28 14:52:32,863:INFO:version 3.3.2
2024-08-28 14:52:32,863:INFO:Initializing setup()
2024-08-28 14:52:32,863:INFO:self.USI: ec8d
2024-08-28 14:52:32,863:INFO:self._variable_keys: {'data', 'html_param', 'pipeline', '_ml_usecase', 'y', 'X_test', 'exp_name_log', 'gpu_param', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'y_test', '_available_plots', 'fix_imbalance', 'fold_generator', 'seed', 'USI', 'memory', 'fold_groups_param', 'idx', 'X', 'exp_id', 'n_jobs_param', 'fold_shuffle_param', 'logging_param', 'y_train', 'is_multiclass', 'target_param'}
2024-08-28 14:52:32,864:INFO:Checking environment
2024-08-28 14:52:32,864:INFO:python_version: 3.11.9
2024-08-28 14:52:32,864:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-08-28 14:52:32,864:INFO:machine: AMD64
2024-08-28 14:52:32,864:INFO:platform: Windows-10-10.0.22631-SP0
2024-08-28 14:52:32,872:INFO:Memory: svmem(total=16867028992, available=4927434752, percent=70.8, used=11939594240, free=4927434752)
2024-08-28 14:52:32,872:INFO:Physical Core: 6
2024-08-28 14:52:32,872:INFO:Logical Core: 12
2024-08-28 14:52:32,873:INFO:Checking libraries
2024-08-28 14:52:32,873:INFO:System:
2024-08-28 14:52:32,873:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-08-28 14:52:32,873:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-08-28 14:52:32,873:INFO:   machine: Windows-10-10.0.22631-SP0
2024-08-28 14:52:32,873:INFO:PyCaret required dependencies:
2024-08-28 14:52:32,873:INFO:                 pip: 23.2.1
2024-08-28 14:52:32,873:INFO:          setuptools: 67.8.0
2024-08-28 14:52:32,873:INFO:             pycaret: 3.3.2
2024-08-28 14:52:32,873:INFO:             IPython: 8.14.0
2024-08-28 14:52:32,873:INFO:          ipywidgets: 8.1.5
2024-08-28 14:52:32,873:INFO:                tqdm: 4.66.5
2024-08-28 14:52:32,873:INFO:               numpy: 1.24.3
2024-08-28 14:52:32,873:INFO:              pandas: 2.0.3
2024-08-28 14:52:32,873:INFO:              jinja2: 3.1.4
2024-08-28 14:52:32,873:INFO:               scipy: 1.10.1
2024-08-28 14:52:32,873:INFO:              joblib: 1.2.0
2024-08-28 14:52:32,873:INFO:             sklearn: 1.4.2
2024-08-28 14:52:32,873:INFO:                pyod: 2.0.1
2024-08-28 14:52:32,873:INFO:            imblearn: 0.12.3
2024-08-28 14:52:32,874:INFO:   category_encoders: 2.6.3
2024-08-28 14:52:32,874:INFO:            lightgbm: 4.5.0
2024-08-28 14:52:32,874:INFO:               numba: 0.60.0
2024-08-28 14:52:32,874:INFO:            requests: 2.32.3
2024-08-28 14:52:32,874:INFO:          matplotlib: 3.7.1
2024-08-28 14:52:32,874:INFO:          scikitplot: 0.3.7
2024-08-28 14:52:32,874:INFO:         yellowbrick: 1.5
2024-08-28 14:52:32,874:INFO:              plotly: 5.16.1
2024-08-28 14:52:32,874:INFO:    plotly-resampler: Not installed
2024-08-28 14:52:32,875:INFO:             kaleido: 0.2.1
2024-08-28 14:52:32,875:INFO:           schemdraw: 0.15
2024-08-28 14:52:32,875:INFO:         statsmodels: 0.14.2
2024-08-28 14:52:32,875:INFO:              sktime: 0.26.0
2024-08-28 14:52:32,875:INFO:               tbats: 1.1.3
2024-08-28 14:52:32,875:INFO:            pmdarima: 2.0.4
2024-08-28 14:52:32,875:INFO:              psutil: 5.9.0
2024-08-28 14:52:32,875:INFO:          markupsafe: 2.1.3
2024-08-28 14:52:32,875:INFO:             pickle5: Not installed
2024-08-28 14:52:32,875:INFO:         cloudpickle: 3.0.0
2024-08-28 14:52:32,875:INFO:         deprecation: 2.1.0
2024-08-28 14:52:32,875:INFO:              xxhash: 3.5.0
2024-08-28 14:52:32,875:INFO:           wurlitzer: Not installed
2024-08-28 14:52:32,875:INFO:PyCaret optional dependencies:
2024-08-28 14:52:32,875:INFO:                shap: Not installed
2024-08-28 14:52:32,875:INFO:           interpret: Not installed
2024-08-28 14:52:32,875:INFO:                umap: Not installed
2024-08-28 14:52:32,876:INFO:     ydata_profiling: Not installed
2024-08-28 14:52:32,876:INFO:  explainerdashboard: Not installed
2024-08-28 14:52:32,876:INFO:             autoviz: Not installed
2024-08-28 14:52:32,876:INFO:           fairlearn: Not installed
2024-08-28 14:52:32,876:INFO:          deepchecks: Not installed
2024-08-28 14:52:32,876:INFO:             xgboost: 2.0.2
2024-08-28 14:52:32,876:INFO:            catboost: Not installed
2024-08-28 14:52:32,876:INFO:              kmodes: Not installed
2024-08-28 14:52:32,876:INFO:             mlxtend: Not installed
2024-08-28 14:52:32,876:INFO:       statsforecast: Not installed
2024-08-28 14:52:32,876:INFO:        tune_sklearn: Not installed
2024-08-28 14:52:32,876:INFO:                 ray: Not installed
2024-08-28 14:52:32,876:INFO:            hyperopt: Not installed
2024-08-28 14:52:32,876:INFO:              optuna: Not installed
2024-08-28 14:52:32,876:INFO:               skopt: Not installed
2024-08-28 14:52:32,876:INFO:              mlflow: Not installed
2024-08-28 14:52:32,877:INFO:              gradio: 4.41.0
2024-08-28 14:52:32,877:INFO:             fastapi: 0.112.1
2024-08-28 14:52:32,877:INFO:             uvicorn: 0.30.6
2024-08-28 14:52:32,877:INFO:              m2cgen: Not installed
2024-08-28 14:52:32,877:INFO:           evidently: Not installed
2024-08-28 14:52:32,877:INFO:               fugue: Not installed
2024-08-28 14:52:32,877:INFO:           streamlit: Not installed
2024-08-28 14:52:32,877:INFO:             prophet: Not installed
2024-08-28 14:52:32,877:INFO:None
2024-08-28 14:52:32,877:INFO:Set up data.
2024-08-28 14:52:32,887:INFO:Set up folding strategy.
2024-08-28 14:52:32,888:INFO:Set up train/test split.
2024-08-28 14:52:32,898:INFO:Set up index.
2024-08-28 14:52:32,899:INFO:Assigning column types.
2024-08-28 14:52:32,906:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-08-28 14:52:32,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:32,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-28 14:52:32,993:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:32,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,032:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-08-28 14:52:33,033:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-28 14:52:33,058:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:33,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,061:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-08-28 14:52:33,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-28 14:52:33,121:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:33,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,157:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-08-28 14:52:33,179:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:33,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,181:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-08-28 14:52:33,239:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:33,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,297:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:33,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,302:INFO:Preparing preprocessing pipeline...
2024-08-28 14:52:33,303:INFO:Set up simple imputation.
2024-08-28 14:52:33,305:INFO:Set up encoding of ordinal features.
2024-08-28 14:52:33,307:INFO:Set up encoding of categorical features.
2024-08-28 14:52:33,366:INFO:Finished creating preprocessing pipeline.
2024-08-28 14:52:33,381:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RestingBP', 'Cholesterol',
                                             'FastingBS', 'MaxHR', 'Oldpeak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('ca...
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['ChestPainType', 'RestingECG',
                                             'ST_Slope'],
                                    transformer=OneHotEncoder(cols=['ChestPainType',
                                                                    'RestingECG',
                                                                    'ST_Slope'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-08-28 14:52:33,381:INFO:Creating final display dataframe.
2024-08-28 14:52:33,560:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      HeartDisease
2                   Target type            Binary
3           Original data shape         (918, 12)
4        Transformed data shape         (918, 19)
5   Transformed train set shape         (642, 19)
6    Transformed test set shape         (276, 19)
7              Numeric features                 6
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              ec8d
2024-08-28 14:52:33,625:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:33,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,686:INFO:Soft dependency imported: xgboost: 2.0.2
2024-08-28 14:52:33,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-08-28 14:52:33,689:INFO:setup() successfully completed in 0.83s...............
2024-08-28 14:52:33,690:INFO:Initializing compare_models()
2024-08-28 14:52:33,690:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-08-28 14:52:33,690:INFO:Checking exceptions
2024-08-28 14:52:33,693:INFO:Preparing display monitor
2024-08-28 14:52:33,713:INFO:Initializing Logistic Regression
2024-08-28 14:52:33,713:INFO:Total runtime is 0.0 minutes
2024-08-28 14:52:33,716:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:33,716:INFO:Initializing create_model()
2024-08-28 14:52:33,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:33,716:INFO:Checking exceptions
2024-08-28 14:52:33,716:INFO:Importing libraries
2024-08-28 14:52:33,716:INFO:Copying training dataset
2024-08-28 14:52:33,722:INFO:Defining folds
2024-08-28 14:52:33,722:INFO:Declaring metric variables
2024-08-28 14:52:33,725:INFO:Importing untrained model
2024-08-28 14:52:33,728:INFO:Logistic Regression Imported successfully
2024-08-28 14:52:33,733:INFO:Starting cross validation
2024-08-28 14:52:33,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:40,930:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:40,999:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:41,136:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:41,163:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:41,177:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:41,186:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:41,213:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:41,242:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-08-28 14:52:41,300:INFO:Calculating mean and std
2024-08-28 14:52:41,301:INFO:Creating metrics dataframe
2024-08-28 14:52:41,303:INFO:Uploading results into container
2024-08-28 14:52:41,304:INFO:Uploading model into container now
2024-08-28 14:52:41,305:INFO:_master_model_container: 1
2024-08-28 14:52:41,305:INFO:_display_container: 2
2024-08-28 14:52:41,305:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-08-28 14:52:41,305:INFO:create_model() successfully completed......................................
2024-08-28 14:52:41,535:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:41,536:INFO:Creating metrics dataframe
2024-08-28 14:52:41,545:INFO:Initializing K Neighbors Classifier
2024-08-28 14:52:41,545:INFO:Total runtime is 0.13052483797073364 minutes
2024-08-28 14:52:41,547:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:41,548:INFO:Initializing create_model()
2024-08-28 14:52:41,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:41,548:INFO:Checking exceptions
2024-08-28 14:52:41,548:INFO:Importing libraries
2024-08-28 14:52:41,548:INFO:Copying training dataset
2024-08-28 14:52:41,555:INFO:Defining folds
2024-08-28 14:52:41,555:INFO:Declaring metric variables
2024-08-28 14:52:41,559:INFO:Importing untrained model
2024-08-28 14:52:41,563:INFO:K Neighbors Classifier Imported successfully
2024-08-28 14:52:41,572:INFO:Starting cross validation
2024-08-28 14:52:41,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:44,147:INFO:Calculating mean and std
2024-08-28 14:52:44,148:INFO:Creating metrics dataframe
2024-08-28 14:52:44,149:INFO:Uploading results into container
2024-08-28 14:52:44,150:INFO:Uploading model into container now
2024-08-28 14:52:44,150:INFO:_master_model_container: 2
2024-08-28 14:52:44,150:INFO:_display_container: 2
2024-08-28 14:52:44,151:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-08-28 14:52:44,151:INFO:create_model() successfully completed......................................
2024-08-28 14:52:44,357:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:44,357:INFO:Creating metrics dataframe
2024-08-28 14:52:44,362:INFO:Initializing Naive Bayes
2024-08-28 14:52:44,364:INFO:Total runtime is 0.1775147795677185 minutes
2024-08-28 14:52:44,366:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:44,367:INFO:Initializing create_model()
2024-08-28 14:52:44,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:44,367:INFO:Checking exceptions
2024-08-28 14:52:44,367:INFO:Importing libraries
2024-08-28 14:52:44,367:INFO:Copying training dataset
2024-08-28 14:52:44,371:INFO:Defining folds
2024-08-28 14:52:44,371:INFO:Declaring metric variables
2024-08-28 14:52:44,373:INFO:Importing untrained model
2024-08-28 14:52:44,377:INFO:Naive Bayes Imported successfully
2024-08-28 14:52:44,381:INFO:Starting cross validation
2024-08-28 14:52:44,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:44,596:INFO:Calculating mean and std
2024-08-28 14:52:44,597:INFO:Creating metrics dataframe
2024-08-28 14:52:44,599:INFO:Uploading results into container
2024-08-28 14:52:44,600:INFO:Uploading model into container now
2024-08-28 14:52:44,600:INFO:_master_model_container: 3
2024-08-28 14:52:44,600:INFO:_display_container: 2
2024-08-28 14:52:44,600:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-08-28 14:52:44,600:INFO:create_model() successfully completed......................................
2024-08-28 14:52:44,801:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:44,801:INFO:Creating metrics dataframe
2024-08-28 14:52:44,808:INFO:Initializing Decision Tree Classifier
2024-08-28 14:52:44,808:INFO:Total runtime is 0.18492305676142373 minutes
2024-08-28 14:52:44,811:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:44,812:INFO:Initializing create_model()
2024-08-28 14:52:44,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:44,812:INFO:Checking exceptions
2024-08-28 14:52:44,812:INFO:Importing libraries
2024-08-28 14:52:44,812:INFO:Copying training dataset
2024-08-28 14:52:44,816:INFO:Defining folds
2024-08-28 14:52:44,816:INFO:Declaring metric variables
2024-08-28 14:52:44,820:INFO:Importing untrained model
2024-08-28 14:52:44,823:INFO:Decision Tree Classifier Imported successfully
2024-08-28 14:52:44,829:INFO:Starting cross validation
2024-08-28 14:52:44,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:45,096:INFO:Calculating mean and std
2024-08-28 14:52:45,098:INFO:Creating metrics dataframe
2024-08-28 14:52:45,099:INFO:Uploading results into container
2024-08-28 14:52:45,100:INFO:Uploading model into container now
2024-08-28 14:52:45,100:INFO:_master_model_container: 4
2024-08-28 14:52:45,100:INFO:_display_container: 2
2024-08-28 14:52:45,101:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-08-28 14:52:45,101:INFO:create_model() successfully completed......................................
2024-08-28 14:52:45,314:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:45,315:INFO:Creating metrics dataframe
2024-08-28 14:52:45,324:INFO:Initializing SVM - Linear Kernel
2024-08-28 14:52:45,324:INFO:Total runtime is 0.1935157577196757 minutes
2024-08-28 14:52:45,328:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:45,328:INFO:Initializing create_model()
2024-08-28 14:52:45,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:45,329:INFO:Checking exceptions
2024-08-28 14:52:45,329:INFO:Importing libraries
2024-08-28 14:52:45,329:INFO:Copying training dataset
2024-08-28 14:52:45,334:INFO:Defining folds
2024-08-28 14:52:45,334:INFO:Declaring metric variables
2024-08-28 14:52:45,337:INFO:Importing untrained model
2024-08-28 14:52:45,342:INFO:SVM - Linear Kernel Imported successfully
2024-08-28 14:52:45,350:INFO:Starting cross validation
2024-08-28 14:52:45,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:45,726:INFO:Calculating mean and std
2024-08-28 14:52:45,728:INFO:Creating metrics dataframe
2024-08-28 14:52:45,729:INFO:Uploading results into container
2024-08-28 14:52:45,730:INFO:Uploading model into container now
2024-08-28 14:52:45,730:INFO:_master_model_container: 5
2024-08-28 14:52:45,730:INFO:_display_container: 2
2024-08-28 14:52:45,731:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-08-28 14:52:45,731:INFO:create_model() successfully completed......................................
2024-08-28 14:52:45,941:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:45,941:INFO:Creating metrics dataframe
2024-08-28 14:52:45,948:INFO:Initializing Ridge Classifier
2024-08-28 14:52:45,948:INFO:Total runtime is 0.2039089242617289 minutes
2024-08-28 14:52:45,951:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:45,951:INFO:Initializing create_model()
2024-08-28 14:52:45,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:45,951:INFO:Checking exceptions
2024-08-28 14:52:45,951:INFO:Importing libraries
2024-08-28 14:52:45,951:INFO:Copying training dataset
2024-08-28 14:52:45,955:INFO:Defining folds
2024-08-28 14:52:45,955:INFO:Declaring metric variables
2024-08-28 14:52:45,958:INFO:Importing untrained model
2024-08-28 14:52:45,961:INFO:Ridge Classifier Imported successfully
2024-08-28 14:52:45,966:INFO:Starting cross validation
2024-08-28 14:52:45,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:46,229:INFO:Calculating mean and std
2024-08-28 14:52:46,230:INFO:Creating metrics dataframe
2024-08-28 14:52:46,232:INFO:Uploading results into container
2024-08-28 14:52:46,232:INFO:Uploading model into container now
2024-08-28 14:52:46,233:INFO:_master_model_container: 6
2024-08-28 14:52:46,233:INFO:_display_container: 2
2024-08-28 14:52:46,233:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:46,233:INFO:create_model() successfully completed......................................
2024-08-28 14:52:46,436:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:46,436:INFO:Creating metrics dataframe
2024-08-28 14:52:46,443:INFO:Initializing Random Forest Classifier
2024-08-28 14:52:46,444:INFO:Total runtime is 0.21218086083730062 minutes
2024-08-28 14:52:46,446:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:46,447:INFO:Initializing create_model()
2024-08-28 14:52:46,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:46,447:INFO:Checking exceptions
2024-08-28 14:52:46,447:INFO:Importing libraries
2024-08-28 14:52:46,447:INFO:Copying training dataset
2024-08-28 14:52:46,451:INFO:Defining folds
2024-08-28 14:52:46,451:INFO:Declaring metric variables
2024-08-28 14:52:46,453:INFO:Importing untrained model
2024-08-28 14:52:46,457:INFO:Random Forest Classifier Imported successfully
2024-08-28 14:52:46,463:INFO:Starting cross validation
2024-08-28 14:52:46,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:47,258:INFO:Calculating mean and std
2024-08-28 14:52:47,260:INFO:Creating metrics dataframe
2024-08-28 14:52:47,262:INFO:Uploading results into container
2024-08-28 14:52:47,263:INFO:Uploading model into container now
2024-08-28 14:52:47,263:INFO:_master_model_container: 7
2024-08-28 14:52:47,263:INFO:_display_container: 2
2024-08-28 14:52:47,264:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-08-28 14:52:47,264:INFO:create_model() successfully completed......................................
2024-08-28 14:52:47,506:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:47,507:INFO:Creating metrics dataframe
2024-08-28 14:52:47,518:INFO:Initializing Quadratic Discriminant Analysis
2024-08-28 14:52:47,518:INFO:Total runtime is 0.23008554776509602 minutes
2024-08-28 14:52:47,524:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:47,524:INFO:Initializing create_model()
2024-08-28 14:52:47,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:47,525:INFO:Checking exceptions
2024-08-28 14:52:47,525:INFO:Importing libraries
2024-08-28 14:52:47,525:INFO:Copying training dataset
2024-08-28 14:52:47,530:INFO:Defining folds
2024-08-28 14:52:47,530:INFO:Declaring metric variables
2024-08-28 14:52:47,535:INFO:Importing untrained model
2024-08-28 14:52:47,541:INFO:Quadratic Discriminant Analysis Imported successfully
2024-08-28 14:52:47,554:INFO:Starting cross validation
2024-08-28 14:52:47,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:47,733:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,735:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,750:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,768:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,771:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,776:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,785:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,791:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,797:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,817:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-08-28 14:52:47,829:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-08-28 14:52:47,895:INFO:Calculating mean and std
2024-08-28 14:52:47,895:INFO:Creating metrics dataframe
2024-08-28 14:52:47,897:INFO:Uploading results into container
2024-08-28 14:52:47,897:INFO:Uploading model into container now
2024-08-28 14:52:47,898:INFO:_master_model_container: 8
2024-08-28 14:52:47,898:INFO:_display_container: 2
2024-08-28 14:52:47,898:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-08-28 14:52:47,899:INFO:create_model() successfully completed......................................
2024-08-28 14:52:48,130:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:48,130:INFO:Creating metrics dataframe
2024-08-28 14:52:48,139:INFO:Initializing Ada Boost Classifier
2024-08-28 14:52:48,139:INFO:Total runtime is 0.2404395302136739 minutes
2024-08-28 14:52:48,143:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:48,143:INFO:Initializing create_model()
2024-08-28 14:52:48,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:48,143:INFO:Checking exceptions
2024-08-28 14:52:48,144:INFO:Importing libraries
2024-08-28 14:52:48,144:INFO:Copying training dataset
2024-08-28 14:52:48,148:INFO:Defining folds
2024-08-28 14:52:48,148:INFO:Declaring metric variables
2024-08-28 14:52:48,151:INFO:Importing untrained model
2024-08-28 14:52:48,156:INFO:Ada Boost Classifier Imported successfully
2024-08-28 14:52:48,164:INFO:Starting cross validation
2024-08-28 14:52:48,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:48,325:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,333:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,339:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,339:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,340:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,344:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,353:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,354:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,366:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,380:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-08-28 14:52:48,794:INFO:Calculating mean and std
2024-08-28 14:52:48,795:INFO:Creating metrics dataframe
2024-08-28 14:52:48,797:INFO:Uploading results into container
2024-08-28 14:52:48,797:INFO:Uploading model into container now
2024-08-28 14:52:48,798:INFO:_master_model_container: 9
2024-08-28 14:52:48,798:INFO:_display_container: 2
2024-08-28 14:52:48,798:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-08-28 14:52:48,798:INFO:create_model() successfully completed......................................
2024-08-28 14:52:49,105:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:49,106:INFO:Creating metrics dataframe
2024-08-28 14:52:49,114:INFO:Initializing Gradient Boosting Classifier
2024-08-28 14:52:49,115:INFO:Total runtime is 0.25669865210851034 minutes
2024-08-28 14:52:49,118:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:49,118:INFO:Initializing create_model()
2024-08-28 14:52:49,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:49,119:INFO:Checking exceptions
2024-08-28 14:52:49,119:INFO:Importing libraries
2024-08-28 14:52:49,119:INFO:Copying training dataset
2024-08-28 14:52:49,129:INFO:Defining folds
2024-08-28 14:52:49,130:INFO:Declaring metric variables
2024-08-28 14:52:49,135:INFO:Importing untrained model
2024-08-28 14:52:49,140:INFO:Gradient Boosting Classifier Imported successfully
2024-08-28 14:52:49,153:INFO:Starting cross validation
2024-08-28 14:52:49,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:49,849:INFO:Calculating mean and std
2024-08-28 14:52:49,850:INFO:Creating metrics dataframe
2024-08-28 14:52:49,851:INFO:Uploading results into container
2024-08-28 14:52:49,852:INFO:Uploading model into container now
2024-08-28 14:52:49,852:INFO:_master_model_container: 10
2024-08-28 14:52:49,852:INFO:_display_container: 2
2024-08-28 14:52:49,853:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-08-28 14:52:49,853:INFO:create_model() successfully completed......................................
2024-08-28 14:52:50,080:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:50,080:INFO:Creating metrics dataframe
2024-08-28 14:52:50,088:INFO:Initializing Linear Discriminant Analysis
2024-08-28 14:52:50,088:INFO:Total runtime is 0.27291417121887207 minutes
2024-08-28 14:52:50,090:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:50,091:INFO:Initializing create_model()
2024-08-28 14:52:50,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:50,091:INFO:Checking exceptions
2024-08-28 14:52:50,091:INFO:Importing libraries
2024-08-28 14:52:50,091:INFO:Copying training dataset
2024-08-28 14:52:50,096:INFO:Defining folds
2024-08-28 14:52:50,096:INFO:Declaring metric variables
2024-08-28 14:52:50,100:INFO:Importing untrained model
2024-08-28 14:52:50,105:INFO:Linear Discriminant Analysis Imported successfully
2024-08-28 14:52:50,114:INFO:Starting cross validation
2024-08-28 14:52:50,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:50,370:INFO:Calculating mean and std
2024-08-28 14:52:50,372:INFO:Creating metrics dataframe
2024-08-28 14:52:50,374:INFO:Uploading results into container
2024-08-28 14:52:50,375:INFO:Uploading model into container now
2024-08-28 14:52:50,375:INFO:_master_model_container: 11
2024-08-28 14:52:50,375:INFO:_display_container: 2
2024-08-28 14:52:50,376:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-08-28 14:52:50,376:INFO:create_model() successfully completed......................................
2024-08-28 14:52:50,605:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:50,605:INFO:Creating metrics dataframe
2024-08-28 14:52:50,618:INFO:Initializing Extra Trees Classifier
2024-08-28 14:52:50,619:INFO:Total runtime is 0.28174819151560465 minutes
2024-08-28 14:52:50,621:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:50,622:INFO:Initializing create_model()
2024-08-28 14:52:50,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:50,622:INFO:Checking exceptions
2024-08-28 14:52:50,623:INFO:Importing libraries
2024-08-28 14:52:50,623:INFO:Copying training dataset
2024-08-28 14:52:50,627:INFO:Defining folds
2024-08-28 14:52:50,627:INFO:Declaring metric variables
2024-08-28 14:52:50,630:INFO:Importing untrained model
2024-08-28 14:52:50,634:INFO:Extra Trees Classifier Imported successfully
2024-08-28 14:52:50,642:INFO:Starting cross validation
2024-08-28 14:52:50,643:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:51,312:INFO:Calculating mean and std
2024-08-28 14:52:51,313:INFO:Creating metrics dataframe
2024-08-28 14:52:51,314:INFO:Uploading results into container
2024-08-28 14:52:51,315:INFO:Uploading model into container now
2024-08-28 14:52:51,315:INFO:_master_model_container: 12
2024-08-28 14:52:51,315:INFO:_display_container: 2
2024-08-28 14:52:51,316:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-08-28 14:52:51,316:INFO:create_model() successfully completed......................................
2024-08-28 14:52:51,525:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:51,525:INFO:Creating metrics dataframe
2024-08-28 14:52:51,534:INFO:Initializing Extreme Gradient Boosting
2024-08-28 14:52:51,535:INFO:Total runtime is 0.29702703952789306 minutes
2024-08-28 14:52:51,537:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:51,537:INFO:Initializing create_model()
2024-08-28 14:52:51,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:51,537:INFO:Checking exceptions
2024-08-28 14:52:51,537:INFO:Importing libraries
2024-08-28 14:52:51,537:INFO:Copying training dataset
2024-08-28 14:52:51,542:INFO:Defining folds
2024-08-28 14:52:51,542:INFO:Declaring metric variables
2024-08-28 14:52:51,545:INFO:Importing untrained model
2024-08-28 14:52:51,549:INFO:Extreme Gradient Boosting Imported successfully
2024-08-28 14:52:51,555:INFO:Starting cross validation
2024-08-28 14:52:51,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:52,081:INFO:Calculating mean and std
2024-08-28 14:52:52,082:INFO:Creating metrics dataframe
2024-08-28 14:52:52,084:INFO:Uploading results into container
2024-08-28 14:52:52,085:INFO:Uploading model into container now
2024-08-28 14:52:52,085:INFO:_master_model_container: 13
2024-08-28 14:52:52,085:INFO:_display_container: 2
2024-08-28 14:52:52,086:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-08-28 14:52:52,087:INFO:create_model() successfully completed......................................
2024-08-28 14:52:52,309:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:52,309:INFO:Creating metrics dataframe
2024-08-28 14:52:52,318:INFO:Initializing Light Gradient Boosting Machine
2024-08-28 14:52:52,318:INFO:Total runtime is 0.3100888252258301 minutes
2024-08-28 14:52:52,321:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:52,321:INFO:Initializing create_model()
2024-08-28 14:52:52,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:52,321:INFO:Checking exceptions
2024-08-28 14:52:52,321:INFO:Importing libraries
2024-08-28 14:52:52,321:INFO:Copying training dataset
2024-08-28 14:52:52,326:INFO:Defining folds
2024-08-28 14:52:52,326:INFO:Declaring metric variables
2024-08-28 14:52:52,330:INFO:Importing untrained model
2024-08-28 14:52:52,333:INFO:Light Gradient Boosting Machine Imported successfully
2024-08-28 14:52:52,339:INFO:Starting cross validation
2024-08-28 14:52:52,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:53,696:INFO:Calculating mean and std
2024-08-28 14:52:53,698:INFO:Creating metrics dataframe
2024-08-28 14:52:53,701:INFO:Uploading results into container
2024-08-28 14:52:53,701:INFO:Uploading model into container now
2024-08-28 14:52:53,702:INFO:_master_model_container: 14
2024-08-28 14:52:53,702:INFO:_display_container: 2
2024-08-28 14:52:53,703:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-08-28 14:52:53,704:INFO:create_model() successfully completed......................................
2024-08-28 14:52:53,942:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:53,943:INFO:Creating metrics dataframe
2024-08-28 14:52:53,952:INFO:Initializing Dummy Classifier
2024-08-28 14:52:53,953:INFO:Total runtime is 0.3373295625050863 minutes
2024-08-28 14:52:53,956:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:53,957:INFO:Initializing create_model()
2024-08-28 14:52:53,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8A90810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:53,957:INFO:Checking exceptions
2024-08-28 14:52:53,957:INFO:Importing libraries
2024-08-28 14:52:53,957:INFO:Copying training dataset
2024-08-28 14:52:53,962:INFO:Defining folds
2024-08-28 14:52:53,963:INFO:Declaring metric variables
2024-08-28 14:52:53,967:INFO:Importing untrained model
2024-08-28 14:52:53,970:INFO:Dummy Classifier Imported successfully
2024-08-28 14:52:53,975:INFO:Starting cross validation
2024-08-28 14:52:53,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:54,219:INFO:Calculating mean and std
2024-08-28 14:52:54,220:INFO:Creating metrics dataframe
2024-08-28 14:52:54,221:INFO:Uploading results into container
2024-08-28 14:52:54,222:INFO:Uploading model into container now
2024-08-28 14:52:54,223:INFO:_master_model_container: 15
2024-08-28 14:52:54,223:INFO:_display_container: 2
2024-08-28 14:52:54,223:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-08-28 14:52:54,223:INFO:create_model() successfully completed......................................
2024-08-28 14:52:54,429:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:54,429:INFO:Creating metrics dataframe
2024-08-28 14:52:54,445:INFO:Initializing create_model()
2024-08-28 14:52:54,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:54,445:INFO:Checking exceptions
2024-08-28 14:52:54,447:INFO:Importing libraries
2024-08-28 14:52:54,447:INFO:Copying training dataset
2024-08-28 14:52:54,451:INFO:Defining folds
2024-08-28 14:52:54,451:INFO:Declaring metric variables
2024-08-28 14:52:54,451:INFO:Importing untrained model
2024-08-28 14:52:54,451:INFO:Declaring custom model
2024-08-28 14:52:54,451:INFO:Ridge Classifier Imported successfully
2024-08-28 14:52:54,453:INFO:Cross validation set to False
2024-08-28 14:52:54,453:INFO:Fitting Model
2024-08-28 14:52:54,504:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:54,504:INFO:create_model() successfully completed......................................
2024-08-28 14:52:54,737:INFO:_master_model_container: 15
2024-08-28 14:52:54,737:INFO:_display_container: 2
2024-08-28 14:52:54,738:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:54,738:INFO:compare_models() successfully completed......................................
2024-08-28 14:52:54,738:INFO:Initializing create_model()
2024-08-28 14:52:54,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:54,738:INFO:Checking exceptions
2024-08-28 14:52:54,750:INFO:Importing libraries
2024-08-28 14:52:54,750:INFO:Copying training dataset
2024-08-28 14:52:54,755:INFO:Defining folds
2024-08-28 14:52:54,755:INFO:Declaring metric variables
2024-08-28 14:52:54,757:INFO:Importing untrained model
2024-08-28 14:52:54,757:INFO:Declaring custom model
2024-08-28 14:52:54,760:INFO:Ridge Classifier Imported successfully
2024-08-28 14:52:54,765:INFO:Starting cross validation
2024-08-28 14:52:54,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:55,142:INFO:Calculating mean and std
2024-08-28 14:52:55,142:INFO:Creating metrics dataframe
2024-08-28 14:52:55,146:INFO:Finalizing model
2024-08-28 14:52:55,198:INFO:Uploading results into container
2024-08-28 14:52:55,199:INFO:Uploading model into container now
2024-08-28 14:52:55,206:INFO:_master_model_container: 16
2024-08-28 14:52:55,207:INFO:_display_container: 3
2024-08-28 14:52:55,207:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:55,208:INFO:create_model() successfully completed......................................
2024-08-28 14:52:55,419:INFO:Initializing tune_model()
2024-08-28 14:52:55,419:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-08-28 14:52:55,419:INFO:Checking exceptions
2024-08-28 14:52:55,432:INFO:Copying training dataset
2024-08-28 14:52:55,436:INFO:Checking base model
2024-08-28 14:52:55,436:INFO:Base model : Ridge Classifier
2024-08-28 14:52:55,439:INFO:Declaring metric variables
2024-08-28 14:52:55,443:INFO:Defining Hyperparameters
2024-08-28 14:52:55,708:INFO:Tuning with n_jobs=-1
2024-08-28 14:52:55,708:INFO:Initializing RandomizedSearchCV
2024-08-28 14:52:58,059:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 6.95}
2024-08-28 14:52:58,061:INFO:Hyperparameter search completed
2024-08-28 14:52:58,061:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:58,061:INFO:Initializing create_model()
2024-08-28 14:52:58,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000155D8105B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 6.95})
2024-08-28 14:52:58,061:INFO:Checking exceptions
2024-08-28 14:52:58,062:INFO:Importing libraries
2024-08-28 14:52:58,062:INFO:Copying training dataset
2024-08-28 14:52:58,070:INFO:Defining folds
2024-08-28 14:52:58,070:INFO:Declaring metric variables
2024-08-28 14:52:58,073:INFO:Importing untrained model
2024-08-28 14:52:58,073:INFO:Declaring custom model
2024-08-28 14:52:58,078:INFO:Ridge Classifier Imported successfully
2024-08-28 14:52:58,084:INFO:Starting cross validation
2024-08-28 14:52:58,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:58,338:INFO:Calculating mean and std
2024-08-28 14:52:58,339:INFO:Creating metrics dataframe
2024-08-28 14:52:58,344:INFO:Finalizing model
2024-08-28 14:52:58,418:INFO:Uploading results into container
2024-08-28 14:52:58,419:INFO:Uploading model into container now
2024-08-28 14:52:58,419:INFO:_master_model_container: 17
2024-08-28 14:52:58,420:INFO:_display_container: 4
2024-08-28 14:52:58,420:INFO:RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:58,420:INFO:create_model() successfully completed......................................
2024-08-28 14:52:58,664:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:58,664:INFO:choose_better activated
2024-08-28 14:52:58,668:INFO:SubProcess create_model() called ==================================
2024-08-28 14:52:58,669:INFO:Initializing create_model()
2024-08-28 14:52:58,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:58,669:INFO:Checking exceptions
2024-08-28 14:52:58,670:INFO:Importing libraries
2024-08-28 14:52:58,670:INFO:Copying training dataset
2024-08-28 14:52:58,674:INFO:Defining folds
2024-08-28 14:52:58,674:INFO:Declaring metric variables
2024-08-28 14:52:58,674:INFO:Importing untrained model
2024-08-28 14:52:58,674:INFO:Declaring custom model
2024-08-28 14:52:58,674:INFO:Ridge Classifier Imported successfully
2024-08-28 14:52:58,675:INFO:Starting cross validation
2024-08-28 14:52:58,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-08-28 14:52:58,915:INFO:Calculating mean and std
2024-08-28 14:52:58,916:INFO:Creating metrics dataframe
2024-08-28 14:52:58,918:INFO:Finalizing model
2024-08-28 14:52:58,982:INFO:Uploading results into container
2024-08-28 14:52:58,982:INFO:Uploading model into container now
2024-08-28 14:52:58,983:INFO:_master_model_container: 18
2024-08-28 14:52:58,983:INFO:_display_container: 5
2024-08-28 14:52:58,983:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:58,983:INFO:create_model() successfully completed......................................
2024-08-28 14:52:59,212:INFO:SubProcess create_model() end ==================================
2024-08-28 14:52:59,213:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) result for Accuracy is 0.8661
2024-08-28 14:52:59,213:INFO:RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) result for Accuracy is 0.8676
2024-08-28 14:52:59,213:INFO:RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001) is best model
2024-08-28 14:52:59,213:INFO:choose_better completed
2024-08-28 14:52:59,221:INFO:_master_model_container: 18
2024-08-28 14:52:59,221:INFO:_display_container: 4
2024-08-28 14:52:59,221:INFO:RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:59,221:INFO:tune_model() successfully completed......................................
2024-08-28 14:52:59,446:INFO:Initializing finalize_model()
2024-08-28 14:52:59,446:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-08-28 14:52:59,446:INFO:Finalizing RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-08-28 14:52:59,449:INFO:Initializing create_model()
2024-08-28 14:52:59,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True, fit_intercept=False,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-08-28 14:52:59,449:INFO:Checking exceptions
2024-08-28 14:52:59,450:INFO:Importing libraries
2024-08-28 14:52:59,450:INFO:Copying training dataset
2024-08-28 14:52:59,450:INFO:Defining folds
2024-08-28 14:52:59,450:INFO:Declaring metric variables
2024-08-28 14:52:59,451:INFO:Importing untrained model
2024-08-28 14:52:59,451:INFO:Declaring custom model
2024-08-28 14:52:59,451:INFO:Ridge Classifier Imported successfully
2024-08-28 14:52:59,452:INFO:Cross validation set to False
2024-08-28 14:52:59,452:INFO:Fitting Model
2024-08-28 14:52:59,528:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RestingBP', 'Cholesterol',
                                             'FastingBS', 'MaxHR', 'Oldpeak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                    transformer=OneHotEncoder(cols=['ChestPainType',
                                                                    'RestingECG',
                                                                    'ST_Slope'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('actual_estimator',
                 RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True,
                                 fit_intercept=False, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-08-28 14:52:59,528:INFO:create_model() successfully completed......................................
2024-08-28 14:52:59,772:INFO:_master_model_container: 18
2024-08-28 14:52:59,772:INFO:_display_container: 4
2024-08-28 14:52:59,790:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RestingBP', 'Cholesterol',
                                             'FastingBS', 'MaxHR', 'Oldpeak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                    transformer=OneHotEncoder(cols=['ChestPainType',
                                                                    'RestingECG',
                                                                    'ST_Slope'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('actual_estimator',
                 RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True,
                                 fit_intercept=False, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2024-08-28 14:52:59,790:INFO:finalize_model() successfully completed......................................
2024-08-28 14:53:00,031:INFO:Initializing predict_model()
2024-08-28 14:53:00,031:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000155D8349850>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'RestingBP', 'Cholesterol',
                                             'FastingBS', 'MaxHR', 'Oldpeak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(ex...
                                    transformer=OneHotEncoder(cols=['ChestPainType',
                                                                    'RestingECG',
                                                                    'ST_Slope'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('actual_estimator',
                 RidgeClassifier(alpha=6.95, class_weight=None, copy_X=True,
                                 fit_intercept=False, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000155D05767A0>)
2024-08-28 14:53:00,031:INFO:Checking exceptions
2024-08-28 14:53:00,031:INFO:Preloading libraries
2024-08-28 14:53:00,033:INFO:Set up data.
2024-08-28 14:53:00,040:INFO:Set up index.
2024-08-28 16:50:13,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 16:50:13,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 16:50:13,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 16:50:13,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 17:27:04,117:WARNING:C:\Users\ardav\AppData\Local\Temp\ipykernel_4744\121300864.py:8: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(X_train[col], ax=axes[i], kde=True)

2024-08-28 18:18:43,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 18:18:43,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 18:18:43,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 18:18:43,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 18:18:56,724:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-08-28 22:19:12,232:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-08-28 22:35:50,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:35:50,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:35:50,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:35:50,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:36:05,174:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-08-28 22:37:22,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:37:22,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:37:22,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:37:22,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:37:36,912:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-08-28 22:40:15,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:40:15,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:40:15,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:40:15,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 22:40:29,624:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-08-28 23:16:14,909:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-08-28 23:19:23,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:19:23,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:19:23,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:19:23,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:19:39,333:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

2024-08-28 23:28:34,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:28:34,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:28:34,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:28:34,073:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-08-28 23:28:48,028:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\feature_engine\encoding\rare_label.py:216: UserWarning: The number of unique categories for variable Gender is less than that indicated in n_categories. Thus, all categories will be considered frequent
  warnings.warn(

